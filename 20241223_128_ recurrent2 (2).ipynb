{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e3bb6ba70918dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T07:50:49.917672Z",
     "start_time": "2024-12-17T07:50:49.704223Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/kornia/feature/lightglue.py:30: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 128, 128])\n",
      "Using cuda device\n",
      "Initial MSE: 0.002903, Initial PSNR: 24.917110, 08:27:02\n",
      "Logging to ./ppo_with_mask/RecurrentPPO_34\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002903, Initial PSNR: 24.917110, 2024-12-23 08:27:02.635675\n",
      "Step: 100, MSE: 0.003123, PSNR: 24.600241, PSNR Diff: -0.316870, Changes: 5, Reward: -2.22, 08:27:04\n",
      "Step: 200, MSE: 0.003293, PSNR: 24.369192, PSNR Diff: -0.547918, Changes: 5, Reward: -3.84, 08:27:06\n",
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 48  |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 5   |\n",
      "|    total_timesteps | 256 |\n",
      "----------------------------\n",
      "Step: 300, MSE: 0.003497, PSNR: 24.108343, PSNR Diff: -0.808767, Changes: 5, Reward: -5.66, 08:27:17\n",
      "Episode failed: PSNR Diff -1.001867 < -1 at step 378\n",
      "Initial MSE: 0.001575, Initial PSNR: 23.704321, 08:27:18\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.001575, Initial PSNR: 23.704321, 2024-12-23 08:27:19.003181\n",
      "Step: 100, MSE: 0.001976, PSNR: 22.717319, PSNR Diff: -0.987001, Changes: 7, Reward: -6.91, 08:27:21\n",
      "Episode failed: PSNR Diff -1.004038 < -1 at step 105\n",
      "Initial MSE: 0.003024, Initial PSNR: 23.792854, 08:27:21\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.003024, Initial PSNR: 23.792854, 2024-12-23 08:27:21.246260\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 242           |\n",
      "|    ep_rew_mean          | -1.06e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 25            |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 19            |\n",
      "|    total_timesteps      | 512           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8754993e+17 |\n",
      "|    clip_fraction        | 0.887         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | -2.32         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.04e+10      |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | 1.59e+10      |\n",
      "|    value_loss           | 0.711         |\n",
      "-------------------------------------------\n",
      "Step: 100, MSE: 0.003171, PSNR: 23.586082, PSNR Diff: -0.206772, Changes: 5, Reward: -1.45, 08:27:31\n",
      "Step: 200, MSE: 0.003353, PSNR: 23.344521, PSNR Diff: -0.448334, Changes: 5, Reward: -3.14, 08:27:33\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 242           |\n",
      "|    ep_rew_mean          | -1.06e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 23            |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 32            |\n",
      "|    total_timesteps      | 768           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4933447e+19 |\n",
      "|    clip_fraction        | 0.889         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | 0.64          |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | -0.122        |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | 1.83e+15      |\n",
      "|    value_loss           | 0.152         |\n",
      "-------------------------------------------\n",
      "Step: 300, MSE: 0.003519, PSNR: 23.134651, PSNR Diff: -0.658203, Changes: 7, Reward: -4.61, 08:27:44\n",
      "Step: 400, MSE: 0.003707, PSNR: 22.908676, PSNR Diff: -0.884178, Changes: 5, Reward: -6.19, 08:27:46\n",
      "Episode failed: PSNR Diff -1.004997 < -1 at step 450\n",
      "Initial MSE: 0.002768, Initial PSNR: 22.790855, 08:27:47\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002768, Initial PSNR: 22.790855, 2024-12-23 08:27:47.025552\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 312          |\n",
      "|    ep_rew_mean          | -1.27e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 46           |\n",
      "|    total_timesteps      | 1024         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.150489e+17 |\n",
      "|    clip_fraction        | 0.891        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.09e+04    |\n",
      "|    explained_variance   | 0.767        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 4.08e+12     |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | 1.22e+11     |\n",
      "|    value_loss           | 0.0372       |\n",
      "------------------------------------------\n",
      "Step: 100, MSE: 0.003097, PSNR: 22.303076, PSNR Diff: -0.487780, Changes: 5, Reward: -3.41, 08:27:57\n",
      "Step: 200, MSE: 0.003429, PSNR: 21.860851, PSNR Diff: -0.930004, Changes: 5, Reward: -6.51, 08:27:59\n",
      "Episode failed: PSNR Diff -1.004425 < -1 at step 218\n",
      "Initial MSE: 0.002154, Initial PSNR: 23.738859, 08:27:59\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002154, Initial PSNR: 23.738859, 2024-12-23 08:27:59.989203\n",
      "Step: 100, MSE: 0.002558, PSNR: 22.991169, PSNR Diff: -0.747690, Changes: 5, Reward: -5.23, 08:28:01\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 289           |\n",
      "|    ep_rew_mean          | -1.19e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 21            |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 60            |\n",
      "|    total_timesteps      | 1280          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.7491503e+16 |\n",
      "|    clip_fraction        | 0.892         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | 0.815         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 3.6e+16       |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | 3.21e+15      |\n",
      "|    value_loss           | 0.0727        |\n",
      "-------------------------------------------\n",
      "Episode failed: PSNR Diff -1.007729 < -1 at step 134\n",
      "Initial MSE: 0.001132, Initial PSNR: 25.303185, 08:28:11\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.001132, Initial PSNR: 25.303185, 2024-12-23 08:28:11.632132\n",
      "Step: 100, MSE: 0.001291, PSNR: 24.733438, PSNR Diff: -0.569746, Changes: 4, Reward: -3.99, 08:28:13\n",
      "Episode failed: PSNR Diff -1.007202 < -1 at step 194\n",
      "Initial MSE: 0.003368, Initial PSNR: 24.725662, 08:28:15\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.003368, Initial PSNR: 24.725662, 2024-12-23 08:28:15.244239\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 248          |\n",
      "|    ep_rew_mean          | -1.05e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 20           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 1536         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.102122e+17 |\n",
      "|    clip_fraction        | 0.88         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.09e+04    |\n",
      "|    explained_variance   | -0.221       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.0115       |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | 9.27e+10     |\n",
      "|    value_loss           | 0.166        |\n",
      "------------------------------------------\n",
      "Step: 100, MSE: 0.003919, PSNR: 24.067722, PSNR Diff: -0.657940, Changes: 6, Reward: -4.61, 08:28:26\n",
      "Episode failed: PSNR Diff -1.000957 < -1 at step 147\n",
      "Initial MSE: 0.003499, Initial PSNR: 24.492687, 08:28:27\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.003499, Initial PSNR: 24.492687, 2024-12-23 08:28:27.249528\n",
      "Step: 100, MSE: 0.004367, PSNR: 23.530064, PSNR Diff: -0.962624, Changes: 5, Reward: -6.74, 08:28:29\n",
      "Episode failed: PSNR Diff -1.002331 < -1 at step 108\n",
      "Initial MSE: 0.003084, Initial PSNR: 24.867685, 08:28:29\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.003084, Initial PSNR: 24.867685, 2024-12-23 08:28:29.341524\n",
      "------------------------------------------------\n",
      "| rollout/                |                    |\n",
      "|    ep_len_mean          | 218                |\n",
      "|    ep_rew_mean          | -943               |\n",
      "| time/                   |                    |\n",
      "|    fps                  | 20                 |\n",
      "|    iterations           | 7                  |\n",
      "|    time_elapsed         | 88                 |\n",
      "|    total_timesteps      | 1792               |\n",
      "| train/                  |                    |\n",
      "|    approx_kl            | 3185726500000000.0 |\n",
      "|    clip_fraction        | 0.89               |\n",
      "|    clip_range           | 0.2                |\n",
      "|    entropy_loss         | -9.09e+04          |\n",
      "|    explained_variance   | -1.58              |\n",
      "|    learning_rate        | 1e-05              |\n",
      "|    loss                 | -0.0801            |\n",
      "|    n_updates            | 60                 |\n",
      "|    policy_gradient_loss | 1.63e+14           |\n",
      "|    value_loss           | 0.0839             |\n",
      "------------------------------------------------\n",
      "Step: 100, MSE: 0.003406, PSNR: 24.436342, PSNR Diff: -0.431343, Changes: 5, Reward: -3.02, 08:28:39\n",
      "Step: 200, MSE: 0.003750, PSNR: 24.017593, PSNR Diff: -0.850092, Changes: 6, Reward: -5.95, 08:28:41\n",
      "Episode failed: PSNR Diff -1.000824 < -1 at step 247\n",
      "Initial MSE: 0.001001, Initial PSNR: 27.300253, 08:28:42\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.001001, Initial PSNR: 27.300253, 2024-12-23 08:28:42.288936\n",
      "---------------------------------------------\n",
      "| rollout/                |                 |\n",
      "|    ep_len_mean          | 221             |\n",
      "|    ep_rew_mean          | -957            |\n",
      "| time/                   |                 |\n",
      "|    fps                  | 20              |\n",
      "|    iterations           | 8               |\n",
      "|    time_elapsed         | 101             |\n",
      "|    total_timesteps      | 2048            |\n",
      "| train/                  |                 |\n",
      "|    approx_kl            | 4824981600000.0 |\n",
      "|    clip_fraction        | 0.893           |\n",
      "|    clip_range           | 0.2             |\n",
      "|    entropy_loss         | -9.09e+04       |\n",
      "|    explained_variance   | -0.854          |\n",
      "|    learning_rate        | 1e-05           |\n",
      "|    loss                 | 0.0923          |\n",
      "|    n_updates            | 70              |\n",
      "|    policy_gradient_loss | 1.74e+11        |\n",
      "|    value_loss           | 0.104           |\n",
      "---------------------------------------------\n",
      "Step: 100, MSE: 0.001093, PSNR: 26.921026, PSNR Diff: -0.379227, Changes: 6, Reward: -2.65, 08:28:52\n",
      "Step: 200, MSE: 0.001201, PSNR: 26.511162, PSNR Diff: -0.789091, Changes: 5, Reward: -5.52, 08:28:54\n",
      "Episode failed: PSNR Diff -1.002783 < -1 at step 253\n",
      "Initial MSE: 0.002832, Initial PSNR: 24.037006, 08:28:55\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002832, Initial PSNR: 24.037006, 2024-12-23 08:28:55.653382\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 224         |\n",
      "|    ep_rew_mean          | -966        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 2304        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 4.27462e+25 |\n",
      "|    clip_fraction        | 0.885       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.09e+04   |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.335       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | 4.08e+23    |\n",
      "|    value_loss           | 0.0666      |\n",
      "-----------------------------------------\n",
      "Episode failed: PSNR Diff -1.003302 < -1 at step 78\n",
      "Initial MSE: 0.006280, Initial PSNR: 21.848166, 08:29:05\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.006280, Initial PSNR: 21.848166, 2024-12-23 08:29:05.535201\n",
      "Step: 100, MSE: 0.006761, PSNR: 21.527939, PSNR Diff: -0.320227, Changes: 5, Reward: -2.24, 08:29:07\n",
      "Step: 200, MSE: 0.007240, PSNR: 21.230911, PSNR Diff: -0.617254, Changes: 4, Reward: -4.32, 08:29:09\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 211           |\n",
      "|    ep_rew_mean          | -920          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 20            |\n",
      "|    iterations           | 10            |\n",
      "|    time_elapsed         | 127           |\n",
      "|    total_timesteps      | 2560          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.6820966e+20 |\n",
      "|    clip_fraction        | 0.889         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | -0.305        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 4.8           |\n",
      "|    n_updates            | 90            |\n",
      "|    policy_gradient_loss | 2.09e+16      |\n",
      "|    value_loss           | 0.124         |\n",
      "-------------------------------------------\n",
      "Step: 300, MSE: 0.007679, PSNR: 20.974848, PSNR Diff: -0.873318, Changes: 6, Reward: -6.11, 08:29:19\n",
      "Episode failed: PSNR Diff -1.003647 < -1 at step 357\n",
      "Initial MSE: 0.003895, Initial PSNR: 23.604679, 08:29:20\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.003895, Initial PSNR: 23.604679, 2024-12-23 08:29:20.690295\n",
      "Episode failed: PSNR Diff -1.001316 < -1 at step 93\n",
      "Initial MSE: 0.002880, Initial PSNR: 23.209085, 08:29:22\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002880, Initial PSNR: 23.209085, 2024-12-23 08:29:22.721174\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 213           |\n",
      "|    ep_rew_mean          | -935          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 141           |\n",
      "|    total_timesteps      | 2816          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9795417e+23 |\n",
      "|    clip_fraction        | 0.891         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | 0.785         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 0.00633       |\n",
      "|    n_updates            | 100           |\n",
      "|    policy_gradient_loss | 1.3e+22       |\n",
      "|    value_loss           | 0.0527        |\n",
      "-------------------------------------------\n",
      "Step: 100, MSE: 0.003040, PSNR: 22.973158, PSNR Diff: -0.235928, Changes: 7, Reward: -1.65, 08:29:32\n",
      "Step: 200, MSE: 0.003174, PSNR: 22.786308, PSNR Diff: -0.422777, Changes: 7, Reward: -2.96, 08:29:34\n",
      "------------------------------------------------\n",
      "| rollout/                |                    |\n",
      "|    ep_len_mean          | 213                |\n",
      "|    ep_rew_mean          | -935               |\n",
      "| time/                   |                    |\n",
      "|    fps                  | 19                 |\n",
      "|    iterations           | 12                 |\n",
      "|    time_elapsed         | 154                |\n",
      "|    total_timesteps      | 3072               |\n",
      "| train/                  |                    |\n",
      "|    approx_kl            | 6283462500000000.0 |\n",
      "|    clip_fraction        | 0.896              |\n",
      "|    clip_range           | 0.2                |\n",
      "|    entropy_loss         | -9.09e+04          |\n",
      "|    explained_variance   | 0.737              |\n",
      "|    learning_rate        | 1e-05              |\n",
      "|    loss                 | 8.74e+03           |\n",
      "|    n_updates            | 110                |\n",
      "|    policy_gradient_loss | 3.24e+10           |\n",
      "|    value_loss           | 0.0994             |\n",
      "------------------------------------------------\n",
      "Step: 300, MSE: 0.003323, PSNR: 22.587204, PSNR Diff: -0.621881, Changes: 5, Reward: -4.35, 08:29:45\n",
      "Step: 400, MSE: 0.003487, PSNR: 22.377644, PSNR Diff: -0.831442, Changes: 6, Reward: -5.82, 08:29:47\n",
      "Episode failed: PSNR Diff -1.000532 < -1 at step 493\n",
      "Initial MSE: 0.002352, Initial PSNR: 22.016918, 08:29:49\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002352, Initial PSNR: 22.016918, 2024-12-23 08:29:49.333994\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 234           |\n",
      "|    ep_rew_mean          | -1.01e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 168           |\n",
      "|    total_timesteps      | 3328          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2663514e+19 |\n",
      "|    clip_fraction        | 0.88          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | 0.295         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 0.148         |\n",
      "|    n_updates            | 120           |\n",
      "|    policy_gradient_loss | 1.17e+16      |\n",
      "|    value_loss           | 0.0721        |\n",
      "-------------------------------------------\n",
      "Step: 100, MSE: 0.002562, PSNR: 21.645748, PSNR Diff: -0.371170, Changes: 4, Reward: -2.60, 08:30:00\n",
      "Step: 200, MSE: 0.002761, PSNR: 21.321680, PSNR Diff: -0.695238, Changes: 5, Reward: -4.87, 08:30:01\n",
      "Episode failed: PSNR Diff -1.000223 < -1 at step 290\n",
      "Initial MSE: 0.003142, Initial PSNR: 24.354715, 08:30:03\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.003142, Initial PSNR: 24.354715, 2024-12-23 08:30:03.515774\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 237           |\n",
      "|    ep_rew_mean          | -1.02e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 14            |\n",
      "|    time_elapsed         | 181           |\n",
      "|    total_timesteps      | 3584          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0820399e+21 |\n",
      "|    clip_fraction        | 0.889         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | -0.966        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 990           |\n",
      "|    n_updates            | 130           |\n",
      "|    policy_gradient_loss | 2.43e+06      |\n",
      "|    value_loss           | 0.109         |\n",
      "-------------------------------------------\n",
      "Step: 100, MSE: 0.003424, PSNR: 23.982428, PSNR Diff: -0.372288, Changes: 7, Reward: -2.61, 08:30:14\n",
      "Step: 200, MSE: 0.003659, PSNR: 23.694380, PSNR Diff: -0.660336, Changes: 3, Reward: -4.62, 08:30:16\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 237           |\n",
      "|    ep_rew_mean          | -1.02e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 195           |\n",
      "|    total_timesteps      | 3840          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3290015e+23 |\n",
      "|    clip_fraction        | 0.893         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | 0.429         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | -0.151        |\n",
      "|    n_updates            | 140           |\n",
      "|    policy_gradient_loss | 1.36e+13      |\n",
      "|    value_loss           | 0.0597        |\n",
      "-------------------------------------------\n",
      "Step: 300, MSE: 0.003906, PSNR: 23.410423, PSNR Diff: -0.944292, Changes: 5, Reward: -6.61, 08:30:27\n",
      "Episode failed: PSNR Diff -1.002802 < -1 at step 318\n",
      "Initial MSE: 0.001912, Initial PSNR: 24.112362, 08:30:27\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.001912, Initial PSNR: 24.112362, 2024-12-23 08:30:27.453843\n",
      "Episode failed: PSNR Diff -1.010946 < -1 at step 80\n",
      "Initial MSE: 0.007060, Initial PSNR: 21.128910, 08:30:28\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.007060, Initial PSNR: 21.128910, 2024-12-23 08:30:28.991097\n",
      "Step: 100, MSE: 0.007499, PSNR: 20.866829, PSNR Diff: -0.262081, Changes: 5, Reward: -1.83, 08:30:31\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 233         |\n",
      "|    ep_rew_mean          | -1.01e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 209         |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 811125440.0 |\n",
      "|    clip_fraction        | 0.886       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.09e+04   |\n",
      "|    explained_variance   | -0.0848     |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 4.52e+05    |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | 1.63e+10    |\n",
      "|    value_loss           | 0.0561      |\n",
      "-----------------------------------------\n",
      "Step: 200, MSE: 0.007932, PSNR: 20.623375, PSNR Diff: -0.505535, Changes: 2, Reward: -3.54, 08:30:40\n",
      "Step: 300, MSE: 0.008396, PSNR: 20.376146, PSNR Diff: -0.752764, Changes: 3, Reward: -5.27, 08:30:42\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 233           |\n",
      "|    ep_rew_mean          | -1.01e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 222           |\n",
      "|    total_timesteps      | 4352          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6923475e+28 |\n",
      "|    clip_fraction        | 0.894         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | 0.263         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 9.53e+27      |\n",
      "|    n_updates            | 160           |\n",
      "|    policy_gradient_loss | 2.38e+26      |\n",
      "|    value_loss           | 0.0467        |\n",
      "-------------------------------------------\n",
      "Step: 400, MSE: 0.008870, PSNR: 20.137611, PSNR Diff: -0.991299, Changes: 3, Reward: -6.94, 08:30:53\n",
      "Episode failed: PSNR Diff -1.002747 < -1 at step 407\n",
      "Initial MSE: 0.002295, Initial PSNR: 25.570395, 08:30:53\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002295, Initial PSNR: 25.570395, 2024-12-23 08:30:53.746479\n",
      "Episode failed: PSNR Diff -1.004869 < -1 at step 80\n",
      "Initial MSE: 0.001913, Initial PSNR: 24.205561, 08:30:55\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.001913, Initial PSNR: 24.205561, 2024-12-23 08:30:55.473967\n",
      "Step: 100, MSE: 0.002232, PSNR: 23.535910, PSNR Diff: -0.669651, Changes: 7, Reward: -4.69, 08:30:57\n",
      "Episode failed: PSNR Diff -1.008043 < -1 at step 157\n",
      "Initial MSE: 0.002157, Initial PSNR: 23.968456, 08:30:58\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002157, Initial PSNR: 23.968456, 2024-12-23 08:30:58.676460\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 230           |\n",
      "|    ep_rew_mean          | -999          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 236           |\n",
      "|    total_timesteps      | 4608          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 12449757000.0 |\n",
      "|    clip_fraction        | 0.888         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | -0.978        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 3.13e+05      |\n",
      "|    n_updates            | 170           |\n",
      "|    policy_gradient_loss | 1.24e+10      |\n",
      "|    value_loss           | 0.0635        |\n",
      "-------------------------------------------\n",
      "Episode failed: PSNR Diff -1.002975 < -1 at step 92\n",
      "Initial MSE: 0.003407, Initial PSNR: 24.076788, 08:31:08\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.003407, Initial PSNR: 24.076788, 2024-12-23 08:31:08.967745\n",
      "Step: 100, MSE: 0.003761, PSNR: 23.648014, PSNR Diff: -0.428774, Changes: 6, Reward: -3.00, 08:31:11\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 224           |\n",
      "|    ep_rew_mean          | -976          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 19            |\n",
      "|    time_elapsed         | 250           |\n",
      "|    total_timesteps      | 4864          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4491446e+27 |\n",
      "|    clip_fraction        | 0.889         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | 0.487         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | -0.116        |\n",
      "|    n_updates            | 180           |\n",
      "|    policy_gradient_loss | 8.34e+24      |\n",
      "|    value_loss           | 0.0691        |\n",
      "-------------------------------------------\n",
      "Step: 200, MSE: 0.004061, PSNR: 23.314522, PSNR Diff: -0.762266, Changes: 3, Reward: -5.34, 08:31:21\n",
      "Episode failed: PSNR Diff -1.005640 < -1 at step 261\n",
      "Initial MSE: 0.005135, Initial PSNR: 22.894939, 08:31:23\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.005135, Initial PSNR: 22.894939, 2024-12-23 08:31:23.134467\n",
      "Step: 100, MSE: 0.005321, PSNR: 22.739811, PSNR Diff: -0.155128, Changes: 5, Reward: -1.09, 08:31:25\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 226           |\n",
      "|    ep_rew_mean          | -981          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 264           |\n",
      "|    total_timesteps      | 5120          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4584842e+22 |\n",
      "|    clip_fraction        | 0.885         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | 0.228         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | -0.14         |\n",
      "|    n_updates            | 190           |\n",
      "|    policy_gradient_loss | 1.89e+16      |\n",
      "|    value_loss           | 0.123         |\n",
      "-------------------------------------------\n",
      "Step: 200, MSE: 0.005483, PSNR: 22.610180, PSNR Diff: -0.284760, Changes: 3, Reward: -1.99, 08:31:35\n",
      "Step: 300, MSE: 0.005656, PSNR: 22.474712, PSNR Diff: -0.420227, Changes: 5, Reward: -2.94, 08:31:37\n",
      "Step: 400, MSE: 0.005841, PSNR: 22.335243, PSNR Diff: -0.559696, Changes: 7, Reward: -3.92, 08:31:39\n",
      "----------------------------------------------\n",
      "| rollout/                |                  |\n",
      "|    ep_len_mean          | 226              |\n",
      "|    ep_rew_mean          | -981             |\n",
      "| time/                   |                  |\n",
      "|    fps                  | 19               |\n",
      "|    iterations           | 21               |\n",
      "|    time_elapsed         | 277              |\n",
      "|    total_timesteps      | 5376             |\n",
      "| train/                  |                  |\n",
      "|    approx_kl            | 64054815000000.0 |\n",
      "|    clip_fraction        | 0.888            |\n",
      "|    clip_range           | 0.2              |\n",
      "|    entropy_loss         | -9.09e+04        |\n",
      "|    explained_variance   | -9.12            |\n",
      "|    learning_rate        | 1e-05            |\n",
      "|    loss                 | 0.0279           |\n",
      "|    n_updates            | 200              |\n",
      "|    policy_gradient_loss | 1.83e+09         |\n",
      "|    value_loss           | 0.0607           |\n",
      "----------------------------------------------\n",
      "Step: 500, MSE: 0.006039, PSNR: 22.190569, PSNR Diff: -0.704370, Changes: 5, Reward: -4.93, 08:31:50\n",
      "Step: 600, MSE: 0.006212, PSNR: 22.067753, PSNR Diff: -0.827187, Changes: 4, Reward: -5.79, 08:31:52\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 226           |\n",
      "|    ep_rew_mean          | -981          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 22            |\n",
      "|    time_elapsed         | 291           |\n",
      "|    total_timesteps      | 5632          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3869415e+20 |\n",
      "|    clip_fraction        | 0.889         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | -2.6          |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 3.64e+20      |\n",
      "|    n_updates            | 210           |\n",
      "|    policy_gradient_loss | 9.1e+18       |\n",
      "|    value_loss           | 0.0156        |\n",
      "-------------------------------------------\n",
      "Step: 700, MSE: 0.006421, PSNR: 21.924122, PSNR Diff: -0.970818, Changes: 6, Reward: -6.80, 08:32:03\n",
      "Episode failed: PSNR Diff -1.001745 < -1 at step 720\n",
      "Initial MSE: 0.002579, Initial PSNR: 25.885078, 08:32:03\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002579, Initial PSNR: 25.885078, 2024-12-23 08:32:03.556170\n",
      "Step: 100, MSE: 0.002682, PSNR: 25.716171, PSNR Diff: -0.168907, Changes: 3, Reward: -1.18, 08:32:05\n",
      "Step: 200, MSE: 0.002776, PSNR: 25.565443, PSNR Diff: -0.319635, Changes: 5, Reward: -2.24, 08:32:07\n",
      "------------------------------------------------\n",
      "| rollout/                |                    |\n",
      "|    ep_len_mean          | 247                |\n",
      "|    ep_rew_mean          | -1.06e+03          |\n",
      "| time/                   |                    |\n",
      "|    fps                  | 19                 |\n",
      "|    iterations           | 23                 |\n",
      "|    time_elapsed         | 305                |\n",
      "|    total_timesteps      | 5888               |\n",
      "| train/                  |                    |\n",
      "|    approx_kl            | 7234539600000000.0 |\n",
      "|    clip_fraction        | 0.891              |\n",
      "|    clip_range           | 0.2                |\n",
      "|    entropy_loss         | -9.09e+04          |\n",
      "|    explained_variance   | 0.36               |\n",
      "|    learning_rate        | 1e-05              |\n",
      "|    loss                 | 1.14e+03           |\n",
      "|    n_updates            | 220                |\n",
      "|    policy_gradient_loss | 2.5e+11            |\n",
      "|    value_loss           | 0.0613             |\n",
      "------------------------------------------------\n",
      "Step: 300, MSE: 0.002865, PSNR: 25.427999, PSNR Diff: -0.457079, Changes: 7, Reward: -3.20, 08:32:17\n",
      "Step: 400, MSE: 0.002982, PSNR: 25.255302, PSNR Diff: -0.629776, Changes: 7, Reward: -4.41, 08:32:19\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 247         |\n",
      "|    ep_rew_mean          | -1.06e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 318         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 182314620.0 |\n",
      "|    clip_fraction        | 0.892       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.09e+04   |\n",
      "|    explained_variance   | 0.801       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.67e+08    |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | 2.08e+11    |\n",
      "|    value_loss           | 0.0761      |\n",
      "-----------------------------------------\n",
      "Step: 500, MSE: 0.003073, PSNR: 25.123856, PSNR Diff: -0.761223, Changes: 4, Reward: -5.33, 08:32:30\n",
      "Step: 600, MSE: 0.003171, PSNR: 24.988291, PSNR Diff: -0.896788, Changes: 6, Reward: -6.28, 08:32:32\n",
      "Episode failed: PSNR Diff -1.001209 < -1 at step 660\n",
      "Initial MSE: 0.002268, Initial PSNR: 23.173620, 08:32:33\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002268, Initial PSNR: 23.173620, 2024-12-23 08:32:33.385131\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 264          |\n",
      "|    ep_rew_mean          | -1.12e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 332          |\n",
      "|    total_timesteps      | 6400         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.054061e+18 |\n",
      "|    clip_fraction        | 0.888        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.09e+04    |\n",
      "|    explained_variance   | -1.44        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 5.42e+05     |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | 1.46e+17     |\n",
      "|    value_loss           | 0.0476       |\n",
      "------------------------------------------\n",
      "Step: 100, MSE: 0.002851, PSNR: 22.179939, PSNR Diff: -0.993681, Changes: 3, Reward: -6.96, 08:32:43\n",
      "Episode failed: PSNR Diff -1.007696 < -1 at step 101\n",
      "Initial MSE: 0.000576, Initial PSNR: 26.342800, 08:32:43\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.000576, Initial PSNR: 26.342800, 2024-12-23 08:32:44.001596\n",
      "Step: 100, MSE: 0.000605, PSNR: 26.127527, PSNR Diff: -0.215273, Changes: 4, Reward: -1.51, 08:32:45\n",
      "Step: 200, MSE: 0.000635, PSNR: 25.920527, PSNR Diff: -0.422274, Changes: 5, Reward: -2.96, 08:32:47\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 258          |\n",
      "|    ep_rew_mean          | -1.09e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 345          |\n",
      "|    total_timesteps      | 6656         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.874074e+22 |\n",
      "|    clip_fraction        | 0.885        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.09e+04    |\n",
      "|    explained_variance   | 0.788        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | -0.00974     |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | 1.58e+12     |\n",
      "|    value_loss           | 0.0914       |\n",
      "------------------------------------------\n",
      "Step: 300, MSE: 0.000669, PSNR: 25.688446, PSNR Diff: -0.654354, Changes: 3, Reward: -4.58, 08:32:57\n",
      "Step: 400, MSE: 0.000705, PSNR: 25.462065, PSNR Diff: -0.880735, Changes: 8, Reward: -6.17, 08:32:58\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 258         |\n",
      "|    ep_rew_mean          | -1.09e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 357         |\n",
      "|    total_timesteps      | 6912        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 329622460.0 |\n",
      "|    clip_fraction        | 0.893       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.09e+04   |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | -0.154      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | 4.41e+12    |\n",
      "|    value_loss           | 0.0456      |\n",
      "-----------------------------------------\n",
      "Episode failed: PSNR Diff -1.000021 < -1 at step 491\n",
      "Initial MSE: 0.003015, Initial PSNR: 23.521301, 08:33:09\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.003015, Initial PSNR: 23.521301, 2024-12-23 08:33:09.837515\n",
      "Step: 100, MSE: 0.003638, PSNR: 22.705322, PSNR Diff: -0.815979, Changes: 5, Reward: -5.71, 08:33:11\n",
      "Episode failed: PSNR Diff -1.004295 < -1 at step 130\n",
      "Initial MSE: 0.005304, Initial PSNR: 21.392305, 08:33:12\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.005304, Initial PSNR: 21.392305, 2024-12-23 08:33:12.544590\n",
      "----------------------------------------------\n",
      "| rollout/                |                  |\n",
      "|    ep_len_mean          | 262              |\n",
      "|    ep_rew_mean          | -1.11e+03        |\n",
      "| time/                   |                  |\n",
      "|    fps                  | 19               |\n",
      "|    iterations           | 28               |\n",
      "|    time_elapsed         | 372              |\n",
      "|    total_timesteps      | 7168             |\n",
      "| train/                  |                  |\n",
      "|    approx_kl            | 13745283000000.0 |\n",
      "|    clip_fraction        | 0.888            |\n",
      "|    clip_range           | 0.2              |\n",
      "|    entropy_loss         | -9.09e+04        |\n",
      "|    explained_variance   | -3.38            |\n",
      "|    learning_rate        | 1e-05            |\n",
      "|    loss                 | -0.00385         |\n",
      "|    n_updates            | 270              |\n",
      "|    policy_gradient_loss | 3.1e+09          |\n",
      "|    value_loss           | 0.0643           |\n",
      "----------------------------------------------\n",
      "Step: 100, MSE: 0.005564, PSNR: 21.184195, PSNR Diff: -0.208111, Changes: 4, Reward: -1.46, 08:33:22\n",
      "Step: 200, MSE: 0.005757, PSNR: 21.036188, PSNR Diff: -0.356117, Changes: 6, Reward: -2.49, 08:33:24\n",
      "Step: 300, MSE: 0.005973, PSNR: 20.876425, PSNR Diff: -0.515881, Changes: 2, Reward: -3.61, 08:33:26\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 262           |\n",
      "|    ep_rew_mean          | -1.11e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 29            |\n",
      "|    time_elapsed         | 385           |\n",
      "|    total_timesteps      | 7424          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.6604633e+18 |\n",
      "|    clip_fraction        | 0.894         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | 0.639         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | -0.104        |\n",
      "|    n_updates            | 280           |\n",
      "|    policy_gradient_loss | 2.26e+16      |\n",
      "|    value_loss           | 0.0413        |\n",
      "-------------------------------------------\n",
      "Step: 400, MSE: 0.006183, PSNR: 20.726002, PSNR Diff: -0.666304, Changes: 4, Reward: -4.66, 08:33:36\n",
      "Step: 500, MSE: 0.006399, PSNR: 20.576931, PSNR Diff: -0.815374, Changes: 5, Reward: -5.71, 08:33:38\n",
      "Step: 600, MSE: 0.006580, PSNR: 20.456018, PSNR Diff: -0.936287, Changes: 7, Reward: -6.55, 08:33:40\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 262           |\n",
      "|    ep_rew_mean          | -1.11e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 30            |\n",
      "|    time_elapsed         | 398           |\n",
      "|    total_timesteps      | 7680          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9823688e+22 |\n",
      "|    clip_fraction        | 0.887         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | 0.485         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 427           |\n",
      "|    n_updates            | 290           |\n",
      "|    policy_gradient_loss | 3.69e+21      |\n",
      "|    value_loss           | 0.0294        |\n",
      "-------------------------------------------\n",
      "Episode failed: PSNR Diff -1.002632 < -1 at step 634\n",
      "Initial MSE: 0.007411, Initial PSNR: 21.300953, 08:33:50\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.007411, Initial PSNR: 21.300953, 2024-12-23 08:33:50.235710\n",
      "Step: 100, MSE: 0.008192, PSNR: 20.866144, PSNR Diff: -0.434809, Changes: 4, Reward: -3.04, 08:33:52\n",
      "Step: 200, MSE: 0.009066, PSNR: 20.425785, PSNR Diff: -0.875168, Changes: 5, Reward: -6.13, 08:33:54\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 275           |\n",
      "|    ep_rew_mean          | -1.16e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 31            |\n",
      "|    time_elapsed         | 412           |\n",
      "|    total_timesteps      | 7936          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6792845e+19 |\n",
      "|    clip_fraction        | 0.876         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | 0.434         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 3.49e+14      |\n",
      "|    n_updates            | 300           |\n",
      "|    policy_gradient_loss | 5.34e+18      |\n",
      "|    value_loss           | 0.0419        |\n",
      "-------------------------------------------\n",
      "Episode failed: PSNR Diff -1.000048 < -1 at step 233\n",
      "Initial MSE: 0.002798, Initial PSNR: 24.406330, 08:34:03\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002798, Initial PSNR: 24.406330, 2024-12-23 08:34:03.328038\n",
      "Step: 100, MSE: 0.002973, PSNR: 24.141825, PSNR Diff: -0.264505, Changes: 4, Reward: -1.85, 08:34:04\n",
      "Step: 200, MSE: 0.003116, PSNR: 23.938454, PSNR Diff: -0.467876, Changes: 6, Reward: -3.28, 08:34:06\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 274           |\n",
      "|    ep_rew_mean          | -1.15e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 32            |\n",
      "|    time_elapsed         | 425           |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.3615766e+25 |\n",
      "|    clip_fraction        | 0.883         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | 0.774         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | -0.134        |\n",
      "|    n_updates            | 310           |\n",
      "|    policy_gradient_loss | 5.93e+23      |\n",
      "|    value_loss           | 0.0647        |\n",
      "-------------------------------------------\n",
      "Step: 300, MSE: 0.003262, PSNR: 23.739288, PSNR Diff: -0.667042, Changes: 6, Reward: -4.67, 08:34:17\n",
      "Step: 400, MSE: 0.003456, PSNR: 23.488380, PSNR Diff: -0.917950, Changes: 6, Reward: -6.43, 08:34:19\n",
      "Episode failed: PSNR Diff -1.000826 < -1 at step 449\n",
      "Initial MSE: 0.005146, Initial PSNR: 22.748283, 08:34:20\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.005146, Initial PSNR: 22.748283, 2024-12-23 08:34:20.054816\n",
      "-----------------------------------------------\n",
      "| rollout/                |                   |\n",
      "|    ep_len_mean          | 280               |\n",
      "|    ep_rew_mean          | -1.17e+03         |\n",
      "| time/                   |                   |\n",
      "|    fps                  | 19                |\n",
      "|    iterations           | 33                |\n",
      "|    time_elapsed         | 439               |\n",
      "|    total_timesteps      | 8448              |\n",
      "| train/                  |                   |\n",
      "|    approx_kl            | 317761600000000.0 |\n",
      "|    clip_fraction        | 0.891             |\n",
      "|    clip_range           | 0.2               |\n",
      "|    entropy_loss         | -9.09e+04         |\n",
      "|    explained_variance   | 0.291             |\n",
      "|    learning_rate        | 1e-05             |\n",
      "|    loss                 | 0.378             |\n",
      "|    n_updates            | 320               |\n",
      "|    policy_gradient_loss | 1.82e+09          |\n",
      "|    value_loss           | 0.031             |\n",
      "-----------------------------------------------\n",
      "Step: 100, MSE: 0.005826, PSNR: 22.209061, PSNR Diff: -0.539223, Changes: 5, Reward: -3.77, 08:34:30\n",
      "Step: 200, MSE: 0.006415, PSNR: 21.790539, PSNR Diff: -0.957745, Changes: 4, Reward: -6.70, 08:34:32\n",
      "Episode failed: PSNR Diff -1.000305 < -1 at step 210\n",
      "Initial MSE: 0.003060, Initial PSNR: 24.395752, 08:34:32\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.003060, Initial PSNR: 24.395752, 2024-12-23 08:34:32.809712\n",
      "Step: 100, MSE: 0.003371, PSNR: 23.976412, PSNR Diff: -0.419340, Changes: 4, Reward: -2.94, 08:34:34\n",
      "-----------------------------------------------\n",
      "| rollout/                |                   |\n",
      "|    ep_len_mean          | 277               |\n",
      "|    ep_rew_mean          | -1.17e+03         |\n",
      "| time/                   |                   |\n",
      "|    fps                  | 19                |\n",
      "|    iterations           | 34                |\n",
      "|    time_elapsed         | 452               |\n",
      "|    total_timesteps      | 8704              |\n",
      "| train/                  |                   |\n",
      "|    approx_kl            | 540547000000000.0 |\n",
      "|    clip_fraction        | 0.888             |\n",
      "|    clip_range           | 0.2               |\n",
      "|    entropy_loss         | -9.09e+04         |\n",
      "|    explained_variance   | 0.441             |\n",
      "|    learning_rate        | 1e-05             |\n",
      "|    loss                 | 1.84e+10          |\n",
      "|    n_updates            | 330               |\n",
      "|    policy_gradient_loss | 5.76e+11          |\n",
      "|    value_loss           | 0.0749            |\n",
      "-----------------------------------------------\n",
      "Step: 200, MSE: 0.003652, PSNR: 23.628677, PSNR Diff: -0.767075, Changes: 4, Reward: -5.37, 08:34:44\n",
      "Episode failed: PSNR Diff -1.002417 < -1 at step 265\n",
      "Initial MSE: 0.004084, Initial PSNR: 23.180096, 08:34:45\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.004084, Initial PSNR: 23.180096, 2024-12-23 08:34:45.986457\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 277           |\n",
      "|    ep_rew_mean          | -1.17e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 35            |\n",
      "|    time_elapsed         | 465           |\n",
      "|    total_timesteps      | 8960          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 11464988000.0 |\n",
      "|    clip_fraction        | 0.876         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | 0.787         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 0.0969        |\n",
      "|    n_updates            | 340           |\n",
      "|    policy_gradient_loss | 5.08e+10      |\n",
      "|    value_loss           | 0.0577        |\n",
      "-------------------------------------------\n",
      "Step: 100, MSE: 0.004452, PSNR: 22.805300, PSNR Diff: -0.374796, Changes: 6, Reward: -2.62, 08:34:56\n",
      "Step: 200, MSE: 0.004792, PSNR: 22.485598, PSNR Diff: -0.694498, Changes: 8, Reward: -4.86, 08:34:58\n",
      "Step: 300, MSE: 0.005138, PSNR: 22.182825, PSNR Diff: -0.997271, Changes: 5, Reward: -6.98, 08:34:59\n",
      "Episode failed: PSNR Diff -1.001553 < -1 at step 302\n",
      "Initial MSE: 0.002417, Initial PSNR: 24.186096, 08:34:59\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002417, Initial PSNR: 24.186096, 2024-12-23 08:34:59.993897\n",
      "------------------------------------------------\n",
      "| rollout/                |                    |\n",
      "|    ep_len_mean          | 278                |\n",
      "|    ep_rew_mean          | -1.17e+03          |\n",
      "| time/                   |                    |\n",
      "|    fps                  | 19                 |\n",
      "|    iterations           | 36                 |\n",
      "|    time_elapsed         | 478                |\n",
      "|    total_timesteps      | 9216               |\n",
      "| train/                  |                    |\n",
      "|    approx_kl            | 3580226200000000.0 |\n",
      "|    clip_fraction        | 0.887              |\n",
      "|    clip_range           | 0.2                |\n",
      "|    entropy_loss         | -9.09e+04          |\n",
      "|    explained_variance   | 0.183              |\n",
      "|    learning_rate        | 1e-05              |\n",
      "|    loss                 | 1.91e+06           |\n",
      "|    n_updates            | 350                |\n",
      "|    policy_gradient_loss | 9.64e+13           |\n",
      "|    value_loss           | 0.0431             |\n",
      "------------------------------------------------\n",
      "Episode failed: PSNR Diff -1.011223 < -1 at step 71\n",
      "Initial MSE: 0.002723, Initial PSNR: 23.922091, 08:35:09\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002723, Initial PSNR: 23.922091, 2024-12-23 08:35:09.908563\n",
      "Episode failed: PSNR Diff -1.003445 < -1 at step 77\n",
      "Initial MSE: 0.008781, Initial PSNR: 20.564693, 08:35:11\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.008781, Initial PSNR: 20.564693, 2024-12-23 08:35:11.422712\n",
      "Step: 100, MSE: 0.009264, PSNR: 20.331915, PSNR Diff: -0.232779, Changes: 6, Reward: -1.63, 08:35:13\n",
      "------------------------------------------------\n",
      "| rollout/                |                    |\n",
      "|    ep_len_mean          | 266                |\n",
      "|    ep_rew_mean          | -1.13e+03          |\n",
      "| time/                   |                    |\n",
      "|    fps                  | 19                 |\n",
      "|    iterations           | 37                 |\n",
      "|    time_elapsed         | 491                |\n",
      "|    total_timesteps      | 9472               |\n",
      "| train/                  |                    |\n",
      "|    approx_kl            | 9217822000000000.0 |\n",
      "|    clip_fraction        | 0.877              |\n",
      "|    clip_range           | 0.2                |\n",
      "|    entropy_loss         | -9.09e+04          |\n",
      "|    explained_variance   | 0.259              |\n",
      "|    learning_rate        | 1e-05              |\n",
      "|    loss                 | 1.13e+13           |\n",
      "|    n_updates            | 360                |\n",
      "|    policy_gradient_loss | 1.16e+14           |\n",
      "|    value_loss           | 0.0634             |\n",
      "------------------------------------------------\n",
      "Step: 200, MSE: 0.009682, PSNR: 20.140289, PSNR Diff: -0.424404, Changes: 5, Reward: -2.97, 08:35:22\n",
      "Step: 300, MSE: 0.010081, PSNR: 19.965158, PSNR Diff: -0.599535, Changes: 5, Reward: -4.20, 08:35:24\n",
      "Step: 400, MSE: 0.010543, PSNR: 19.770420, PSNR Diff: -0.794273, Changes: 5, Reward: -5.56, 08:35:26\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 266           |\n",
      "|    ep_rew_mean          | -1.13e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 38            |\n",
      "|    time_elapsed         | 504           |\n",
      "|    total_timesteps      | 9728          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0932068e+23 |\n",
      "|    clip_fraction        | 0.89          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | -0.571        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 0.057         |\n",
      "|    n_updates            | 370           |\n",
      "|    policy_gradient_loss | 2.08e+20      |\n",
      "|    value_loss           | 0.0468        |\n",
      "-------------------------------------------\n",
      "Episode failed: PSNR Diff -1.001684 < -1 at step 498\n",
      "Initial MSE: 0.003061, Initial PSNR: 24.357063, 08:35:37\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.003061, Initial PSNR: 24.357063, 2024-12-23 08:35:37.385543\n",
      "Step: 100, MSE: 0.003527, PSNR: 23.741722, PSNR Diff: -0.615341, Changes: 4, Reward: -4.31, 08:35:38\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 273         |\n",
      "|    ep_rew_mean          | -1.15e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 518         |\n",
      "|    total_timesteps      | 9984        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 889508900.0 |\n",
      "|    clip_fraction        | 0.892       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.09e+04   |\n",
      "|    explained_variance   | -0.652      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.99e+03    |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | 1.82e+13    |\n",
      "|    value_loss           | 0.0429      |\n",
      "-----------------------------------------\n",
      "Episode failed: PSNR Diff -1.004030 < -1 at step 184\n",
      "Initial MSE: 0.002478, Initial PSNR: 25.125654, 08:35:49\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002478, Initial PSNR: 25.125654, 2024-12-23 08:35:49.242239\n",
      "Step: 100, MSE: 0.002605, PSNR: 24.907955, PSNR Diff: -0.217699, Changes: 4, Reward: -1.52, 08:35:51\n",
      "Step: 200, MSE: 0.002678, PSNR: 24.787989, PSNR Diff: -0.337666, Changes: 3, Reward: -2.36, 08:35:53\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 270          |\n",
      "|    ep_rew_mean          | -1.14e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 531          |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4160327200.0 |\n",
      "|    clip_fraction        | 0.894        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.09e+04    |\n",
      "|    explained_variance   | 0.79         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 481          |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | 9.2e+10      |\n",
      "|    value_loss           | 0.0692       |\n",
      "------------------------------------------\n",
      "Step: 300, MSE: 0.002804, PSNR: 24.588814, PSNR Diff: -0.536840, Changes: 4, Reward: -3.76, 08:36:04\n",
      "Step: 400, MSE: 0.002919, PSNR: 24.414070, PSNR Diff: -0.711584, Changes: 7, Reward: -4.98, 08:36:06\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 270           |\n",
      "|    ep_rew_mean          | -1.14e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 41            |\n",
      "|    time_elapsed         | 545           |\n",
      "|    total_timesteps      | 10496         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4981899e+17 |\n",
      "|    clip_fraction        | 0.894         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | 0.416         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | -0.1          |\n",
      "|    n_updates            | 400           |\n",
      "|    policy_gradient_loss | 7.56e+11      |\n",
      "|    value_loss           | 0.0332        |\n",
      "-------------------------------------------\n",
      "Step: 500, MSE: 0.003058, PSNR: 24.211174, PSNR Diff: -0.914480, Changes: 4, Reward: -6.40, 08:36:16\n",
      "Episode failed: PSNR Diff -1.001116 < -1 at step 582\n",
      "Initial MSE: 0.000731, Initial PSNR: 26.151915, 08:36:18\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.000731, Initial PSNR: 26.151915, 2024-12-23 08:36:18.245123\n",
      "Step: 100, MSE: 0.000806, PSNR: 25.730316, PSNR Diff: -0.421598, Changes: 3, Reward: -2.95, 08:36:20\n",
      "------------------------------------------------\n",
      "| rollout/                |                    |\n",
      "|    ep_len_mean          | 279                |\n",
      "|    ep_rew_mean          | -1.17e+03          |\n",
      "| time/                   |                    |\n",
      "|    fps                  | 19                 |\n",
      "|    iterations           | 42                 |\n",
      "|    time_elapsed         | 559                |\n",
      "|    total_timesteps      | 10752              |\n",
      "| train/                  |                    |\n",
      "|    approx_kl            | 2367041300000000.0 |\n",
      "|    clip_fraction        | 0.886              |\n",
      "|    clip_range           | 0.2                |\n",
      "|    entropy_loss         | -9.09e+04          |\n",
      "|    explained_variance   | -1.62              |\n",
      "|    learning_rate        | 1e-05              |\n",
      "|    loss                 | 9.08e+07           |\n",
      "|    n_updates            | 410                |\n",
      "|    policy_gradient_loss | 3.16e+13           |\n",
      "|    value_loss           | 0.0463             |\n",
      "------------------------------------------------\n",
      "Step: 200, MSE: 0.000889, PSNR: 25.302055, PSNR Diff: -0.849859, Changes: 6, Reward: -5.95, 08:36:30\n",
      "Episode failed: PSNR Diff -1.003704 < -1 at step 241\n",
      "Initial MSE: 0.004443, Initial PSNR: 23.140408, 08:36:31\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.004443, Initial PSNR: 23.140408, 2024-12-23 08:36:31.071443\n",
      "Step: 100, MSE: 0.005533, PSNR: 22.187775, PSNR Diff: -0.952633, Changes: 5, Reward: -6.67, 08:36:32\n",
      "Episode failed: PSNR Diff -1.003082 < -1 at step 104\n",
      "Initial MSE: 0.001704, Initial PSNR: 26.637392, 08:36:33\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.001704, Initial PSNR: 26.637392, 2024-12-23 08:36:33.208089\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 273           |\n",
      "|    ep_rew_mean          | -1.15e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 43            |\n",
      "|    time_elapsed         | 572           |\n",
      "|    total_timesteps      | 11008         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 41549650000.0 |\n",
      "|    clip_fraction        | 0.888         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | -3.19         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 4.47e+10      |\n",
      "|    n_updates            | 420           |\n",
      "|    policy_gradient_loss | 5.48e+10      |\n",
      "|    value_loss           | 0.0734        |\n",
      "-------------------------------------------\n",
      "Step: 100, MSE: 0.001882, PSNR: 26.205557, PSNR Diff: -0.431835, Changes: 6, Reward: -3.02, 08:36:42\n",
      "Step: 200, MSE: 0.002068, PSNR: 25.796696, PSNR Diff: -0.840696, Changes: 6, Reward: -5.88, 08:36:44\n",
      "Episode failed: PSNR Diff -1.003372 < -1 at step 236\n",
      "Initial MSE: 0.003496, Initial PSNR: 24.145239, 08:36:45\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.003496, Initial PSNR: 24.145239, 2024-12-23 08:36:45.322013\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 272           |\n",
      "|    ep_rew_mean          | -1.15e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 44            |\n",
      "|    time_elapsed         | 584           |\n",
      "|    total_timesteps      | 11264         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9178609e+24 |\n",
      "|    clip_fraction        | 0.89          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | -0.239        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | -0.152        |\n",
      "|    n_updates            | 430           |\n",
      "|    policy_gradient_loss | 4.21e+21      |\n",
      "|    value_loss           | 0.0486        |\n",
      "-------------------------------------------\n",
      "Step: 100, MSE: 0.003947, PSNR: 23.619064, PSNR Diff: -0.526175, Changes: 5, Reward: -3.68, 08:36:55\n",
      "Step: 200, MSE: 0.004334, PSNR: 23.212757, PSNR Diff: -0.932482, Changes: 3, Reward: -6.53, 08:36:57\n",
      "Episode failed: PSNR Diff -1.001261 < -1 at step 216\n",
      "Initial MSE: 0.001475, Initial PSNR: 24.687796, 08:36:57\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.001475, Initial PSNR: 24.687796, 2024-12-23 08:36:57.868265\n",
      "Step: 100, MSE: 0.001647, PSNR: 24.208340, PSNR Diff: -0.479456, Changes: 4, Reward: -3.36, 08:36:59\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 271          |\n",
      "|    ep_rew_mean          | -1.15e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 598          |\n",
      "|    total_timesteps      | 11520        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1386693100.0 |\n",
      "|    clip_fraction        | 0.893        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.09e+04    |\n",
      "|    explained_variance   | 0.751        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 3.31e+03     |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | 1.5e+09      |\n",
      "|    value_loss           | 0.064        |\n",
      "------------------------------------------\n",
      "Step: 200, MSE: 0.001815, PSNR: 23.786886, PSNR Diff: -0.900909, Changes: 6, Reward: -6.31, 08:37:09\n",
      "Episode failed: PSNR Diff -1.001898 < -1 at step 220\n",
      "Initial MSE: 0.003414, Initial PSNR: 24.633181, 08:37:10\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.003414, Initial PSNR: 24.633181, 2024-12-23 08:37:10.262455\n",
      "Step: 100, MSE: 0.003833, PSNR: 24.130913, PSNR Diff: -0.502268, Changes: 8, Reward: -3.52, 08:37:12\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 270       |\n",
      "|    ep_rew_mean          | -1.14e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 19        |\n",
      "|    iterations           | 46        |\n",
      "|    time_elapsed         | 611       |\n",
      "|    total_timesteps      | 11776     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 4785565.0 |\n",
      "|    clip_fraction        | 0.887     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -9.09e+04 |\n",
      "|    explained_variance   | -8.15     |\n",
      "|    learning_rate        | 1e-05     |\n",
      "|    loss                 | 6.16e+06  |\n",
      "|    n_updates            | 450       |\n",
      "|    policy_gradient_loss | 6.8e+08   |\n",
      "|    value_loss           | 0.0941    |\n",
      "---------------------------------------\n",
      "Step: 200, MSE: 0.004235, PSNR: 23.696884, PSNR Diff: -0.936296, Changes: 3, Reward: -6.55, 08:37:22\n",
      "Episode failed: PSNR Diff -1.002962 < -1 at step 220\n",
      "Initial MSE: 0.004700, Initial PSNR: 22.495375, 08:37:22\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.004700, Initial PSNR: 22.495375, 2024-12-23 08:37:22.836438\n",
      "Step: 100, MSE: 0.005145, PSNR: 22.102852, PSNR Diff: -0.392523, Changes: 5, Reward: -2.75, 08:37:23\n",
      "Step: 200, MSE: 0.005573, PSNR: 21.755707, PSNR Diff: -0.739668, Changes: 5, Reward: -5.18, 08:37:24\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 269           |\n",
      "|    ep_rew_mean          | -1.14e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 47            |\n",
      "|    time_elapsed         | 622           |\n",
      "|    total_timesteps      | 12032         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 68853380000.0 |\n",
      "|    clip_fraction        | 0.889         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | -4.04         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 0.173         |\n",
      "|    n_updates            | 460           |\n",
      "|    policy_gradient_loss | 3.21e+14      |\n",
      "|    value_loss           | 0.0477        |\n",
      "-------------------------------------------\n",
      "Episode failed: PSNR Diff -1.000231 < -1 at step 272\n",
      "Initial MSE: 0.001352, Initial PSNR: 27.368942, 08:37:34\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.001352, Initial PSNR: 27.368942, 2024-12-23 08:37:34.307119\n",
      "Step: 100, MSE: 0.001481, PSNR: 26.973841, PSNR Diff: -0.395102, Changes: 4, Reward: -2.77, 08:37:35\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 269           |\n",
      "|    ep_rew_mean          | -1.14e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 48            |\n",
      "|    time_elapsed         | 635           |\n",
      "|    total_timesteps      | 12288         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1718348e+23 |\n",
      "|    clip_fraction        | 0.891         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | 0.751         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | -0.0681       |\n",
      "|    n_updates            | 470           |\n",
      "|    policy_gradient_loss | 4.36e+18      |\n",
      "|    value_loss           | 0.0438        |\n",
      "-------------------------------------------\n",
      "Step: 200, MSE: 0.001599, PSNR: 26.639324, PSNR Diff: -0.729618, Changes: 5, Reward: -5.11, 08:37:45\n",
      "Episode failed: PSNR Diff -1.000589 < -1 at step 297\n",
      "Initial MSE: 0.002758, Initial PSNR: 24.192589, 08:37:47\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002758, Initial PSNR: 24.192589, 2024-12-23 08:37:47.525448\n",
      "Episode failed: PSNR Diff -1.004408 < -1 at step 83\n",
      "Initial MSE: 0.001855, Initial PSNR: 25.506069, 08:37:48\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.001855, Initial PSNR: 25.506069, 2024-12-23 08:37:48.947658\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 266         |\n",
      "|    ep_rew_mean          | -1.13e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 647         |\n",
      "|    total_timesteps      | 12544       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 232917100.0 |\n",
      "|    clip_fraction        | 0.896       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.09e+04   |\n",
      "|    explained_variance   | -0.379      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 2.27e+08    |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | 5.7e+06     |\n",
      "|    value_loss           | 0.0549      |\n",
      "-----------------------------------------\n",
      "Step: 100, MSE: 0.002138, PSNR: 24.887547, PSNR Diff: -0.618523, Changes: 5, Reward: -4.33, 08:37:58\n",
      "Episode failed: PSNR Diff -1.000872 < -1 at step 166\n",
      "Initial MSE: 0.003717, Initial PSNR: 23.551502, 08:37:59\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.003717, Initial PSNR: 23.551502, 2024-12-23 08:37:59.766364\n",
      "Step: 100, MSE: 0.004125, PSNR: 23.099243, PSNR Diff: -0.452259, Changes: 3, Reward: -3.17, 08:38:01\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 264         |\n",
      "|    ep_rew_mean          | -1.12e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 660         |\n",
      "|    total_timesteps      | 12800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 846105340.0 |\n",
      "|    clip_fraction        | 0.888       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.09e+04   |\n",
      "|    explained_variance   | 0.0687      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | -0.0224     |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | 1.31e+09    |\n",
      "|    value_loss           | 0.0545      |\n",
      "-----------------------------------------\n",
      "Step: 200, MSE: 0.004510, PSNR: 22.711508, PSNR Diff: -0.839994, Changes: 3, Reward: -5.88, 08:38:11\n",
      "Episode failed: PSNR Diff -1.008785 < -1 at step 233\n",
      "Initial MSE: 0.007424, Initial PSNR: 21.293495, 08:38:12\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.007424, Initial PSNR: 21.293495, 2024-12-23 08:38:12.446356\n",
      "Step: 100, MSE: 0.008198, PSNR: 20.862862, PSNR Diff: -0.430634, Changes: 6, Reward: -3.01, 08:38:14\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 263           |\n",
      "|    ep_rew_mean          | -1.12e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 51            |\n",
      "|    time_elapsed         | 673           |\n",
      "|    total_timesteps      | 13056         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0323695e+18 |\n",
      "|    clip_fraction        | 0.89          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | 0.714         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | -0.109        |\n",
      "|    n_updates            | 500           |\n",
      "|    policy_gradient_loss | 1.15e+16      |\n",
      "|    value_loss           | 0.0527        |\n",
      "-------------------------------------------\n",
      "Step: 200, MSE: 0.008844, PSNR: 20.533278, PSNR Diff: -0.760218, Changes: 4, Reward: -5.32, 08:38:24\n",
      "Episode failed: PSNR Diff -1.003300 < -1 at step 283\n",
      "Initial MSE: 0.006045, Initial PSNR: 22.186392, 08:38:26\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.006045, Initial PSNR: 22.186392, 2024-12-23 08:38:26.327850\n",
      "Step: 100, MSE: 0.006868, PSNR: 21.631947, PSNR Diff: -0.554445, Changes: 4, Reward: -3.88, 08:38:28\n",
      "----------------------------------------------\n",
      "| rollout/                |                  |\n",
      "|    ep_len_mean          | 263              |\n",
      "|    ep_rew_mean          | -1.12e+03        |\n",
      "| time/                   |                  |\n",
      "|    fps                  | 19               |\n",
      "|    iterations           | 52               |\n",
      "|    time_elapsed         | 686              |\n",
      "|    total_timesteps      | 13312            |\n",
      "| train/                  |                  |\n",
      "|    approx_kl            | 23566240000000.0 |\n",
      "|    clip_fraction        | 0.885            |\n",
      "|    clip_range           | 0.2              |\n",
      "|    entropy_loss         | -9.09e+04        |\n",
      "|    explained_variance   | -0.225           |\n",
      "|    learning_rate        | 1e-05            |\n",
      "|    loss                 | 0.0466           |\n",
      "|    n_updates            | 510              |\n",
      "|    policy_gradient_loss | 3.67e+05         |\n",
      "|    value_loss           | 0.0672           |\n",
      "----------------------------------------------\n",
      "Episode failed: PSNR Diff -1.006027 < -1 at step 200\n",
      "Initial MSE: 0.006182, Initial PSNR: 20.319016, 08:38:38\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.006182, Initial PSNR: 20.319016, 2024-12-23 08:38:38.699838\n",
      "Step: 100, MSE: 0.006646, PSNR: 20.004707, PSNR Diff: -0.314308, Changes: 5, Reward: -2.20, 08:38:40\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 262           |\n",
      "|    ep_rew_mean          | -1.12e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 53            |\n",
      "|    time_elapsed         | 700           |\n",
      "|    total_timesteps      | 13568         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.2777895e+22 |\n",
      "|    clip_fraction        | 0.887         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | 0.69          |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 4.97e+07      |\n",
      "|    n_updates            | 520           |\n",
      "|    policy_gradient_loss | 1.46e+21      |\n",
      "|    value_loss           | 0.0461        |\n",
      "-------------------------------------------\n",
      "Step: 200, MSE: 0.007081, PSNR: 19.729292, PSNR Diff: -0.589724, Changes: 5, Reward: -4.13, 08:38:50\n",
      "Step: 300, MSE: 0.007505, PSNR: 19.476892, PSNR Diff: -0.842123, Changes: 5, Reward: -5.89, 08:38:52\n",
      "Episode failed: PSNR Diff -1.000776 < -1 at step 371\n",
      "Initial MSE: 0.005509, Initial PSNR: 22.241707, 08:38:54\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.005509, Initial PSNR: 22.241707, 2024-12-23 08:38:54.019811\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 264         |\n",
      "|    ep_rew_mean          | -1.12e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 713         |\n",
      "|    total_timesteps      | 13824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 355997570.0 |\n",
      "|    clip_fraction        | 0.894       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.09e+04   |\n",
      "|    explained_variance   | -0.3        |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | -0.12       |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | 1.1e+13     |\n",
      "|    value_loss           | 0.0537      |\n",
      "-----------------------------------------\n",
      "Step: 100, MSE: 0.005971, PSNR: 21.891897, PSNR Diff: -0.349810, Changes: 5, Reward: -2.45, 08:39:04\n",
      "Step: 200, MSE: 0.006472, PSNR: 21.541842, PSNR Diff: -0.699865, Changes: 7, Reward: -4.90, 08:39:06\n",
      "Step: 300, MSE: 0.006916, PSNR: 21.253857, PSNR Diff: -0.987850, Changes: 4, Reward: -6.91, 08:39:08\n",
      "Episode failed: PSNR Diff -1.004330 < -1 at step 304\n",
      "Initial MSE: 0.002630, Initial PSNR: 24.237015, 08:39:08\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002630, Initial PSNR: 24.237015, 2024-12-23 08:39:08.426597\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 265          |\n",
      "|    ep_rew_mean          | -1.13e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 726          |\n",
      "|    total_timesteps      | 14080        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.341876e+16 |\n",
      "|    clip_fraction        | 0.895        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.09e+04    |\n",
      "|    explained_variance   | -4.46        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | -0.179       |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | 8.2e+11      |\n",
      "|    value_loss           | 0.0453       |\n",
      "------------------------------------------\n",
      "Episode failed: PSNR Diff -1.003883 < -1 at step 95\n",
      "Initial MSE: 0.010428, Initial PSNR: 19.817806, 08:39:18\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.010428, Initial PSNR: 19.817806, 2024-12-23 08:39:18.673723\n",
      "Step: 100, MSE: 0.010687, PSNR: 19.711540, PSNR Diff: -0.106266, Changes: 2, Reward: -0.74, 08:39:20\n",
      "------------------------------------------------\n",
      "| rollout/                |                    |\n",
      "|    ep_len_mean          | 262                |\n",
      "|    ep_rew_mean          | -1.12e+03          |\n",
      "| time/                   |                    |\n",
      "|    fps                  | 19                 |\n",
      "|    iterations           | 56                 |\n",
      "|    time_elapsed         | 739                |\n",
      "|    total_timesteps      | 14336              |\n",
      "| train/                  |                    |\n",
      "|    approx_kl            | 1098159600000000.0 |\n",
      "|    clip_fraction        | 0.892              |\n",
      "|    clip_range           | 0.2                |\n",
      "|    entropy_loss         | -9.09e+04          |\n",
      "|    explained_variance   | -0.513             |\n",
      "|    learning_rate        | 1e-05              |\n",
      "|    loss                 | 2.3e+15            |\n",
      "|    n_updates            | 550                |\n",
      "|    policy_gradient_loss | 6.56e+13           |\n",
      "|    value_loss           | 0.0387             |\n",
      "------------------------------------------------\n",
      "Step: 200, MSE: 0.010914, PSNR: 19.619987, PSNR Diff: -0.197819, Changes: 3, Reward: -1.38, 08:39:30\n",
      "Step: 300, MSE: 0.011095, PSNR: 19.548822, PSNR Diff: -0.268984, Changes: 4, Reward: -1.88, 08:39:31\n",
      "Step: 400, MSE: 0.011302, PSNR: 19.468534, PSNR Diff: -0.349272, Changes: 4, Reward: -2.44, 08:39:32\n",
      "---------------------------------------------\n",
      "| rollout/                |                 |\n",
      "|    ep_len_mean          | 262             |\n",
      "|    ep_rew_mean          | -1.12e+03       |\n",
      "| time/                   |                 |\n",
      "|    fps                  | 19              |\n",
      "|    iterations           | 57              |\n",
      "|    time_elapsed         | 750             |\n",
      "|    total_timesteps      | 14592           |\n",
      "| train/                  |                 |\n",
      "|    approx_kl            | 6057223000000.0 |\n",
      "|    clip_fraction        | 0.892           |\n",
      "|    clip_range           | 0.2             |\n",
      "|    entropy_loss         | -9.09e+04       |\n",
      "|    explained_variance   | 0.944           |\n",
      "|    learning_rate        | 1e-05           |\n",
      "|    loss                 | -0.0594         |\n",
      "|    n_updates            | 560             |\n",
      "|    policy_gradient_loss | 5.7e+09         |\n",
      "|    value_loss           | 0.0235          |\n",
      "---------------------------------------------\n",
      "Step: 500, MSE: 0.011513, PSNR: 19.388052, PSNR Diff: -0.429754, Changes: 5, Reward: -3.01, 08:39:42\n",
      "Step: 600, MSE: 0.011770, PSNR: 19.292152, PSNR Diff: -0.525654, Changes: 6, Reward: -3.68, 08:39:44\n",
      "Step: 700, MSE: 0.012171, PSNR: 19.146799, PSNR Diff: -0.671007, Changes: 3, Reward: -4.70, 08:39:46\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 262          |\n",
      "|    ep_rew_mean          | -1.12e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 764          |\n",
      "|    total_timesteps      | 14848        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5460515000.0 |\n",
      "|    clip_fraction        | 0.889        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.09e+04    |\n",
      "|    explained_variance   | 0.215        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 38.2         |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | 8.82e+09     |\n",
      "|    value_loss           | 0.0191       |\n",
      "------------------------------------------\n",
      "Step: 800, MSE: 0.012385, PSNR: 19.071091, PSNR Diff: -0.746716, Changes: 2, Reward: -5.23, 08:39:57\n",
      "Step: 900, MSE: 0.012671, PSNR: 18.971903, PSNR Diff: -0.845903, Changes: 5, Reward: -5.92, 08:39:58\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 262          |\n",
      "|    ep_rew_mean          | -1.12e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 777          |\n",
      "|    total_timesteps      | 15104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8095149000.0 |\n",
      "|    clip_fraction        | 0.864        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.09e+04    |\n",
      "|    explained_variance   | 0.586        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.444        |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | 1.02e+08     |\n",
      "|    value_loss           | 0.0386       |\n",
      "------------------------------------------\n",
      "Step: 1000, MSE: 0.012900, PSNR: 18.893944, PSNR Diff: -0.923862, Changes: 3, Reward: -6.47, 08:40:09\n",
      "Step: 1100, MSE: 0.013065, PSNR: 18.839001, PSNR Diff: -0.978806, Changes: 4, Reward: -6.85, 08:40:11\n",
      "Episode failed: PSNR Diff -1.001505 < -1 at step 1117\n",
      "Initial MSE: 0.003067, Initial PSNR: 24.083843, 08:40:11\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.003067, Initial PSNR: 24.083843, 2024-12-23 08:40:11.617703\n",
      "Episode failed: PSNR Diff -1.007496 < -1 at step 84\n",
      "Initial MSE: 0.001741, Initial PSNR: 22.068148, 08:40:13\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.001741, Initial PSNR: 22.068148, 2024-12-23 08:40:13.389919\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 274          |\n",
      "|    ep_rew_mean          | -1.16e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 791          |\n",
      "|    total_timesteps      | 15360        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1505162600.0 |\n",
      "|    clip_fraction        | 0.888        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.09e+04    |\n",
      "|    explained_variance   | -0.834       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.62e+05     |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | 4.31e+06     |\n",
      "|    value_loss           | 0.0761       |\n",
      "------------------------------------------\n",
      "Step: 100, MSE: 0.002135, PSNR: 21.181261, PSNR Diff: -0.886887, Changes: 3, Reward: -6.21, 08:40:23\n",
      "Episode failed: PSNR Diff -1.002913 < -1 at step 117\n",
      "Initial MSE: 0.000975, Initial PSNR: 22.404881, 08:40:23\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.000975, Initial PSNR: 22.404881, 2024-12-23 08:40:23.839617\n",
      "Step: 100, MSE: 0.001215, PSNR: 21.447407, PSNR Diff: -0.957474, Changes: 4, Reward: -6.70, 08:40:25\n",
      "Episode failed: PSNR Diff -1.007139 < -1 at step 106\n",
      "Initial MSE: 0.001864, Initial PSNR: 22.331972, 08:40:25\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.001864, Initial PSNR: 22.331972, 2024-12-23 08:40:25.695986\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 268           |\n",
      "|    ep_rew_mean          | -1.14e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 61            |\n",
      "|    time_elapsed         | 804           |\n",
      "|    total_timesteps      | 15616         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.8104513e+18 |\n",
      "|    clip_fraction        | 0.887         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | -1.27         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 2.49          |\n",
      "|    n_updates            | 600           |\n",
      "|    policy_gradient_loss | 1.58e+08      |\n",
      "|    value_loss           | 0.129         |\n",
      "-------------------------------------------\n",
      "Step: 100, MSE: 0.002338, PSNR: 21.348335, PSNR Diff: -0.983637, Changes: 4, Reward: -6.89, 08:40:35\n",
      "Episode failed: PSNR Diff -1.004961 < -1 at step 104\n",
      "Initial MSE: 0.002959, Initial PSNR: 25.288197, 08:40:35\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002959, Initial PSNR: 25.288197, 2024-12-23 08:40:35.732100\n",
      "Step: 100, MSE: 0.003220, PSNR: 24.921778, PSNR Diff: -0.366419, Changes: 3, Reward: -2.56, 08:40:37\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 266           |\n",
      "|    ep_rew_mean          | -1.13e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 62            |\n",
      "|    time_elapsed         | 816           |\n",
      "|    total_timesteps      | 15872         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2092701e+21 |\n",
      "|    clip_fraction        | 0.881         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | -0.0908       |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 7.15e+20      |\n",
      "|    n_updates            | 610           |\n",
      "|    policy_gradient_loss | 1.81e+19      |\n",
      "|    value_loss           | 0.0444        |\n",
      "-------------------------------------------\n",
      "Step: 200, MSE: 0.003505, PSNR: 24.553360, PSNR Diff: -0.734837, Changes: 6, Reward: -5.14, 08:40:47\n",
      "Episode failed: PSNR Diff -1.002005 < -1 at step 265\n",
      "Initial MSE: 0.001437, Initial PSNR: 21.878548, 08:40:49\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.001437, Initial PSNR: 21.878548, 2024-12-23 08:40:49.052911\n",
      "Step: 100, MSE: 0.001806, PSNR: 20.885813, PSNR Diff: -0.992735, Changes: 5, Reward: -6.95, 08:40:50\n",
      "Episode failed: PSNR Diff -1.004629 < -1 at step 101\n",
      "Initial MSE: 0.009275, Initial PSNR: 20.326784, 08:40:50\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.009275, Initial PSNR: 20.326784, 2024-12-23 08:40:50.929022\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 263         |\n",
      "|    ep_rew_mean          | -1.12e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 830         |\n",
      "|    total_timesteps      | 16128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 117523670.0 |\n",
      "|    clip_fraction        | 0.886       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.09e+04   |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 5.49e+06    |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | 2.3e+13     |\n",
      "|    value_loss           | 0.0831      |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "from sb3_contrib import MaskablePPO\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import torchOptics.optics as tt\n",
    "import torch.nn as nn\n",
    "import torchOptics.metrics as tm\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torchvision\n",
    "import tqdm\n",
    "import time\n",
    "import pandas as pd\n",
    "from sb3_contrib.common.maskable.utils import get_action_masks\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "from stable_baselines3 import PPO\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 현재 날짜와 시간을 가져와 포맷 지정\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "class BinaryNet(nn.Module):\n",
    "    def __init__(self, num_hologram, final='Sigmoid', in_planes=3,\n",
    "                 channels=[32, 64, 128, 256, 512, 1024, 2048, 4096],\n",
    "                 convReLU=True, convBN=True, poolReLU=True, poolBN=True,\n",
    "                 deconvReLU=True, deconvBN=True):\n",
    "        super(BinaryNet, self).__init__()\n",
    "\n",
    "        def CRB2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True, relu=True, bn=True):\n",
    "            layers = []\n",
    "            layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                 kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                                 bias=bias)]\n",
    "            if relu:\n",
    "                layers += [nn.Tanh()]\n",
    "            if bn:\n",
    "                layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "\n",
    "            cbr = nn.Sequential(*layers)  # *으로 list unpacking\n",
    "\n",
    "            return cbr\n",
    "\n",
    "        def TRB2d(in_channels, out_channels, kernel_size=2, stride=2, bias=True, relu=True, bn=True):\n",
    "            layers = []\n",
    "            layers += [nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                          kernel_size=2, stride=2, padding=0,\n",
    "                                          bias=True)]\n",
    "            if bn:\n",
    "                layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "            if relu:\n",
    "                layers += [nn.ReLU()]\n",
    "\n",
    "            cbr = nn.Sequential(*layers)  # *으로 list unpacking\n",
    "\n",
    "            return cbr\n",
    "\n",
    "        self.enc1_1 = CRB2d(in_planes, channels[0], relu=convReLU, bn=convBN)\n",
    "        self.enc1_2 = CRB2d(channels[0], channels[0], relu=convReLU, bn=convBN)\n",
    "        self.pool1 = CRB2d(channels[0], channels[0], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc2_1 = CRB2d(channels[0], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.enc2_2 = CRB2d(channels[1], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.pool2 = CRB2d(channels[1], channels[1], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc3_1 = CRB2d(channels[1], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.enc3_2 = CRB2d(channels[2], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.pool3 = CRB2d(channels[2], channels[2], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc4_1 = CRB2d(channels[2], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.enc4_2 = CRB2d(channels[3], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.pool4 = CRB2d(channels[3], channels[3], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc5_1 = CRB2d(channels[3], channels[4], relu=convReLU, bn=convBN)\n",
    "        self.enc5_2 = CRB2d(channels[4], channels[4], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv4 = TRB2d(channels[4], channels[3], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec4_1 = CRB2d(channels[4], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.dec4_2 = CRB2d(channels[3], channels[3], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv3 = TRB2d(channels[3], channels[2], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec3_1 = CRB2d(channels[3], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.dec3_2 = CRB2d(channels[2], channels[2], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv2 = TRB2d(channels[2], channels[1], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec2_1 = CRB2d(channels[2], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.dec2_2 = CRB2d(channels[1], channels[1], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv1 = TRB2d(channels[1], channels[0], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec1_1 = CRB2d(channels[1], channels[0], relu=convReLU, bn=convBN)\n",
    "        self.dec1_2 = CRB2d(channels[0], channels[0], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.classifier = CRB2d(channels[0], num_hologram, relu=False, bn=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1_1 = self.enc1_1(x)\n",
    "        enc1_2 = self.enc1_2(enc1_1)\n",
    "        pool1 = self.pool1(enc1_2)\n",
    "\n",
    "        enc2_1 = self.enc2_1(pool1)\n",
    "        enc2_2 = self.enc2_2(enc2_1)\n",
    "        pool2 = self.pool2(enc2_2)\n",
    "\n",
    "        enc3_1 = self.enc3_1(pool2)\n",
    "        enc3_2 = self.enc3_2(enc3_1)\n",
    "        pool3 = self.pool3(enc3_2)\n",
    "\n",
    "        enc4_1 = self.enc4_1(pool3)\n",
    "        enc4_2 = self.enc4_2(enc4_1)\n",
    "        pool4 = self.pool4(enc4_2)\n",
    "\n",
    "        enc5_1 = self.enc5_1(pool4)\n",
    "        enc5_2 = self.enc5_2(enc5_1)\n",
    "\n",
    "        deconv4 = self.deconv4(enc5_2)\n",
    "        concat4 = torch.cat((deconv4, enc4_2), dim=1)\n",
    "        dec4_1 = self.dec4_1(concat4)\n",
    "        dec4_2 = self.dec4_2(dec4_1)\n",
    "\n",
    "        deconv3 = self.deconv3(dec4_2)\n",
    "        concat3 = torch.cat((deconv3, enc3_2), dim=1)\n",
    "        dec3_1 = self.dec3_1(concat3)\n",
    "        dec3_2 = self.dec3_2(dec3_1)\n",
    "\n",
    "        deconv2 = self.deconv2(dec3_2)\n",
    "        concat2 = torch.cat((deconv2, enc2_2), dim=1)\n",
    "        dec2_1 = self.dec2_1(concat2)\n",
    "        dec2_2 = self.dec2_2(dec2_1)\n",
    "\n",
    "        deconv1 = self.deconv1(dec2_2)\n",
    "        concat1 = torch.cat((deconv1, enc1_2), dim=1)\n",
    "        dec1_1 = self.dec1_1(concat1)\n",
    "        dec1_2 = self.dec1_2(dec1_1)\n",
    "\n",
    "        # Final classifier\n",
    "        out = self.classifier(dec1_2)\n",
    "        out = nn.Sigmoid()(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = BinaryNet(num_hologram=8, in_planes=1, convReLU=False,\n",
    "                  convBN=False, poolReLU=False, poolBN=False,\n",
    "                  deconvReLU=False, deconvBN=False).cuda()\n",
    "test = torch.randn(1, 1, 128, 128).cuda()\n",
    "out = model(test)\n",
    "print(out.shape)\n",
    "\n",
    "\n",
    "class Dataset512(Dataset):\n",
    "    def __init__(self, target_dir, meta, transform=None, isTrain=True, padding=0):\n",
    "        self.target_dir = target_dir\n",
    "        self.transform = transform\n",
    "        self.meta = meta\n",
    "        self.isTrain = isTrain\n",
    "        self.target_list = sorted(glob.glob(target_dir+'*.png'))\n",
    "        self.center_crop = torchvision.transforms.CenterCrop(128)\n",
    "        self.random_crop = torchvision.transforms.RandomCrop((128, 128))\n",
    "        self.padding = padding\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        target = tt.imread(self.target_list[idx], meta=meta, gray=True).unsqueeze(0)\n",
    "        if target.shape[-1] < 128 or target.shape[-2] < 128:\n",
    "            target = torchvision.transforms.Resize(128)(target)\n",
    "        if self.isTrain:\n",
    "            target = self.random_crop(target)\n",
    "            target = torchvision.transforms.functional.pad(target, (self.padding, self.padding, self.padding, self.padding))\n",
    "        else:\n",
    "            target = self.center_crop(target)\n",
    "            target = torchvision.transforms.functional.pad(target, (self.padding, self.padding, self.padding, self.padding))\n",
    "        return target\n",
    "\n",
    "\n",
    "# BinaryHologramEnv 클래스\n",
    "class BinaryHologramEnv(gym.Env):\n",
    "    def __init__(self, target_function, trainloader, max_steps=10000, T_PSNR=30, T_steps=10, max_allowed_changes=10):\n",
    "        \"\"\"\n",
    "        target_function: 타겟 이미지와의 손실(MSE 또는 PSNR) 계산 함수.\n",
    "        trainloader: 학습 데이터셋 로더.\n",
    "        max_steps: 최대 타임스텝 제한.\n",
    "        T_PSNR: 목표 PSNR 값.\n",
    "        T_steps: PSNR 목표를 유지해야 하는 최소 타임스텝.\n",
    "        max_allowed_changes: 한 번에 조작할 수 있는 최대 픽셀 수.\n",
    "        \"\"\"\n",
    "        super(BinaryHologramEnv, self).__init__()\n",
    "\n",
    "        # 관찰 공간 (1, 8, 128, 128)\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(1, 8, 128, 128), dtype=np.float32)\n",
    "\n",
    "        # 행동 공간: MultiBinary 데이터\n",
    "        self.action_space = spaces.MultiBinary(1 * 8 * 128 * 128)\n",
    "\n",
    "        # 모델 및 데이터 로더 설정\n",
    "        self.target_function = target_function  # BinaryNet 모델\n",
    "        self.trainloader = trainloader          # 학습 데이터 로더\n",
    "\n",
    "        # 에피소드 설정\n",
    "        self.max_steps = max_steps\n",
    "        self.T_PSNR = T_PSNR\n",
    "        self.T_steps = T_steps\n",
    "        self.max_allowed_changes = max_allowed_changes  # 한 번에 조작할 수 있는 최대 픽셀 수\n",
    "\n",
    "        # 학습 상태 초기화\n",
    "        self.state = None\n",
    "        self.observation = None\n",
    "        self.steps = 0\n",
    "        self.psnr_sustained_steps = 0\n",
    "\n",
    "        # 학습 데이터셋에서 첫 배치 추출\n",
    "        self.data_iter = iter(self.trainloader)\n",
    "        self.target_image = None\n",
    "\n",
    "    def reset(self, seed=None, options=None, lr=1e-4, z=2e-3):\n",
    "        \"\"\"\n",
    "        환경 초기화 함수.\n",
    "        데이터셋에서 새로운 이미지를 가져오고 초기 상태를 설정합니다.\n",
    "        - 데이터셋의 다음 이미지를 불러옵니다. \n",
    "        - BinaryNet을 사용해 초기 관찰값을 생성합니다.\n",
    "        - 초기 상태(state)는 관찰값을 이진화한 결과입니다.\n",
    "        - 초기 PSNR과 MSE를 계산하고 출력합니다.\n",
    "\n",
    "        Args:\n",
    "            seed (int, optional): 랜덤 시드 값. Default는 None.\n",
    "            options (dict, optional): 추가 옵션. Default는 None.\n",
    "            lr (float, optional): 학습률. Default는 1e-4.\n",
    "            z (float, optional): 시뮬레이션 거리. Default는 2e-3.\n",
    "\n",
    "        Returns:\n",
    "            observation (np.ndarray): 초기 관찰값.\n",
    "            dict: 초기 상태와 행동 마스크.\n",
    "        \"\"\"\n",
    "        torch.cuda.empty_cache()\n",
    "        try:\n",
    "            self.target_image = next(self.data_iter)\n",
    "        except StopIteration:\n",
    "            self.data_iter = iter(self.trainloader)\n",
    "            self.target_image = next(self.data_iter)\n",
    "\n",
    "        self.target_image = self.target_image.cuda()\n",
    "        with torch.no_grad():\n",
    "            model_output = self.target_function(self.target_image)\n",
    "        self.observation = model_output.cpu().numpy()  # (1, 8, 512, 512)\n",
    "\n",
    "        self.steps = 0\n",
    "        self.psnr_sustained_steps = 0\n",
    "        self.state = (self.observation >= 0.5).astype(np.int8)  # 이진화 상태\n",
    "\n",
    "        binary = torch.tensor(self.state, dtype=torch.float32).cuda()\n",
    "        binary = tt.Tensor(binary, meta={'dx': (7.56e-6, 7.56e-6), 'wl': 515e-9})  # meta 정보 포함\n",
    "\n",
    "        # 시뮬레이션\n",
    "        sim = tt.simulate(binary, z).abs()**2\n",
    "        result = torch.mean(sim, dim=1, keepdim=True)\n",
    "\n",
    "        # MSE 및 PSNR 계산\n",
    "        mse = tt.relativeLoss(result, self.target_image, F.mse_loss).detach().cpu().numpy()\n",
    "        self.initial_psnr = tt.relativeLoss(result, self.target_image, tm.get_PSNR)  # 초기 PSNR 저장\n",
    "\n",
    "        current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        print(f\"Initial MSE: {mse:.6f}, Initial PSNR: {self.initial_psnr:.6f}, {current_time}\")\n",
    "\n",
    "        mask = self.create_action_mask(self.observation)\n",
    "        return self.observation, {\"state\": self.state, \"mask\": mask}\n",
    "\n",
    "\n",
    "    def initialize_state(self, z=2e-3):\n",
    "        \"\"\"\n",
    "        초기 상태를 생성하고, 시뮬레이션 및 관련 값을 계산합니다.\n",
    "\n",
    "        Args:\n",
    "            z (float): 시뮬레이션 거리. Default는 2e-3.\n",
    "\n",
    "        Returns:\n",
    "            observation (np.ndarray): 초기 관찰값.\n",
    "            dict: 초기 상태와 행동 마스크.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            # 모델로 초기 관찰값 생성\n",
    "            model_output = self.target_function(self.target_image)\n",
    "        self.observation = model_output.cpu().numpy()  # 관찰값을 numpy 배열로 변환\n",
    "\n",
    "        self.state = (self.observation >= 0.5).astype(np.int8)  # 이진화 상태\n",
    "\n",
    "        binary = torch.tensor(self.state, dtype=torch.float32).cuda()  # 상태를 Torch 텐서로 변환\n",
    "        binary = tt.Tensor(binary, meta={'dx': (7.56e-6, 7.56e-6), 'wl': 515e-9})  # 메타 정보 추가\n",
    "\n",
    "        # 시뮬레이션 수행\n",
    "        sim = tt.simulate(binary, z).abs()**2\n",
    "        result = torch.mean(sim, dim=1, keepdim=True)\n",
    "\n",
    "        # 초기 MSE와 PSNR 계산\n",
    "        mse = tt.relativeLoss(result, self.target_image, F.mse_loss).detach().cpu().numpy()\n",
    "        psnr = tt.relativeLoss(result, self.target_image, tm.get_PSNR)\n",
    "\n",
    "        # 초기 값 출력\n",
    "        print(f\"Initial MSE: {mse:.6f}, Initial PSNR: {psnr:.6f}, {datetime.now()}\")\n",
    "\n",
    "        # 관찰값 업데이트\n",
    "        self.observation = result.detach().cpu().numpy()\n",
    "        mask = self.create_action_mask(self.observation)\n",
    "\n",
    "        return self.observation, {\"state\": self.state, \"mask\": mask}\n",
    "\n",
    "    def create_action_mask(self, observation):\n",
    "        \"\"\"\n",
    "        관찰값에 따라 행동 마스크 생성.\n",
    "        - 관찰값이 0~0.2인 경우 행동 0으로 고정.\n",
    "        - 관찰값이 0.8~1인 경우 행동 1로 고정.\n",
    "        - 최대 변경 가능 픽셀 수 제한.\n",
    "\n",
    "        Args:\n",
    "            observation (np.ndarray): 관찰값.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: 행동 마스크.\n",
    "        \"\"\"\n",
    "        mask = np.ones_like(observation, dtype=np.int8)  # 기본적으로 모든 행동 가능\n",
    "        mask[observation <= 0.2] = 0  # 관찰값이 0~0.2면 행동 0으로 고정\n",
    "        mask[observation >= 0.8] = 1  # 관찰값이 0.8~1이면 행동 1로 고정\n",
    "\n",
    "        # 허용된 변경 수를 강제 적용\n",
    "        allowed_indices = np.where(mask.flatten() == 1)[0]\n",
    "        if len(allowed_indices) > self.max_allowed_changes:\n",
    "            # 초과 변경을 방지하도록 고정된 수의 픽셀만 선택 가능\n",
    "            selected_indices = np.random.choice(allowed_indices, self.max_allowed_changes, replace=False)\n",
    "            mask = np.zeros_like(mask.flatten())\n",
    "            mask[selected_indices] = 1\n",
    "            mask = mask.reshape(observation.shape)\n",
    "\n",
    "        return mask\n",
    "\n",
    "    def step(self, action, lr=1e-4, z=2e-3):\n",
    "        \"\"\"\n",
    "        환경의 한 타임스텝을 진행합니다.\n",
    "        - 주어진 행동(action)을 적용하고, 새로운 상태를 계산합니다.\n",
    "        - MSE와 PSNR 계산 후 보상을 반환합니다.\n",
    "\n",
    "        Args:\n",
    "            action (np.ndarray): 에이전트가 수행한 행동.\n",
    "            lr (float, optional): 학습률. Default는 1e-4.\n",
    "            z (float, optional): 시뮬레이션 거리. Default는 2e-3.\n",
    "    \n",
    "        eturns:\n",
    "            observation (np.ndarray): 새로운 관찰값.\n",
    "            float: 보상 값.\n",
    "            bool: 종료 여부.\n",
    "            bool: Truncated 여부.\n",
    "            dict: 추가 정보 (MSE, PSNR, 행동 마스크 등).\n",
    "        \"\"\"\n",
    "        if self.steps == 0:\n",
    "            print(\"Executing reset logic for the first step\")\n",
    "            self.steps += 1\n",
    "            observation, info = self.initialize_state(z)\n",
    "            return observation, 0.0, False, False, info\n",
    "\n",
    "        action = np.reshape(action, (1, 8, 128, 128)).astype(np.int8)\n",
    "\n",
    "        # 행동에 마스크 강제 적용\n",
    "        mask = self.create_action_mask(self.observation)\n",
    "        masked_action = action * mask\n",
    "\n",
    "        # 조작 픽셀 수 확인\n",
    "        num_changes = np.sum(masked_action)\n",
    "        reward = 0\n",
    "\n",
    "        if num_changes > self.max_allowed_changes:\n",
    "            reward -= 50\n",
    "\n",
    "        # 현재 상태에 행동을 적용하여 새로운 상태 생성\n",
    "        new_state = np.logical_xor(self.state, masked_action).astype(np.int8)\n",
    "\n",
    "        binary = torch.tensor(new_state, dtype=torch.float32).cuda()\n",
    "        binary = tt.Tensor(binary, meta={'dx': (7.56e-6, 7.56e-6), 'wl': 515e-9})\n",
    "\n",
    "        # 시뮬레이션 수행\n",
    "        sim = tt.simulate(binary, z).abs()**2\n",
    "        result = torch.mean(sim, dim=1, keepdim=True)\n",
    "\n",
    "        # MSE 및 PSNR 계산\n",
    "        mse = tt.relativeLoss(result, self.target_image, F.mse_loss).detach().cpu().numpy()\n",
    "        psnr = tt.relativeLoss(result, self.target_image, tm.get_PSNR)\n",
    "\n",
    "        # 초기 PSNR과의 차이 계산\n",
    "        psnr_diff = psnr - self.initial_psnr\n",
    "\n",
    "        # 실패 조건 확인\n",
    "        if psnr_diff < -1:\n",
    "            print(f\"Episode failed: PSNR Diff {psnr_diff:.6f} < -1 at step {self.steps}\")\n",
    "            return self.observation, -100.0, True, False, {\"mse\": mse, \"psnr\": psnr, \"psnr_diff\": psnr_diff, \"mask\": None}\n",
    "\n",
    "        # 보상 계산\n",
    "        reward += psnr_diff * 7\n",
    "        reward -= 0.1 * num_changes if num_changes > self.max_allowed_changes else 0\n",
    "\n",
    "        # 출력 추가 (100 스텝마다 출력)\n",
    "        if self.steps % 100 == 0:\n",
    "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "            print(f\"Step: {self.steps}, MSE: {mse:.6f}, PSNR: {psnr:.6f}, PSNR Diff: {psnr_diff:.6f}, \"\n",
    "                  f\"Changes: {num_changes}, Reward: {reward:.2f}, {current_time}\")\n",
    "\n",
    "        # 상태 업데이트\n",
    "        self.state = new_state\n",
    "        self.observation = self.state\n",
    "\n",
    "        terminated = self.steps >= self.max_steps or self.psnr_sustained_steps >= self.T_steps\n",
    "        truncated = self.steps >= self.max_steps\n",
    "\n",
    "        if psnr >= self.T_PSNR:\n",
    "            self.psnr_sustained_steps += 1\n",
    "        else:\n",
    "            self.psnr_sustained_steps = 0\n",
    "\n",
    "        mask = self.create_action_mask(self.observation)\n",
    "        info = {\"mse\": mse, \"psnr\": psnr, \"psnr_diff\": psnr_diff, \"mask\": mask}\n",
    "\n",
    "        del binary, sim, result\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        self.steps += 1\n",
    "        return self.observation, reward, terminated, truncated, info\n",
    "\n",
    "\n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_uniform_(m.weight.data, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight.data, 1)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight.data)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "batch_size = 1\n",
    "target_dir = '/nfs/dataset/DIV2K/DIV2K_train_HR/DIV2K_train_HR/'\n",
    "valid_dir = '/nfs/dataset/DIV2K/DIV2K_valid_HR/DIV2K_valid_HR/'\n",
    "meta = {'wl': (515e-9), 'dx': (7.56e-6, 7.56e-6)}  # 메타 정보\n",
    "padding = 0\n",
    "\n",
    "# Dataset512 클래스 사용\n",
    "train_dataset = Dataset512(target_dir=target_dir, meta=meta, isTrain=True, padding=padding)\n",
    "valid_dataset = Dataset512(target_dir=valid_dir, meta=meta, isTrain=False, padding=padding)\n",
    "\n",
    "# DataLoader 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# BinaryNet 모델 로드\n",
    "model = BinaryNet(num_hologram=8, in_planes=1, convReLU=False, convBN=False,\n",
    "                  poolReLU=False, poolBN=False, deconvReLU=False, deconvBN=False).cuda()\n",
    "model.load_state_dict(torch.load('result_v/2024-12-19 21:37:10.439713_pre_reinforce_8_0.002/2024-12-19 21:37:10.439713_pre_reinforce_8_0.002'))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# 마스크 함수 정의\n",
    "def mask_fn(env):\n",
    "    return env.create_action_mask(env.observation)\n",
    "\n",
    "# 환경 생성에 새로운 데이터 로더 적용\n",
    "env = BinaryHologramEnv(\n",
    "    target_function=model,\n",
    "    trainloader=train_loader,  # 업데이트된 train_loader 사용\n",
    "    max_steps=10000,\n",
    "    T_PSNR=30,\n",
    "    T_steps=10\n",
    ")\n",
    "\n",
    "# ActionMasker 래퍼 적용\n",
    "env = ActionMasker(env, mask_fn)\n",
    "\n",
    "# Vectorized 환경 생성\n",
    "venv = make_vec_env(lambda: env, n_envs=1)\n",
    "venv = VecNormalize(venv, norm_obs=True, norm_reward=True, clip_obs=10.0)\n",
    "\n",
    "# PPO 학습\n",
    "#ppo_model = PPO(\n",
    "#    \"MlpPolicy\",\n",
    "#    venv,\n",
    "#    verbose=2,\n",
    "#    n_steps=1024,\n",
    "#    batch_size=64,\n",
    "#    gamma=0.99,\n",
    "#    learning_rate=3e-4,\n",
    "#    tensorboard_log=\"./ppo_with_mask/\"\n",
    "#)\n",
    "\n",
    "#ppo_model.learn(total_timesteps=10000000)\n",
    "\n",
    "# 학습된 모델 저장\n",
    "#ppo_model.save(f\"ppo_with_mask_{current_date}\")\n",
    "\n",
    "from sb3_contrib import RecurrentPPO\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    net_arch=[dict(pi=[256, 256], vf=[256, 256])],  # 더 복잡한 네트워크 구조\n",
    "    lstm_hidden_size=128,  # LSTM 크기 유지\n",
    "    shared_lstm=False  # 별도 LSTM 사용\n",
    ")\n",
    "\n",
    "ppo_model = RecurrentPPO(\n",
    "    \"MlpLstmPolicy\",\n",
    "    venv,\n",
    "    verbose=2,\n",
    "    n_steps=256,\n",
    "    batch_size=64,\n",
    "    gamma=0.99,\n",
    "    gae_lambda=0.95,\n",
    "    learning_rate=1e-5,\n",
    "    clip_range=0.2,\n",
    "    vf_coef=0.5,\n",
    "    max_grad_norm=0.5,  # 그라디언트 클리핑 활성화\n",
    "    tensorboard_log=\"./ppo_with_mask/\",\n",
    "    policy_kwargs=policy_kwargs\n",
    ")\n",
    "\n",
    "\n",
    "# 학습\n",
    "ppo_model.learn(total_timesteps=10000000)\n",
    "\n",
    "# 모델 저장\n",
    "ppo_model.save(f\"ppo_with_mask_{current_date}\")\n",
    "\n",
    "\n",
    "# 평가용 환경 생성\n",
    "#eval_env = make_vec_env(lambda: env, n_envs=1)\n",
    "\n",
    "# EvalCallback 추가\n",
    "#eval_callback = EvalCallback(\n",
    "#    eval_env,\n",
    "#    best_model_save_path='./logs/',\n",
    "#    log_path='./logs/',\n",
    "#    eval_freq=10000,  # 평가 빈도 (타임스텝 기준)\n",
    "#    deterministic=True,\n",
    "#    render=False\n",
    "#)\n",
    "\n",
    "#ppo_model = PPO(\n",
    "#    \"MlpPolicy\",\n",
    "#    venv,\n",
    "#    verbose=2,\n",
    "#    n_steps=1024,\n",
    "#    batch_size=64,\n",
    "#    gamma=0.99,\n",
    "#    learning_rate=3e-4,\n",
    "#    tensorboard_log=\"./ppo_with_mask/\"\n",
    "#)\n",
    "\n",
    "# 학습 시작 (콜백 추가)\n",
    "#ppo_model.learn(total_timesteps=10000000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dd0c83-99b3-4f86-bc23-89c6b278e3ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e105c7a2-bd3a-440c-9ad3-3ec9a08af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
