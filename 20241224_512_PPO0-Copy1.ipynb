{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e3bb6ba70918dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T07:50:49.917672Z",
     "start_time": "2024-12-17T07:50:49.704223Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/kornia/feature/lightglue.py:30: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 512, 512])\n",
      "Using cuda device\n",
      "\u001b[91mResetting environment. Consecutive episode failures: 0, Max consecutive episode failures: 0\u001b[0m\n",
      "Initial MSE: 0.003232, Initial PSNR: 24.905533, 12:03:18\n",
      "Logging to ./ppo_with_mask/PPO_123\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.003232, Initial PSNR: 24.905533, 2024-12-24 12:03:19.942378\n",
      "\u001b[94mStep: 5, PSNR Before: 24.905533, PSNR After: 24.905565, PSNR Change: 0.000032, PSNR Diff: 0.000032 (New Max), Reward: 2.59, 12:03:25\u001b[0m\n",
      "\u001b[94mStep: 14, PSNR Before: 24.905565, PSNR After: 24.905634, PSNR Change: 0.000069, PSNR Diff: 0.000101 (New Max), Reward: 5.49, 12:03:34\u001b[0m\n",
      "\u001b[94mStep: 15, PSNR Before: 24.905634, PSNR After: 24.905647, PSNR Change: 0.000013, PSNR Diff: 0.000114 (New Max), Reward: 1.07, 12:03:35\u001b[0m\n",
      "\u001b[94mStep: 21, PSNR Before: 24.905647, PSNR After: 24.905661, PSNR Change: 0.000013, PSNR Diff: 0.000128 (New Max), Reward: 1.07, 12:03:41\u001b[0m\n",
      "\u001b[94mStep: 32, PSNR Before: 24.905661, PSNR After: 24.905704, PSNR Change: 0.000044, PSNR Diff: 0.000172 (New Max), Reward: 3.51, 12:03:52\u001b[0m\n",
      "\u001b[94mStep: 36, PSNR Before: 24.905704, PSNR After: 24.905720, PSNR Change: 0.000015, PSNR Diff: 0.000187 (New Max), Reward: 1.22, 12:03:56\u001b[0m\n",
      "\u001b[94mStep: 45, PSNR Before: 24.905720, PSNR After: 24.905737, PSNR Change: 0.000017, PSNR Diff: 0.000204 (New Max), Reward: 1.37, 12:04:05\u001b[0m\n",
      "\u001b[94mStep: 48, PSNR Before: 24.905737, PSNR After: 24.905743, PSNR Change: 0.000006, PSNR Diff: 0.000210 (New Max), Reward: 0.46, 12:04:09\u001b[0m\n",
      "\u001b[94mStep: 53, PSNR Before: 24.905743, PSNR After: 24.905800, PSNR Change: 0.000057, PSNR Diff: 0.000267 (New Max), Reward: 4.58, 12:04:14\u001b[0m\n",
      "\u001b[94mStep: 60, PSNR Before: 24.905800, PSNR After: 24.905827, PSNR Change: 0.000027, PSNR Diff: 0.000294 (New Max), Reward: 2.14, 12:04:21\u001b[0m\n",
      "\u001b[94mStep: 61, PSNR Before: 24.905827, PSNR After: 24.905832, PSNR Change: 0.000006, PSNR Diff: 0.000299 (New Max), Reward: 0.46, 12:04:23\u001b[0m\n",
      "\u001b[94mStep: 64, PSNR Before: 24.905832, PSNR After: 24.905861, PSNR Change: 0.000029, PSNR Diff: 0.000328 (New Max), Reward: 2.29, 12:04:26\u001b[0m\n",
      "\u001b[94mStep: 70, PSNR Before: 24.905861, PSNR After: 24.905869, PSNR Change: 0.000008, PSNR Diff: 0.000336 (New Max), Reward: 0.61, 12:04:32\u001b[0m\n",
      "\u001b[94mStep: 75, PSNR Before: 24.905869, PSNR After: 24.905874, PSNR Change: 0.000006, PSNR Diff: 0.000341 (New Max), Reward: 0.46, 12:04:39\u001b[0m\n",
      "\u001b[94mStep: 91, PSNR Before: 24.905874, PSNR After: 24.905907, PSNR Change: 0.000032, PSNR Diff: 0.000374 (New Max), Reward: 2.59, 12:04:55\u001b[0m\n",
      "\u001b[94mStep: 96, PSNR Before: 24.905907, PSNR After: 24.905928, PSNR Change: 0.000021, PSNR Diff: 0.000395 (New Max), Reward: 1.68, 12:05:01\u001b[0m\n",
      "\u001b[94mStep: 98, PSNR Before: 24.905928, PSNR After: 24.905947, PSNR Change: 0.000019, PSNR Diff: 0.000414 (New Max), Reward: 1.53, 12:05:05\u001b[0m\n",
      "\u001b[94mStep: 100, PSNR Before: 24.905947, PSNR After: 24.905960, PSNR Change: 0.000013, PSNR Diff: 0.000427 (New Max), Reward: 1.07, 12:05:07\u001b[0m\n",
      "Step: 100, PSNR Before: 24.905947, PSNR After: 24.905960, PSNR Change: 0.000013, PSNR Diff: 0.000427, Reward: 1.07, 12:05:07\n",
      "\u001b[94mStep: 103, PSNR Before: 24.905960, PSNR After: 24.905970, PSNR Change: 0.000010, PSNR Diff: 0.000437 (New Max), Reward: 0.76, 12:05:11\u001b[0m\n",
      "\u001b[94mStep: 104, PSNR Before: 24.905970, PSNR After: 24.905989, PSNR Change: 0.000019, PSNR Diff: 0.000456 (New Max), Reward: 1.53, 12:05:13\u001b[0m\n",
      "\u001b[94mStep: 112, PSNR Before: 24.905989, PSNR After: 24.906036, PSNR Change: 0.000048, PSNR Diff: 0.000504 (New Max), Reward: 3.81, 12:05:21\u001b[0m\n",
      "\u001b[94mStep: 114, PSNR Before: 24.906036, PSNR After: 24.906054, PSNR Change: 0.000017, PSNR Diff: 0.000521 (New Max), Reward: 1.37, 12:05:24\u001b[0m\n",
      "\u001b[94mStep: 117, PSNR Before: 24.906054, PSNR After: 24.906086, PSNR Change: 0.000032, PSNR Diff: 0.000553 (New Max), Reward: 2.59, 12:05:28\u001b[0m\n",
      "\u001b[94mStep: 121, PSNR Before: 24.906086, PSNR After: 24.906128, PSNR Change: 0.000042, PSNR Diff: 0.000595 (New Max), Reward: 3.36, 12:05:32\u001b[0m\n",
      "\u001b[94mStep: 123, PSNR Before: 24.906128, PSNR After: 24.906200, PSNR Change: 0.000072, PSNR Diff: 0.000668 (New Max), Reward: 5.80, 12:05:35\u001b[0m\n",
      "\u001b[94mStep: 125, PSNR Before: 24.906200, PSNR After: 24.906263, PSNR Change: 0.000063, PSNR Diff: 0.000731 (New Max), Reward: 5.04, 12:05:38\u001b[0m\n",
      "\u001b[94mStep: 126, PSNR Before: 24.906263, PSNR After: 24.906277, PSNR Change: 0.000013, PSNR Diff: 0.000744 (New Max), Reward: 1.07, 12:05:40\u001b[0m\n",
      "\u001b[94mStep: 129, PSNR Before: 24.906277, PSNR After: 24.906441, PSNR Change: 0.000164, PSNR Diff: 0.000908 (New Max), Reward: 13.12, 12:05:44\u001b[0m\n",
      "\u001b[94mStep: 141, PSNR Before: 24.906441, PSNR After: 24.906445, PSNR Change: 0.000004, PSNR Diff: 0.000912 (New Max), Reward: 0.31, 12:05:56\u001b[0m\n",
      "\u001b[94mStep: 151, PSNR Before: 24.906445, PSNR After: 24.906466, PSNR Change: 0.000021, PSNR Diff: 0.000933 (New Max), Reward: 1.68, 12:06:06\u001b[0m\n",
      "\u001b[94mStep: 155, PSNR Before: 24.906466, PSNR After: 24.906479, PSNR Change: 0.000013, PSNR Diff: 0.000946 (New Max), Reward: 1.07, 12:06:11\u001b[0m\n",
      "\u001b[94mStep: 156, PSNR Before: 24.906479, PSNR After: 24.906511, PSNR Change: 0.000032, PSNR Diff: 0.000978 (New Max), Reward: 2.59, 12:06:13\u001b[0m\n",
      "\u001b[94mStep: 157, PSNR Before: 24.906511, PSNR After: 24.906513, PSNR Change: 0.000002, PSNR Diff: 0.000980 (New Max), Reward: 0.15, 12:06:14\u001b[0m\n",
      "\u001b[94mStep: 162, PSNR Before: 24.906513, PSNR After: 24.906525, PSNR Change: 0.000011, PSNR Diff: 0.000992 (New Max), Reward: 0.92, 12:06:20\u001b[0m\n",
      "\u001b[94mStep: 166, PSNR Before: 24.906525, PSNR After: 24.906540, PSNR Change: 0.000015, PSNR Diff: 0.001007 (New Max), Reward: 1.22, 12:06:25\u001b[0m\n",
      "\u001b[94mStep: 175, PSNR Before: 24.906540, PSNR After: 24.906549, PSNR Change: 0.000010, PSNR Diff: 0.001017 (New Max), Reward: 0.76, 12:06:34\u001b[0m\n",
      "\u001b[94mStep: 177, PSNR Before: 24.906549, PSNR After: 24.906620, PSNR Change: 0.000071, PSNR Diff: 0.001087 (New Max), Reward: 5.65, 12:06:37\u001b[0m\n",
      "\u001b[94mStep: 178, PSNR Before: 24.906620, PSNR After: 24.906637, PSNR Change: 0.000017, PSNR Diff: 0.001104 (New Max), Reward: 1.37, 12:06:38\u001b[0m\n",
      "\u001b[94mStep: 180, PSNR Before: 24.906637, PSNR After: 24.906647, PSNR Change: 0.000010, PSNR Diff: 0.001114 (New Max), Reward: 0.76, 12:06:41\u001b[0m\n",
      "\u001b[94mStep: 181, PSNR Before: 24.906647, PSNR After: 24.906700, PSNR Change: 0.000053, PSNR Diff: 0.001167 (New Max), Reward: 4.27, 12:06:43\u001b[0m\n",
      "\u001b[94mStep: 193, PSNR Before: 24.906700, PSNR After: 24.906727, PSNR Change: 0.000027, PSNR Diff: 0.001194 (New Max), Reward: 2.14, 12:06:56\u001b[0m\n",
      "\u001b[94mStep: 194, PSNR Before: 24.906727, PSNR After: 24.906731, PSNR Change: 0.000004, PSNR Diff: 0.001198 (New Max), Reward: 0.31, 12:06:58\u001b[0m\n",
      "\u001b[94mStep: 196, PSNR Before: 24.906731, PSNR After: 24.906759, PSNR Change: 0.000029, PSNR Diff: 0.001226 (New Max), Reward: 2.29, 12:07:00\u001b[0m\n",
      "\u001b[94mStep: 197, PSNR Before: 24.906759, PSNR After: 24.906780, PSNR Change: 0.000021, PSNR Diff: 0.001247 (New Max), Reward: 1.68, 12:07:02\u001b[0m\n",
      "\u001b[94mStep: 204, PSNR Before: 24.906780, PSNR After: 24.906805, PSNR Change: 0.000025, PSNR Diff: 0.001272 (New Max), Reward: 1.98, 12:07:09\u001b[0m\n",
      "\u001b[94mStep: 207, PSNR Before: 24.906805, PSNR After: 24.906816, PSNR Change: 0.000011, PSNR Diff: 0.001284 (New Max), Reward: 0.92, 12:07:13\u001b[0m\n",
      "\u001b[94mStep: 210, PSNR Before: 24.906816, PSNR After: 24.906822, PSNR Change: 0.000006, PSNR Diff: 0.001289 (New Max), Reward: 0.46, 12:07:17\u001b[0m\n",
      "\u001b[94mStep: 219, PSNR Before: 24.906822, PSNR After: 24.906906, PSNR Change: 0.000084, PSNR Diff: 0.001373 (New Max), Reward: 6.71, 12:07:26\u001b[0m\n",
      "\u001b[94mStep: 221, PSNR Before: 24.906906, PSNR After: 24.906921, PSNR Change: 0.000015, PSNR Diff: 0.001389 (New Max), Reward: 1.22, 12:07:28\u001b[0m\n",
      "\u001b[94mStep: 226, PSNR Before: 24.906921, PSNR After: 24.906952, PSNR Change: 0.000031, PSNR Diff: 0.001419 (New Max), Reward: 2.44, 12:07:34\u001b[0m\n",
      "\u001b[94mStep: 229, PSNR Before: 24.906952, PSNR After: 24.906958, PSNR Change: 0.000006, PSNR Diff: 0.001425 (New Max), Reward: 0.46, 12:07:37\u001b[0m\n",
      "\u001b[94mStep: 244, PSNR Before: 24.906958, PSNR After: 24.906982, PSNR Change: 0.000025, PSNR Diff: 0.001450 (New Max), Reward: 1.98, 12:07:52\u001b[0m\n",
      "\u001b[94mStep: 248, PSNR Before: 24.906982, PSNR After: 24.907034, PSNR Change: 0.000051, PSNR Diff: 0.001501 (New Max), Reward: 4.12, 12:07:56\u001b[0m\n",
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 0   |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 285 |\n",
      "|    total_timesteps | 256 |\n",
      "----------------------------\n",
      "\u001b[94mStep: 266, PSNR Before: 24.907034, PSNR After: 24.907064, PSNR Change: 0.000031, PSNR Diff: 0.001532 (New Max), Reward: 2.44, 12:08:21\u001b[0m\n",
      "\u001b[94mStep: 273, PSNR Before: 24.907064, PSNR After: 24.907076, PSNR Change: 0.000011, PSNR Diff: 0.001543 (New Max), Reward: 0.92, 12:08:29\u001b[0m\n",
      "\u001b[94mStep: 285, PSNR Before: 24.907076, PSNR After: 24.907095, PSNR Change: 0.000019, PSNR Diff: 0.001562 (New Max), Reward: 1.53, 12:08:42\u001b[0m\n",
      "\u001b[94mStep: 290, PSNR Before: 24.907095, PSNR After: 24.907169, PSNR Change: 0.000074, PSNR Diff: 0.001637 (New Max), Reward: 5.95, 12:08:47\u001b[0m\n",
      "\u001b[94mStep: 299, PSNR Before: 24.907169, PSNR After: 24.907217, PSNR Change: 0.000048, PSNR Diff: 0.001684 (New Max), Reward: 3.81, 12:08:56\u001b[0m\n",
      "\u001b[94mStep: 301, PSNR Before: 24.907217, PSNR After: 24.907248, PSNR Change: 0.000031, PSNR Diff: 0.001715 (New Max), Reward: 2.44, 12:08:59\u001b[0m\n",
      "\u001b[94mStep: 307, PSNR Before: 24.907248, PSNR After: 24.907284, PSNR Change: 0.000036, PSNR Diff: 0.001751 (New Max), Reward: 2.90, 12:09:05\u001b[0m\n",
      "\u001b[94mStep: 309, PSNR Before: 24.907284, PSNR After: 24.907312, PSNR Change: 0.000029, PSNR Diff: 0.001780 (New Max), Reward: 2.29, 12:09:08\u001b[0m\n",
      "\u001b[94mStep: 312, PSNR Before: 24.907312, PSNR After: 24.907379, PSNR Change: 0.000067, PSNR Diff: 0.001846 (New Max), Reward: 5.34, 12:09:11\u001b[0m\n",
      "\u001b[94mStep: 319, PSNR Before: 24.907379, PSNR After: 24.907440, PSNR Change: 0.000061, PSNR Diff: 0.001907 (New Max), Reward: 4.88, 12:09:18\u001b[0m\n",
      "\u001b[94mStep: 324, PSNR Before: 24.907440, PSNR After: 24.907446, PSNR Change: 0.000006, PSNR Diff: 0.001913 (New Max), Reward: 0.46, 12:09:23\u001b[0m\n",
      "\u001b[94mStep: 330, PSNR Before: 24.907446, PSNR After: 24.907455, PSNR Change: 0.000010, PSNR Diff: 0.001923 (New Max), Reward: 0.76, 12:09:29\u001b[0m\n",
      "\u001b[94mStep: 331, PSNR Before: 24.907455, PSNR After: 24.907543, PSNR Change: 0.000088, PSNR Diff: 0.002010 (New Max), Reward: 7.02, 12:09:31\u001b[0m\n",
      "\u001b[94mStep: 337, PSNR Before: 24.907543, PSNR After: 24.907553, PSNR Change: 0.000010, PSNR Diff: 0.002020 (New Max), Reward: 0.76, 12:09:37\u001b[0m\n",
      "\u001b[94mStep: 338, PSNR Before: 24.907553, PSNR After: 24.907629, PSNR Change: 0.000076, PSNR Diff: 0.002096 (New Max), Reward: 6.10, 12:09:39\u001b[0m\n",
      "\u001b[94mStep: 339, PSNR Before: 24.907629, PSNR After: 24.907654, PSNR Change: 0.000025, PSNR Diff: 0.002121 (New Max), Reward: 1.98, 12:09:41\u001b[0m\n",
      "\u001b[94mStep: 348, PSNR Before: 24.907654, PSNR After: 24.907677, PSNR Change: 0.000023, PSNR Diff: 0.002144 (New Max), Reward: 1.83, 12:09:49\u001b[0m\n",
      "\u001b[94mStep: 354, PSNR Before: 24.907677, PSNR After: 24.907696, PSNR Change: 0.000019, PSNR Diff: 0.002163 (New Max), Reward: 1.53, 12:09:56\u001b[0m\n",
      "\u001b[94mStep: 357, PSNR Before: 24.907696, PSNR After: 24.907705, PSNR Change: 0.000010, PSNR Diff: 0.002172 (New Max), Reward: 0.76, 12:09:59\u001b[0m\n",
      "\u001b[94mStep: 363, PSNR Before: 24.907705, PSNR After: 24.907724, PSNR Change: 0.000019, PSNR Diff: 0.002192 (New Max), Reward: 1.53, 12:10:05\u001b[0m\n",
      "\u001b[94mStep: 368, PSNR Before: 24.907724, PSNR After: 24.907738, PSNR Change: 0.000013, PSNR Diff: 0.002205 (New Max), Reward: 1.07, 12:10:11\u001b[0m\n",
      "\u001b[94mStep: 370, PSNR Before: 24.907738, PSNR After: 24.907835, PSNR Change: 0.000097, PSNR Diff: 0.002302 (New Max), Reward: 7.78, 12:10:13\u001b[0m\n",
      "\u001b[94mStep: 384, PSNR Before: 24.907835, PSNR After: 24.907856, PSNR Change: 0.000021, PSNR Diff: 0.002323 (New Max), Reward: 1.68, 12:10:26\u001b[0m\n",
      "\u001b[94mStep: 387, PSNR Before: 24.907856, PSNR After: 24.907873, PSNR Change: 0.000017, PSNR Diff: 0.002340 (New Max), Reward: 1.37, 12:10:30\u001b[0m\n",
      "\u001b[94mStep: 394, PSNR Before: 24.907873, PSNR After: 24.907942, PSNR Change: 0.000069, PSNR Diff: 0.002409 (New Max), Reward: 5.49, 12:10:37\u001b[0m\n",
      "\u001b[94mStep: 398, PSNR Before: 24.907942, PSNR After: 24.907991, PSNR Change: 0.000050, PSNR Diff: 0.002459 (New Max), Reward: 3.97, 12:10:41\u001b[0m\n",
      "\u001b[94mStep: 401, PSNR Before: 24.907991, PSNR After: 24.908031, PSNR Change: 0.000040, PSNR Diff: 0.002499 (New Max), Reward: 3.20, 12:10:45\u001b[0m\n",
      "\u001b[94mStep: 406, PSNR Before: 24.908031, PSNR After: 24.908047, PSNR Change: 0.000015, PSNR Diff: 0.002514 (New Max), Reward: 1.22, 12:10:50\u001b[0m\n",
      "\u001b[94mStep: 410, PSNR Before: 24.908047, PSNR After: 24.908070, PSNR Change: 0.000023, PSNR Diff: 0.002537 (New Max), Reward: 1.83, 12:10:55\u001b[0m\n",
      "\u001b[94mStep: 415, PSNR Before: 24.908070, PSNR After: 24.908102, PSNR Change: 0.000032, PSNR Diff: 0.002569 (New Max), Reward: 2.59, 12:11:00\u001b[0m\n",
      "\u001b[94mStep: 416, PSNR Before: 24.908102, PSNR After: 24.908180, PSNR Change: 0.000078, PSNR Diff: 0.002647 (New Max), Reward: 6.26, 12:11:02\u001b[0m\n",
      "\u001b[94mStep: 420, PSNR Before: 24.908180, PSNR After: 24.908184, PSNR Change: 0.000004, PSNR Diff: 0.002651 (New Max), Reward: 0.31, 12:11:06\u001b[0m\n",
      "\u001b[94mStep: 422, PSNR Before: 24.908184, PSNR After: 24.908195, PSNR Change: 0.000011, PSNR Diff: 0.002663 (New Max), Reward: 0.92, 12:11:09\u001b[0m\n",
      "\u001b[94mStep: 432, PSNR Before: 24.908195, PSNR After: 24.908197, PSNR Change: 0.000002, PSNR Diff: 0.002665 (New Max), Reward: 0.15, 12:11:19\u001b[0m\n",
      "\u001b[94mStep: 438, PSNR Before: 24.908197, PSNR After: 24.908239, PSNR Change: 0.000042, PSNR Diff: 0.002707 (New Max), Reward: 3.36, 12:11:26\u001b[0m\n",
      "\u001b[94mStep: 439, PSNR Before: 24.908239, PSNR After: 24.908268, PSNR Change: 0.000029, PSNR Diff: 0.002735 (New Max), Reward: 2.29, 12:11:28\u001b[0m\n",
      "\u001b[94mStep: 444, PSNR Before: 24.908268, PSNR After: 24.908298, PSNR Change: 0.000031, PSNR Diff: 0.002766 (New Max), Reward: 2.44, 12:11:33\u001b[0m\n",
      "\u001b[94mStep: 446, PSNR Before: 24.908298, PSNR After: 24.908306, PSNR Change: 0.000008, PSNR Diff: 0.002773 (New Max), Reward: 0.61, 12:11:36\u001b[0m\n",
      "\u001b[94mStep: 468, PSNR Before: 24.908306, PSNR After: 24.908344, PSNR Change: 0.000038, PSNR Diff: 0.002811 (New Max), Reward: 3.05, 12:11:59\u001b[0m\n",
      "\u001b[94mStep: 470, PSNR Before: 24.908344, PSNR After: 24.908440, PSNR Change: 0.000095, PSNR Diff: 0.002907 (New Max), Reward: 7.63, 12:12:01\u001b[0m\n",
      "\u001b[94mStep: 474, PSNR Before: 24.908440, PSNR After: 24.908457, PSNR Change: 0.000017, PSNR Diff: 0.002924 (New Max), Reward: 1.37, 12:12:06\u001b[0m\n",
      "\u001b[94mStep: 476, PSNR Before: 24.908457, PSNR After: 24.908470, PSNR Change: 0.000013, PSNR Diff: 0.002937 (New Max), Reward: 1.07, 12:12:08\u001b[0m\n",
      "\u001b[94mStep: 484, PSNR Before: 24.908470, PSNR After: 24.908512, PSNR Change: 0.000042, PSNR Diff: 0.002979 (New Max), Reward: 3.36, 12:12:17\u001b[0m\n",
      "\u001b[94mStep: 485, PSNR Before: 24.908512, PSNR After: 24.908558, PSNR Change: 0.000046, PSNR Diff: 0.003025 (New Max), Reward: 3.66, 12:12:18\u001b[0m\n",
      "\u001b[94mStep: 486, PSNR Before: 24.908558, PSNR After: 24.908560, PSNR Change: 0.000002, PSNR Diff: 0.003027 (New Max), Reward: 0.15, 12:12:20\u001b[0m\n",
      "\u001b[94mStep: 489, PSNR Before: 24.908560, PSNR After: 24.908607, PSNR Change: 0.000048, PSNR Diff: 0.003075 (New Max), Reward: 3.81, 12:12:24\u001b[0m\n",
      "\u001b[94mStep: 491, PSNR Before: 24.908607, PSNR After: 24.908609, PSNR Change: 0.000002, PSNR Diff: 0.003077 (New Max), Reward: 0.15, 12:12:26\u001b[0m\n",
      "\u001b[94mStep: 496, PSNR Before: 24.908609, PSNR After: 24.908623, PSNR Change: 0.000013, PSNR Diff: 0.003090 (New Max), Reward: 1.07, 12:12:32\u001b[0m\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 567           |\n",
      "|    total_timesteps      | 512           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0721927e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -14.6         |\n",
      "|    explained_variance   | 0.000507      |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 0.0703        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -5.4e-05      |\n",
      "|    value_loss           | 0.413         |\n",
      "-------------------------------------------\n",
      "\u001b[94mStep: 510, PSNR Before: 24.908623, PSNR After: 24.908667, PSNR Change: 0.000044, PSNR Diff: 0.003134 (New Max), Reward: 3.51, 12:12:53\u001b[0m\n",
      "\u001b[94mStep: 514, PSNR Before: 24.908667, PSNR After: 24.908684, PSNR Change: 0.000017, PSNR Diff: 0.003151 (New Max), Reward: 1.37, 12:12:57\u001b[0m\n",
      "\u001b[94mStep: 515, PSNR Before: 24.908684, PSNR After: 24.908691, PSNR Change: 0.000008, PSNR Diff: 0.003159 (New Max), Reward: 0.61, 12:12:59\u001b[0m\n",
      "\u001b[94mStep: 519, PSNR Before: 24.908691, PSNR After: 24.908760, PSNR Change: 0.000069, PSNR Diff: 0.003227 (New Max), Reward: 5.49, 12:13:04\u001b[0m\n",
      "\u001b[94mStep: 523, PSNR Before: 24.908760, PSNR After: 24.908779, PSNR Change: 0.000019, PSNR Diff: 0.003246 (New Max), Reward: 1.53, 12:13:09\u001b[0m\n",
      "\u001b[94mStep: 525, PSNR Before: 24.908779, PSNR After: 24.908794, PSNR Change: 0.000015, PSNR Diff: 0.003262 (New Max), Reward: 1.22, 12:13:11\u001b[0m\n",
      "\u001b[94mStep: 529, PSNR Before: 24.908794, PSNR After: 24.908857, PSNR Change: 0.000063, PSNR Diff: 0.003325 (New Max), Reward: 5.04, 12:13:16\u001b[0m\n",
      "\u001b[94mStep: 530, PSNR Before: 24.908857, PSNR After: 24.908890, PSNR Change: 0.000032, PSNR Diff: 0.003357 (New Max), Reward: 2.59, 12:13:18\u001b[0m\n",
      "\u001b[94mStep: 531, PSNR Before: 24.908890, PSNR After: 24.908926, PSNR Change: 0.000036, PSNR Diff: 0.003393 (New Max), Reward: 2.90, 12:13:19\u001b[0m\n",
      "\u001b[94mStep: 533, PSNR Before: 24.908926, PSNR After: 24.908936, PSNR Change: 0.000010, PSNR Diff: 0.003403 (New Max), Reward: 0.76, 12:13:22\u001b[0m\n",
      "\u001b[94mStep: 534, PSNR Before: 24.908936, PSNR After: 24.908943, PSNR Change: 0.000008, PSNR Diff: 0.003410 (New Max), Reward: 0.61, 12:13:24\u001b[0m\n",
      "\u001b[94mStep: 536, PSNR Before: 24.908943, PSNR After: 24.908958, PSNR Change: 0.000015, PSNR Diff: 0.003426 (New Max), Reward: 1.22, 12:13:27\u001b[0m\n",
      "\u001b[94mStep: 548, PSNR Before: 24.908958, PSNR After: 24.909019, PSNR Change: 0.000061, PSNR Diff: 0.003487 (New Max), Reward: 4.88, 12:13:39\u001b[0m\n",
      "\u001b[94mStep: 551, PSNR Before: 24.909019, PSNR After: 24.909073, PSNR Change: 0.000053, PSNR Diff: 0.003540 (New Max), Reward: 4.27, 12:13:43\u001b[0m\n",
      "\u001b[94mStep: 556, PSNR Before: 24.909073, PSNR After: 24.909098, PSNR Change: 0.000025, PSNR Diff: 0.003565 (New Max), Reward: 1.98, 12:13:48\u001b[0m\n",
      "\u001b[94mStep: 558, PSNR Before: 24.909098, PSNR After: 24.909134, PSNR Change: 0.000036, PSNR Diff: 0.003601 (New Max), Reward: 2.90, 12:13:50\u001b[0m\n",
      "\u001b[94mStep: 561, PSNR Before: 24.909134, PSNR After: 24.909145, PSNR Change: 0.000011, PSNR Diff: 0.003613 (New Max), Reward: 0.92, 12:13:54\u001b[0m\n",
      "\u001b[94mStep: 569, PSNR Before: 24.909145, PSNR After: 24.909168, PSNR Change: 0.000023, PSNR Diff: 0.003635 (New Max), Reward: 1.83, 12:14:02\u001b[0m\n",
      "\u001b[94mStep: 577, PSNR Before: 24.909168, PSNR After: 24.909189, PSNR Change: 0.000021, PSNR Diff: 0.003656 (New Max), Reward: 1.68, 12:14:10\u001b[0m\n",
      "\u001b[94mStep: 588, PSNR Before: 24.909189, PSNR After: 24.909210, PSNR Change: 0.000021, PSNR Diff: 0.003677 (New Max), Reward: 1.68, 12:14:21\u001b[0m\n",
      "\u001b[94mStep: 590, PSNR Before: 24.909210, PSNR After: 24.909239, PSNR Change: 0.000029, PSNR Diff: 0.003706 (New Max), Reward: 2.29, 12:14:24\u001b[0m\n",
      "\u001b[94mStep: 598, PSNR Before: 24.909239, PSNR After: 24.909323, PSNR Change: 0.000084, PSNR Diff: 0.003790 (New Max), Reward: 6.71, 12:14:32\u001b[0m\n",
      "\u001b[94mStep: 601, PSNR Before: 24.909323, PSNR After: 24.909418, PSNR Change: 0.000095, PSNR Diff: 0.003885 (New Max), Reward: 7.63, 12:14:35\u001b[0m\n",
      "\u001b[94mStep: 603, PSNR Before: 24.909418, PSNR After: 24.909475, PSNR Change: 0.000057, PSNR Diff: 0.003942 (New Max), Reward: 4.58, 12:14:38\u001b[0m\n",
      "\u001b[94mStep: 609, PSNR Before: 24.909475, PSNR After: 24.909492, PSNR Change: 0.000017, PSNR Diff: 0.003960 (New Max), Reward: 1.37, 12:14:44\u001b[0m\n",
      "\u001b[94mStep: 615, PSNR Before: 24.909492, PSNR After: 24.909500, PSNR Change: 0.000008, PSNR Diff: 0.003967 (New Max), Reward: 0.61, 12:14:50\u001b[0m\n",
      "\u001b[94mStep: 617, PSNR Before: 24.909500, PSNR After: 24.909517, PSNR Change: 0.000017, PSNR Diff: 0.003984 (New Max), Reward: 1.37, 12:14:53\u001b[0m\n",
      "\u001b[94mStep: 625, PSNR Before: 24.909517, PSNR After: 24.909582, PSNR Change: 0.000065, PSNR Diff: 0.004049 (New Max), Reward: 5.19, 12:15:01\u001b[0m\n",
      "\u001b[94mStep: 629, PSNR Before: 24.909582, PSNR After: 24.909590, PSNR Change: 0.000008, PSNR Diff: 0.004057 (New Max), Reward: 0.61, 12:15:05\u001b[0m\n",
      "\u001b[94mStep: 631, PSNR Before: 24.909590, PSNR After: 24.909613, PSNR Change: 0.000023, PSNR Diff: 0.004080 (New Max), Reward: 1.83, 12:15:08\u001b[0m\n",
      "\u001b[94mStep: 644, PSNR Before: 24.909613, PSNR After: 24.909695, PSNR Change: 0.000082, PSNR Diff: 0.004162 (New Max), Reward: 6.56, 12:15:21\u001b[0m\n",
      "\u001b[94mStep: 645, PSNR Before: 24.909695, PSNR After: 24.909698, PSNR Change: 0.000004, PSNR Diff: 0.004166 (New Max), Reward: 0.31, 12:15:23\u001b[0m\n",
      "\u001b[94mStep: 650, PSNR Before: 24.909698, PSNR After: 24.909708, PSNR Change: 0.000010, PSNR Diff: 0.004175 (New Max), Reward: 0.76, 12:15:28\u001b[0m\n",
      "\u001b[94mStep: 654, PSNR Before: 24.909708, PSNR After: 24.909721, PSNR Change: 0.000013, PSNR Diff: 0.004189 (New Max), Reward: 1.07, 12:15:33\u001b[0m\n",
      "\u001b[94mStep: 659, PSNR Before: 24.909721, PSNR After: 24.909746, PSNR Change: 0.000025, PSNR Diff: 0.004213 (New Max), Reward: 1.98, 12:15:38\u001b[0m\n",
      "\u001b[94mStep: 661, PSNR Before: 24.909746, PSNR After: 24.909771, PSNR Change: 0.000025, PSNR Diff: 0.004238 (New Max), Reward: 1.98, 12:15:41\u001b[0m\n",
      "\u001b[94mStep: 666, PSNR Before: 24.909771, PSNR After: 24.909773, PSNR Change: 0.000002, PSNR Diff: 0.004240 (New Max), Reward: 0.15, 12:15:46\u001b[0m\n",
      "\u001b[94mStep: 668, PSNR Before: 24.909773, PSNR After: 24.909786, PSNR Change: 0.000013, PSNR Diff: 0.004253 (New Max), Reward: 1.07, 12:15:49\u001b[0m\n",
      "\u001b[94mStep: 672, PSNR Before: 24.909786, PSNR After: 24.909851, PSNR Change: 0.000065, PSNR Diff: 0.004318 (New Max), Reward: 5.19, 12:15:54\u001b[0m\n",
      "\u001b[94mStep: 684, PSNR Before: 24.909851, PSNR After: 24.909857, PSNR Change: 0.000006, PSNR Diff: 0.004324 (New Max), Reward: 0.46, 12:16:05\u001b[0m\n",
      "\u001b[94mStep: 693, PSNR Before: 24.909857, PSNR After: 24.909870, PSNR Change: 0.000013, PSNR Diff: 0.004337 (New Max), Reward: 1.07, 12:16:15\u001b[0m\n",
      "\u001b[94mStep: 698, PSNR Before: 24.909870, PSNR After: 24.909882, PSNR Change: 0.000011, PSNR Diff: 0.004349 (New Max), Reward: 0.92, 12:16:20\u001b[0m\n",
      "\u001b[94mStep: 701, PSNR Before: 24.909882, PSNR After: 24.909899, PSNR Change: 0.000017, PSNR Diff: 0.004366 (New Max), Reward: 1.37, 12:16:24\u001b[0m\n",
      "\u001b[94mStep: 721, PSNR Before: 24.909899, PSNR After: 24.909937, PSNR Change: 0.000038, PSNR Diff: 0.004404 (New Max), Reward: 3.05, 12:16:43\u001b[0m\n",
      "\u001b[94mStep: 724, PSNR Before: 24.909937, PSNR After: 24.910002, PSNR Change: 0.000065, PSNR Diff: 0.004469 (New Max), Reward: 5.19, 12:16:46\u001b[0m\n",
      "\u001b[94mStep: 729, PSNR Before: 24.910002, PSNR After: 24.910013, PSNR Change: 0.000011, PSNR Diff: 0.004480 (New Max), Reward: 0.92, 12:16:52\u001b[0m\n",
      "\u001b[94mStep: 742, PSNR Before: 24.910013, PSNR After: 24.910038, PSNR Change: 0.000025, PSNR Diff: 0.004505 (New Max), Reward: 1.98, 12:17:05\u001b[0m\n",
      "\u001b[94mStep: 744, PSNR Before: 24.910038, PSNR After: 24.910057, PSNR Change: 0.000019, PSNR Diff: 0.004524 (New Max), Reward: 1.53, 12:17:07\u001b[0m\n",
      "\u001b[94mStep: 750, PSNR Before: 24.910057, PSNR After: 24.910061, PSNR Change: 0.000004, PSNR Diff: 0.004528 (New Max), Reward: 0.31, 12:17:14\u001b[0m\n",
      "\u001b[94mStep: 752, PSNR Before: 24.910061, PSNR After: 24.910070, PSNR Change: 0.000010, PSNR Diff: 0.004538 (New Max), Reward: 0.76, 12:17:17\u001b[0m\n",
      "\u001b[94mStep: 756, PSNR Before: 24.910070, PSNR After: 24.910088, PSNR Change: 0.000017, PSNR Diff: 0.004555 (New Max), Reward: 1.37, 12:17:21\u001b[0m\n",
      "\u001b[94mStep: 758, PSNR Before: 24.910088, PSNR After: 24.910152, PSNR Change: 0.000065, PSNR Diff: 0.004620 (New Max), Reward: 5.19, 12:17:24\u001b[0m\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 853           |\n",
      "|    total_timesteps      | 768           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3993274e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -14.6         |\n",
      "|    explained_variance   | 0.155         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 0.12          |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -9.7e-05      |\n",
      "|    value_loss           | 0.382         |\n",
      "-------------------------------------------\n",
      "\u001b[94mStep: 768, PSNR Before: 24.910152, PSNR After: 24.910179, PSNR Change: 0.000027, PSNR Diff: 0.004646 (New Max), Reward: 2.14, 12:17:41\u001b[0m\n",
      "\u001b[94mStep: 769, PSNR Before: 24.910179, PSNR After: 24.910183, PSNR Change: 0.000004, PSNR Diff: 0.004650 (New Max), Reward: 0.31, 12:17:42\u001b[0m\n",
      "\u001b[94mStep: 770, PSNR Before: 24.910183, PSNR After: 24.910219, PSNR Change: 0.000036, PSNR Diff: 0.004686 (New Max), Reward: 2.90, 12:17:44\u001b[0m\n",
      "\u001b[94mStep: 772, PSNR Before: 24.910219, PSNR After: 24.910362, PSNR Change: 0.000143, PSNR Diff: 0.004829 (New Max), Reward: 11.44, 12:17:47\u001b[0m\n",
      "\u001b[94mStep: 782, PSNR Before: 24.910362, PSNR After: 24.910374, PSNR Change: 0.000011, PSNR Diff: 0.004841 (New Max), Reward: 0.92, 12:17:57\u001b[0m\n",
      "\u001b[94mStep: 784, PSNR Before: 24.910374, PSNR After: 24.910381, PSNR Change: 0.000008, PSNR Diff: 0.004848 (New Max), Reward: 0.61, 12:18:00\u001b[0m\n",
      "\u001b[94mStep: 785, PSNR Before: 24.910381, PSNR After: 24.910484, PSNR Change: 0.000103, PSNR Diff: 0.004951 (New Max), Reward: 8.24, 12:18:01\u001b[0m\n",
      "\u001b[94mStep: 787, PSNR Before: 24.910484, PSNR After: 24.910522, PSNR Change: 0.000038, PSNR Diff: 0.004990 (New Max), Reward: 3.05, 12:18:04\u001b[0m\n",
      "\u001b[94mStep: 789, PSNR Before: 24.910522, PSNR After: 24.910530, PSNR Change: 0.000008, PSNR Diff: 0.004997 (New Max), Reward: 0.61, 12:18:07\u001b[0m\n",
      "\u001b[94mStep: 792, PSNR Before: 24.910530, PSNR After: 24.910553, PSNR Change: 0.000023, PSNR Diff: 0.005020 (New Max), Reward: 1.83, 12:18:10\u001b[0m\n",
      "\u001b[94mStep: 796, PSNR Before: 24.910553, PSNR After: 24.910595, PSNR Change: 0.000042, PSNR Diff: 0.005062 (New Max), Reward: 3.36, 12:18:15\u001b[0m\n",
      "\u001b[94mStep: 801, PSNR Before: 24.910595, PSNR After: 24.910707, PSNR Change: 0.000113, PSNR Diff: 0.005175 (New Max), Reward: 9.00, 12:18:20\u001b[0m\n",
      "\u001b[94mStep: 814, PSNR Before: 24.910707, PSNR After: 24.910738, PSNR Change: 0.000031, PSNR Diff: 0.005205 (New Max), Reward: 2.44, 12:18:34\u001b[0m\n",
      "\u001b[94mStep: 836, PSNR Before: 24.910738, PSNR After: 24.910740, PSNR Change: 0.000002, PSNR Diff: 0.005207 (New Max), Reward: 0.15, 12:18:55\u001b[0m\n",
      "\u001b[94mStep: 837, PSNR Before: 24.910740, PSNR After: 24.910772, PSNR Change: 0.000032, PSNR Diff: 0.005239 (New Max), Reward: 2.59, 12:18:57\u001b[0m\n",
      "\u001b[94mStep: 839, PSNR Before: 24.910772, PSNR After: 24.910776, PSNR Change: 0.000004, PSNR Diff: 0.005243 (New Max), Reward: 0.31, 12:19:00\u001b[0m\n",
      "\u001b[94mStep: 842, PSNR Before: 24.910776, PSNR After: 24.910778, PSNR Change: 0.000002, PSNR Diff: 0.005245 (New Max), Reward: 0.15, 12:19:03\u001b[0m\n",
      "\u001b[94mStep: 844, PSNR Before: 24.910778, PSNR After: 24.910830, PSNR Change: 0.000051, PSNR Diff: 0.005297 (New Max), Reward: 4.12, 12:19:06\u001b[0m\n",
      "\u001b[94mStep: 845, PSNR Before: 24.910830, PSNR After: 24.910879, PSNR Change: 0.000050, PSNR Diff: 0.005346 (New Max), Reward: 3.97, 12:19:08\u001b[0m\n",
      "\u001b[94mStep: 846, PSNR Before: 24.910879, PSNR After: 24.910908, PSNR Change: 0.000029, PSNR Diff: 0.005375 (New Max), Reward: 2.29, 12:19:10\u001b[0m\n",
      "\u001b[94mStep: 848, PSNR Before: 24.910908, PSNR After: 24.910915, PSNR Change: 0.000008, PSNR Diff: 0.005383 (New Max), Reward: 0.61, 12:19:12\u001b[0m\n",
      "\u001b[94mStep: 851, PSNR Before: 24.910915, PSNR After: 24.910923, PSNR Change: 0.000008, PSNR Diff: 0.005390 (New Max), Reward: 0.61, 12:19:16\u001b[0m\n",
      "\u001b[94mStep: 854, PSNR Before: 24.910923, PSNR After: 24.910948, PSNR Change: 0.000025, PSNR Diff: 0.005415 (New Max), Reward: 1.98, 12:19:20\u001b[0m\n",
      "\u001b[94mStep: 863, PSNR Before: 24.910948, PSNR After: 24.910988, PSNR Change: 0.000040, PSNR Diff: 0.005455 (New Max), Reward: 3.20, 12:19:29\u001b[0m\n",
      "\u001b[94mStep: 868, PSNR Before: 24.910988, PSNR After: 24.911049, PSNR Change: 0.000061, PSNR Diff: 0.005516 (New Max), Reward: 4.88, 12:19:35\u001b[0m\n",
      "\u001b[94mStep: 869, PSNR Before: 24.911049, PSNR After: 24.911070, PSNR Change: 0.000021, PSNR Diff: 0.005537 (New Max), Reward: 1.68, 12:19:37\u001b[0m\n",
      "\u001b[94mStep: 874, PSNR Before: 24.911070, PSNR After: 24.911072, PSNR Change: 0.000002, PSNR Diff: 0.005539 (New Max), Reward: 0.15, 12:19:42\u001b[0m\n",
      "\u001b[94mStep: 875, PSNR Before: 24.911072, PSNR After: 24.911097, PSNR Change: 0.000025, PSNR Diff: 0.005564 (New Max), Reward: 1.98, 12:19:44\u001b[0m\n",
      "\u001b[94mStep: 881, PSNR Before: 24.911097, PSNR After: 24.911144, PSNR Change: 0.000048, PSNR Diff: 0.005611 (New Max), Reward: 3.81, 12:19:51\u001b[0m\n",
      "\u001b[94mStep: 886, PSNR Before: 24.911144, PSNR After: 24.911152, PSNR Change: 0.000008, PSNR Diff: 0.005619 (New Max), Reward: 0.61, 12:19:57\u001b[0m\n",
      "\u001b[94mStep: 888, PSNR Before: 24.911152, PSNR After: 24.911190, PSNR Change: 0.000038, PSNR Diff: 0.005657 (New Max), Reward: 3.05, 12:19:59\u001b[0m\n",
      "\u001b[94mStep: 892, PSNR Before: 24.911190, PSNR After: 24.911221, PSNR Change: 0.000031, PSNR Diff: 0.005688 (New Max), Reward: 2.44, 12:20:04\u001b[0m\n",
      "\u001b[94mStep: 916, PSNR Before: 24.911221, PSNR After: 24.911222, PSNR Change: 0.000002, PSNR Diff: 0.005690 (New Max), Reward: 0.15, 12:20:26\u001b[0m\n",
      "\u001b[94mStep: 922, PSNR Before: 24.911222, PSNR After: 24.911263, PSNR Change: 0.000040, PSNR Diff: 0.005730 (New Max), Reward: 3.20, 12:20:32\u001b[0m\n",
      "\u001b[94mStep: 931, PSNR Before: 24.911263, PSNR After: 24.911331, PSNR Change: 0.000069, PSNR Diff: 0.005798 (New Max), Reward: 5.49, 12:20:42\u001b[0m\n",
      "\u001b[94mStep: 934, PSNR Before: 24.911331, PSNR After: 24.911348, PSNR Change: 0.000017, PSNR Diff: 0.005816 (New Max), Reward: 1.37, 12:20:45\u001b[0m\n",
      "\u001b[94mStep: 936, PSNR Before: 24.911348, PSNR After: 24.911381, PSNR Change: 0.000032, PSNR Diff: 0.005848 (New Max), Reward: 2.59, 12:20:48\u001b[0m\n",
      "\u001b[94mStep: 953, PSNR Before: 24.911381, PSNR After: 24.911411, PSNR Change: 0.000031, PSNR Diff: 0.005878 (New Max), Reward: 2.44, 12:21:04\u001b[0m\n",
      "\u001b[94mStep: 955, PSNR Before: 24.911411, PSNR After: 24.911533, PSNR Change: 0.000122, PSNR Diff: 0.006001 (New Max), Reward: 9.77, 12:21:07\u001b[0m\n",
      "\u001b[94mStep: 968, PSNR Before: 24.911533, PSNR After: 24.911564, PSNR Change: 0.000031, PSNR Diff: 0.006031 (New Max), Reward: 2.44, 12:21:21\u001b[0m\n",
      "\u001b[94mStep: 984, PSNR Before: 24.911564, PSNR After: 24.911577, PSNR Change: 0.000013, PSNR Diff: 0.006044 (New Max), Reward: 1.07, 12:21:36\u001b[0m\n",
      "\u001b[94mStep: 993, PSNR Before: 24.911577, PSNR After: 24.911594, PSNR Change: 0.000017, PSNR Diff: 0.006062 (New Max), Reward: 1.37, 12:21:45\u001b[0m\n",
      "\u001b[94mStep: 996, PSNR Before: 24.911594, PSNR After: 24.911598, PSNR Change: 0.000004, PSNR Diff: 0.006065 (New Max), Reward: 0.31, 12:21:49\u001b[0m\n",
      "\u001b[94mStep: 1004, PSNR Before: 24.911598, PSNR After: 24.911648, PSNR Change: 0.000050, PSNR Diff: 0.006115 (New Max), Reward: 3.97, 12:21:58\u001b[0m\n",
      "\u001b[94mStep: 1007, PSNR Before: 24.911648, PSNR After: 24.911758, PSNR Change: 0.000111, PSNR Diff: 0.006226 (New Max), Reward: 8.85, 12:22:01\u001b[0m\n",
      "\u001b[94mStep: 1010, PSNR Before: 24.911758, PSNR After: 24.911766, PSNR Change: 0.000008, PSNR Diff: 0.006233 (New Max), Reward: 0.61, 12:22:05\u001b[0m\n",
      "\u001b[94mStep: 1011, PSNR Before: 24.911766, PSNR After: 24.911777, PSNR Change: 0.000011, PSNR Diff: 0.006245 (New Max), Reward: 0.92, 12:22:07\u001b[0m\n",
      "\u001b[94mStep: 1015, PSNR Before: 24.911777, PSNR After: 24.911789, PSNR Change: 0.000011, PSNR Diff: 0.006256 (New Max), Reward: 0.92, 12:22:12\u001b[0m\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 1138         |\n",
      "|    total_timesteps      | 1024         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.075708e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -14.6        |\n",
      "|    explained_variance   | 0.0352       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.304        |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.000119    |\n",
      "|    value_loss           | 0.748        |\n",
      "------------------------------------------\n",
      "\u001b[94mStep: 1028, PSNR Before: 24.911789, PSNR After: 24.911816, PSNR Change: 0.000027, PSNR Diff: 0.006283 (New Max), Reward: 2.14, 12:22:32\u001b[0m\n",
      "\u001b[94mStep: 1042, PSNR Before: 24.911816, PSNR After: 24.911819, PSNR Change: 0.000004, PSNR Diff: 0.006287 (New Max), Reward: 0.31, 12:22:45\u001b[0m\n",
      "\u001b[94mStep: 1061, PSNR Before: 24.911819, PSNR After: 24.911850, PSNR Change: 0.000031, PSNR Diff: 0.006317 (New Max), Reward: 2.44, 12:23:03\u001b[0m\n",
      "\u001b[94mStep: 1065, PSNR Before: 24.911850, PSNR After: 24.911852, PSNR Change: 0.000002, PSNR Diff: 0.006319 (New Max), Reward: 0.15, 12:23:07\u001b[0m\n",
      "\u001b[94mStep: 1067, PSNR Before: 24.911852, PSNR After: 24.912018, PSNR Change: 0.000166, PSNR Diff: 0.006485 (New Max), Reward: 13.28, 12:23:10\u001b[0m\n",
      "\u001b[94mStep: 1070, PSNR Before: 24.912018, PSNR After: 24.912048, PSNR Change: 0.000031, PSNR Diff: 0.006516 (New Max), Reward: 2.44, 12:23:14\u001b[0m\n",
      "\u001b[94mStep: 1076, PSNR Before: 24.912048, PSNR After: 24.912081, PSNR Change: 0.000032, PSNR Diff: 0.006548 (New Max), Reward: 2.59, 12:23:20\u001b[0m\n",
      "\u001b[94mStep: 1079, PSNR Before: 24.912081, PSNR After: 24.912094, PSNR Change: 0.000013, PSNR Diff: 0.006561 (New Max), Reward: 1.07, 12:23:23\u001b[0m\n",
      "\u001b[94mStep: 1080, PSNR Before: 24.912094, PSNR After: 24.912117, PSNR Change: 0.000023, PSNR Diff: 0.006584 (New Max), Reward: 1.83, 12:23:25\u001b[0m\n",
      "\u001b[94mStep: 1083, PSNR Before: 24.912117, PSNR After: 24.912121, PSNR Change: 0.000004, PSNR Diff: 0.006588 (New Max), Reward: 0.31, 12:23:29\u001b[0m\n",
      "\u001b[94mStep: 1086, PSNR Before: 24.912121, PSNR After: 24.912167, PSNR Change: 0.000046, PSNR Diff: 0.006634 (New Max), Reward: 3.66, 12:23:32\u001b[0m\n",
      "\u001b[94mStep: 1109, PSNR Before: 24.912167, PSNR After: 24.912174, PSNR Change: 0.000008, PSNR Diff: 0.006641 (New Max), Reward: 0.61, 12:23:55\u001b[0m\n",
      "\u001b[94mStep: 1114, PSNR Before: 24.912174, PSNR After: 24.912231, PSNR Change: 0.000057, PSNR Diff: 0.006699 (New Max), Reward: 4.58, 12:24:00\u001b[0m\n",
      "\u001b[94mStep: 1119, PSNR Before: 24.912231, PSNR After: 24.912239, PSNR Change: 0.000008, PSNR Diff: 0.006706 (New Max), Reward: 0.61, 12:24:05\u001b[0m\n",
      "\u001b[94mStep: 1120, PSNR Before: 24.912239, PSNR After: 24.912245, PSNR Change: 0.000006, PSNR Diff: 0.006712 (New Max), Reward: 0.46, 12:24:07\u001b[0m\n",
      "\u001b[94mStep: 1122, PSNR Before: 24.912245, PSNR After: 24.912279, PSNR Change: 0.000034, PSNR Diff: 0.006746 (New Max), Reward: 2.75, 12:24:10\u001b[0m\n",
      "\u001b[94mStep: 1123, PSNR Before: 24.912279, PSNR After: 24.912292, PSNR Change: 0.000013, PSNR Diff: 0.006760 (New Max), Reward: 1.07, 12:24:11\u001b[0m\n",
      "\u001b[94mStep: 1132, PSNR Before: 24.912292, PSNR After: 24.912323, PSNR Change: 0.000031, PSNR Diff: 0.006790 (New Max), Reward: 2.44, 12:24:21\u001b[0m\n",
      "\u001b[94mStep: 1140, PSNR Before: 24.912323, PSNR After: 24.912357, PSNR Change: 0.000034, PSNR Diff: 0.006824 (New Max), Reward: 2.75, 12:24:29\u001b[0m\n",
      "\u001b[94mStep: 1146, PSNR Before: 24.912357, PSNR After: 24.912394, PSNR Change: 0.000036, PSNR Diff: 0.006861 (New Max), Reward: 2.90, 12:24:35\u001b[0m\n",
      "\u001b[94mStep: 1154, PSNR Before: 24.912394, PSNR After: 24.912399, PSNR Change: 0.000006, PSNR Diff: 0.006866 (New Max), Reward: 0.46, 12:24:43\u001b[0m\n",
      "\u001b[94mStep: 1156, PSNR Before: 24.912399, PSNR After: 24.912416, PSNR Change: 0.000017, PSNR Diff: 0.006884 (New Max), Reward: 1.37, 12:24:46\u001b[0m\n",
      "\u001b[94mStep: 1160, PSNR Before: 24.912416, PSNR After: 24.912430, PSNR Change: 0.000013, PSNR Diff: 0.006897 (New Max), Reward: 1.07, 12:24:50\u001b[0m\n",
      "\u001b[94mStep: 1165, PSNR Before: 24.912430, PSNR After: 24.912451, PSNR Change: 0.000021, PSNR Diff: 0.006918 (New Max), Reward: 1.68, 12:24:56\u001b[0m\n",
      "\u001b[94mStep: 1174, PSNR Before: 24.912451, PSNR After: 24.912464, PSNR Change: 0.000013, PSNR Diff: 0.006931 (New Max), Reward: 1.07, 12:25:05\u001b[0m\n",
      "\u001b[94mStep: 1184, PSNR Before: 24.912464, PSNR After: 24.912508, PSNR Change: 0.000044, PSNR Diff: 0.006975 (New Max), Reward: 3.51, 12:25:15\u001b[0m\n",
      "\u001b[94mStep: 1185, PSNR Before: 24.912508, PSNR After: 24.912544, PSNR Change: 0.000036, PSNR Diff: 0.007011 (New Max), Reward: 2.90, 12:25:16\u001b[0m\n",
      "\u001b[94mStep: 1194, PSNR Before: 24.912544, PSNR After: 24.912550, PSNR Change: 0.000006, PSNR Diff: 0.007017 (New Max), Reward: 0.46, 12:25:26\u001b[0m\n",
      "\u001b[94mStep: 1204, PSNR Before: 24.912550, PSNR After: 24.912560, PSNR Change: 0.000010, PSNR Diff: 0.007027 (New Max), Reward: 0.76, 12:25:36\u001b[0m\n",
      "\u001b[94mStep: 1212, PSNR Before: 24.912560, PSNR After: 24.912577, PSNR Change: 0.000017, PSNR Diff: 0.007044 (New Max), Reward: 1.37, 12:25:44\u001b[0m\n",
      "\u001b[94mStep: 1246, PSNR Before: 24.912577, PSNR After: 24.912586, PSNR Change: 0.000010, PSNR Diff: 0.007053 (New Max), Reward: 0.76, 12:26:16\u001b[0m\n",
      "\u001b[94mStep: 1247, PSNR Before: 24.912586, PSNR After: 24.912628, PSNR Change: 0.000042, PSNR Diff: 0.007095 (New Max), Reward: 3.36, 12:26:18\u001b[0m\n",
      "\u001b[94mStep: 1259, PSNR Before: 24.912628, PSNR After: 24.912718, PSNR Change: 0.000090, PSNR Diff: 0.007185 (New Max), Reward: 7.17, 12:26:30\u001b[0m\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 1408         |\n",
      "|    total_timesteps      | 1280         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.892959e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -14.6        |\n",
      "|    explained_variance   | -0.0151      |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.331        |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.000155    |\n",
      "|    value_loss           | 0.769        |\n",
      "------------------------------------------\n",
      "\u001b[94mStep: 1283, PSNR Before: 24.912718, PSNR After: 24.912735, PSNR Change: 0.000017, PSNR Diff: 0.007202 (New Max), Reward: 1.37, 12:27:00\u001b[0m\n",
      "\u001b[94mStep: 1284, PSNR Before: 24.912735, PSNR After: 24.912777, PSNR Change: 0.000042, PSNR Diff: 0.007244 (New Max), Reward: 3.36, 12:27:02\u001b[0m\n",
      "\u001b[94mStep: 1285, PSNR Before: 24.912777, PSNR After: 24.912807, PSNR Change: 0.000031, PSNR Diff: 0.007275 (New Max), Reward: 2.44, 12:27:04\u001b[0m\n",
      "\u001b[94mStep: 1293, PSNR Before: 24.912807, PSNR After: 24.912830, PSNR Change: 0.000023, PSNR Diff: 0.007298 (New Max), Reward: 1.83, 12:27:12\u001b[0m\n",
      "\u001b[94mStep: 1302, PSNR Before: 24.912830, PSNR After: 24.912842, PSNR Change: 0.000011, PSNR Diff: 0.007309 (New Max), Reward: 0.92, 12:27:21\u001b[0m\n",
      "\u001b[94mStep: 1313, PSNR Before: 24.912842, PSNR After: 24.912851, PSNR Change: 0.000010, PSNR Diff: 0.007318 (New Max), Reward: 0.76, 12:27:32\u001b[0m\n",
      "\u001b[94mStep: 1319, PSNR Before: 24.912851, PSNR After: 24.912891, PSNR Change: 0.000040, PSNR Diff: 0.007359 (New Max), Reward: 3.20, 12:27:38\u001b[0m\n",
      "\u001b[94mStep: 1331, PSNR Before: 24.912891, PSNR After: 24.912910, PSNR Change: 0.000019, PSNR Diff: 0.007378 (New Max), Reward: 1.53, 12:27:50\u001b[0m\n",
      "\u001b[94mStep: 1337, PSNR Before: 24.912910, PSNR After: 24.912926, PSNR Change: 0.000015, PSNR Diff: 0.007393 (New Max), Reward: 1.22, 12:27:56\u001b[0m\n",
      "\u001b[94mStep: 1340, PSNR Before: 24.912926, PSNR After: 24.912930, PSNR Change: 0.000004, PSNR Diff: 0.007397 (New Max), Reward: 0.31, 12:28:00\u001b[0m\n",
      "\u001b[94mStep: 1342, PSNR Before: 24.912930, PSNR After: 24.912951, PSNR Change: 0.000021, PSNR Diff: 0.007418 (New Max), Reward: 1.68, 12:28:03\u001b[0m\n",
      "\u001b[94mStep: 1343, PSNR Before: 24.912951, PSNR After: 24.912971, PSNR Change: 0.000021, PSNR Diff: 0.007439 (New Max), Reward: 1.68, 12:28:04\u001b[0m\n",
      "\u001b[94mStep: 1344, PSNR Before: 24.912971, PSNR After: 24.913006, PSNR Change: 0.000034, PSNR Diff: 0.007473 (New Max), Reward: 2.75, 12:28:06\u001b[0m\n",
      "\u001b[94mStep: 1346, PSNR Before: 24.913006, PSNR After: 24.913052, PSNR Change: 0.000046, PSNR Diff: 0.007519 (New Max), Reward: 3.66, 12:28:09\u001b[0m\n",
      "\u001b[94mStep: 1363, PSNR Before: 24.913052, PSNR After: 24.913116, PSNR Change: 0.000065, PSNR Diff: 0.007584 (New Max), Reward: 5.19, 12:28:26\u001b[0m\n",
      "\u001b[94mStep: 1378, PSNR Before: 24.913116, PSNR After: 24.913195, PSNR Change: 0.000078, PSNR Diff: 0.007662 (New Max), Reward: 6.26, 12:28:40\u001b[0m\n",
      "\u001b[94mStep: 1384, PSNR Before: 24.913195, PSNR After: 24.913208, PSNR Change: 0.000013, PSNR Diff: 0.007675 (New Max), Reward: 1.07, 12:28:47\u001b[0m\n",
      "\u001b[94mStep: 1386, PSNR Before: 24.913208, PSNR After: 24.913387, PSNR Change: 0.000179, PSNR Diff: 0.007854 (New Max), Reward: 14.34, 12:28:50\u001b[0m\n",
      "\u001b[94mStep: 1391, PSNR Before: 24.913387, PSNR After: 24.913397, PSNR Change: 0.000010, PSNR Diff: 0.007864 (New Max), Reward: 0.76, 12:28:55\u001b[0m\n",
      "\u001b[94mStep: 1393, PSNR Before: 24.913397, PSNR After: 24.913406, PSNR Change: 0.000010, PSNR Diff: 0.007874 (New Max), Reward: 0.76, 12:28:58\u001b[0m\n",
      "\u001b[94mStep: 1400, PSNR Before: 24.913406, PSNR After: 24.913446, PSNR Change: 0.000040, PSNR Diff: 0.007914 (New Max), Reward: 3.20, 12:29:05\u001b[0m\n",
      "Step: 1400, PSNR Before: 24.913406, PSNR After: 24.913446, PSNR Change: 0.000040, PSNR Diff: 0.007914, Reward: 3.20, 12:29:05\n",
      "\u001b[94mStep: 1403, PSNR Before: 24.913446, PSNR After: 24.913465, PSNR Change: 0.000019, PSNR Diff: 0.007933 (New Max), Reward: 1.53, 12:29:09\u001b[0m\n",
      "\u001b[94mStep: 1404, PSNR Before: 24.913465, PSNR After: 24.913492, PSNR Change: 0.000027, PSNR Diff: 0.007959 (New Max), Reward: 2.14, 12:29:10\u001b[0m\n",
      "\u001b[94mStep: 1405, PSNR Before: 24.913492, PSNR After: 24.913513, PSNR Change: 0.000021, PSNR Diff: 0.007980 (New Max), Reward: 1.68, 12:29:12\u001b[0m\n",
      "\u001b[94mStep: 1407, PSNR Before: 24.913513, PSNR After: 24.913528, PSNR Change: 0.000015, PSNR Diff: 0.007996 (New Max), Reward: 1.22, 12:29:15\u001b[0m\n",
      "\u001b[94mStep: 1408, PSNR Before: 24.913528, PSNR After: 24.913551, PSNR Change: 0.000023, PSNR Diff: 0.008018 (New Max), Reward: 1.83, 12:29:17\u001b[0m\n",
      "\u001b[94mStep: 1411, PSNR Before: 24.913551, PSNR After: 24.913574, PSNR Change: 0.000023, PSNR Diff: 0.008041 (New Max), Reward: 1.83, 12:29:20\u001b[0m\n",
      "\u001b[94mStep: 1423, PSNR Before: 24.913574, PSNR After: 24.913631, PSNR Change: 0.000057, PSNR Diff: 0.008099 (New Max), Reward: 4.58, 12:29:32\u001b[0m\n",
      "\u001b[94mStep: 1434, PSNR Before: 24.913631, PSNR After: 24.913633, PSNR Change: 0.000002, PSNR Diff: 0.008101 (New Max), Reward: 0.15, 12:29:43\u001b[0m\n",
      "\u001b[94mStep: 1441, PSNR Before: 24.913633, PSNR After: 24.913727, PSNR Change: 0.000093, PSNR Diff: 0.008194 (New Max), Reward: 7.48, 12:29:50\u001b[0m\n",
      "\u001b[94mStep: 1443, PSNR Before: 24.913727, PSNR After: 24.913765, PSNR Change: 0.000038, PSNR Diff: 0.008232 (New Max), Reward: 3.05, 12:29:53\u001b[0m\n",
      "\u001b[94mStep: 1451, PSNR Before: 24.913765, PSNR After: 24.913788, PSNR Change: 0.000023, PSNR Diff: 0.008255 (New Max), Reward: 1.83, 12:30:01\u001b[0m\n",
      "\u001b[94mStep: 1465, PSNR Before: 24.913788, PSNR After: 24.913824, PSNR Change: 0.000036, PSNR Diff: 0.008291 (New Max), Reward: 2.90, 12:30:15\u001b[0m\n",
      "\u001b[94mStep: 1467, PSNR Before: 24.913824, PSNR After: 24.913837, PSNR Change: 0.000013, PSNR Diff: 0.008305 (New Max), Reward: 1.07, 12:30:18\u001b[0m\n",
      "\u001b[94mStep: 1468, PSNR Before: 24.913837, PSNR After: 24.913849, PSNR Change: 0.000011, PSNR Diff: 0.008316 (New Max), Reward: 0.92, 12:30:20\u001b[0m\n",
      "\u001b[94mStep: 1469, PSNR Before: 24.913849, PSNR After: 24.913860, PSNR Change: 0.000011, PSNR Diff: 0.008327 (New Max), Reward: 0.92, 12:30:21\u001b[0m\n",
      "\u001b[94mStep: 1472, PSNR Before: 24.913860, PSNR After: 24.913874, PSNR Change: 0.000013, PSNR Diff: 0.008341 (New Max), Reward: 1.07, 12:30:25\u001b[0m\n",
      "\u001b[94mStep: 1481, PSNR Before: 24.913874, PSNR After: 24.913942, PSNR Change: 0.000069, PSNR Diff: 0.008410 (New Max), Reward: 5.49, 12:30:34\u001b[0m\n",
      "\u001b[94mStep: 1486, PSNR Before: 24.913942, PSNR After: 24.913975, PSNR Change: 0.000032, PSNR Diff: 0.008442 (New Max), Reward: 2.59, 12:30:40\u001b[0m\n",
      "\u001b[94mStep: 1487, PSNR Before: 24.913975, PSNR After: 24.913977, PSNR Change: 0.000002, PSNR Diff: 0.008444 (New Max), Reward: 0.15, 12:30:41\u001b[0m\n",
      "\u001b[94mStep: 1488, PSNR Before: 24.913977, PSNR After: 24.914005, PSNR Change: 0.000029, PSNR Diff: 0.008472 (New Max), Reward: 2.29, 12:30:43\u001b[0m\n",
      "\u001b[94mStep: 1491, PSNR Before: 24.914005, PSNR After: 24.914036, PSNR Change: 0.000031, PSNR Diff: 0.008503 (New Max), Reward: 2.44, 12:30:47\u001b[0m\n",
      "\u001b[94mStep: 1499, PSNR Before: 24.914036, PSNR After: 24.914186, PSNR Change: 0.000151, PSNR Diff: 0.008654 (New Max), Reward: 12.05, 12:30:55\u001b[0m\n",
      "\u001b[94mStep: 1501, PSNR Before: 24.914186, PSNR After: 24.914207, PSNR Change: 0.000021, PSNR Diff: 0.008675 (New Max), Reward: 1.68, 12:30:58\u001b[0m\n",
      "\u001b[94mStep: 1515, PSNR Before: 24.914207, PSNR After: 24.914238, PSNR Change: 0.000031, PSNR Diff: 0.008705 (New Max), Reward: 2.44, 12:31:11\u001b[0m\n",
      "\u001b[94mStep: 1517, PSNR Before: 24.914238, PSNR After: 24.914276, PSNR Change: 0.000038, PSNR Diff: 0.008743 (New Max), Reward: 3.05, 12:31:14\u001b[0m\n",
      "\u001b[94mStep: 1518, PSNR Before: 24.914276, PSNR After: 24.914371, PSNR Change: 0.000095, PSNR Diff: 0.008839 (New Max), Reward: 7.63, 12:31:16\u001b[0m\n",
      "\u001b[94mStep: 1519, PSNR Before: 24.914371, PSNR After: 24.914421, PSNR Change: 0.000050, PSNR Diff: 0.008888 (New Max), Reward: 3.97, 12:31:18\u001b[0m\n",
      "\u001b[94mStep: 1528, PSNR Before: 24.914421, PSNR After: 24.914501, PSNR Change: 0.000080, PSNR Diff: 0.008968 (New Max), Reward: 6.41, 12:31:27\u001b[0m\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 1692         |\n",
      "|    total_timesteps      | 1536         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.381903e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -14.6        |\n",
      "|    explained_variance   | -0.0964      |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.517        |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.000156    |\n",
      "|    value_loss           | 1.07         |\n",
      "------------------------------------------\n",
      "\u001b[94mStep: 1543, PSNR Before: 24.914501, PSNR After: 24.914509, PSNR Change: 0.000008, PSNR Diff: 0.008976 (New Max), Reward: 0.61, 12:31:49\u001b[0m\n",
      "\u001b[94mStep: 1550, PSNR Before: 24.914509, PSNR After: 24.914515, PSNR Change: 0.000006, PSNR Diff: 0.008982 (New Max), Reward: 0.46, 12:31:56\u001b[0m\n",
      "\u001b[94mStep: 1555, PSNR Before: 24.914515, PSNR After: 24.914532, PSNR Change: 0.000017, PSNR Diff: 0.008999 (New Max), Reward: 1.37, 12:32:02\u001b[0m\n",
      "\u001b[94mStep: 1560, PSNR Before: 24.914532, PSNR After: 24.914539, PSNR Change: 0.000008, PSNR Diff: 0.009007 (New Max), Reward: 0.61, 12:32:08\u001b[0m\n",
      "\u001b[94mStep: 1565, PSNR Before: 24.914539, PSNR After: 24.914543, PSNR Change: 0.000004, PSNR Diff: 0.009010 (New Max), Reward: 0.31, 12:32:14\u001b[0m\n",
      "\u001b[94mStep: 1568, PSNR Before: 24.914543, PSNR After: 24.914558, PSNR Change: 0.000015, PSNR Diff: 0.009026 (New Max), Reward: 1.22, 12:32:17\u001b[0m\n",
      "\u001b[94mStep: 1586, PSNR Before: 24.914558, PSNR After: 24.914658, PSNR Change: 0.000099, PSNR Diff: 0.009125 (New Max), Reward: 7.93, 12:32:35\u001b[0m\n",
      "\u001b[94mStep: 1590, PSNR Before: 24.914658, PSNR After: 24.914680, PSNR Change: 0.000023, PSNR Diff: 0.009148 (New Max), Reward: 1.83, 12:32:39\u001b[0m\n",
      "\u001b[94mStep: 1599, PSNR Before: 24.914680, PSNR After: 24.914703, PSNR Change: 0.000023, PSNR Diff: 0.009171 (New Max), Reward: 1.83, 12:32:48\u001b[0m\n",
      "\u001b[94mStep: 1603, PSNR Before: 24.914703, PSNR After: 24.914707, PSNR Change: 0.000004, PSNR Diff: 0.009174 (New Max), Reward: 0.31, 12:32:53\u001b[0m\n",
      "\u001b[94mStep: 1608, PSNR Before: 24.914707, PSNR After: 24.914797, PSNR Change: 0.000090, PSNR Diff: 0.009264 (New Max), Reward: 7.17, 12:32:58\u001b[0m\n",
      "\u001b[94mStep: 1619, PSNR Before: 24.914797, PSNR After: 24.914810, PSNR Change: 0.000013, PSNR Diff: 0.009277 (New Max), Reward: 1.07, 12:33:09\u001b[0m\n",
      "\u001b[94mStep: 1627, PSNR Before: 24.914810, PSNR After: 24.914818, PSNR Change: 0.000008, PSNR Diff: 0.009285 (New Max), Reward: 0.61, 12:33:17\u001b[0m\n",
      "\u001b[94mStep: 1631, PSNR Before: 24.914818, PSNR After: 24.914902, PSNR Change: 0.000084, PSNR Diff: 0.009369 (New Max), Reward: 6.71, 12:33:22\u001b[0m\n",
      "\u001b[94mStep: 1642, PSNR Before: 24.914902, PSNR After: 24.914972, PSNR Change: 0.000071, PSNR Diff: 0.009439 (New Max), Reward: 5.65, 12:33:33\u001b[0m\n",
      "\u001b[94mStep: 1643, PSNR Before: 24.914972, PSNR After: 24.915037, PSNR Change: 0.000065, PSNR Diff: 0.009504 (New Max), Reward: 5.19, 12:33:35\u001b[0m\n",
      "\u001b[94mStep: 1646, PSNR Before: 24.915037, PSNR After: 24.915054, PSNR Change: 0.000017, PSNR Diff: 0.009521 (New Max), Reward: 1.37, 12:33:38\u001b[0m\n",
      "\u001b[94mStep: 1647, PSNR Before: 24.915054, PSNR After: 24.915113, PSNR Change: 0.000059, PSNR Diff: 0.009581 (New Max), Reward: 4.73, 12:33:40\u001b[0m\n",
      "\u001b[94mStep: 1656, PSNR Before: 24.915113, PSNR After: 24.915138, PSNR Change: 0.000025, PSNR Diff: 0.009605 (New Max), Reward: 1.98, 12:33:51\u001b[0m\n",
      "\u001b[94mStep: 1658, PSNR Before: 24.915138, PSNR After: 24.915150, PSNR Change: 0.000011, PSNR Diff: 0.009617 (New Max), Reward: 0.92, 12:33:54\u001b[0m\n",
      "\u001b[94mStep: 1665, PSNR Before: 24.915150, PSNR After: 24.915176, PSNR Change: 0.000027, PSNR Diff: 0.009644 (New Max), Reward: 2.14, 12:34:01\u001b[0m\n",
      "\u001b[94mStep: 1666, PSNR Before: 24.915176, PSNR After: 24.915178, PSNR Change: 0.000002, PSNR Diff: 0.009645 (New Max), Reward: 0.15, 12:34:03\u001b[0m\n",
      "\u001b[94mStep: 1669, PSNR Before: 24.915178, PSNR After: 24.915197, PSNR Change: 0.000019, PSNR Diff: 0.009665 (New Max), Reward: 1.53, 12:34:07\u001b[0m\n",
      "\u001b[94mStep: 1673, PSNR Before: 24.915197, PSNR After: 24.915226, PSNR Change: 0.000029, PSNR Diff: 0.009693 (New Max), Reward: 2.29, 12:34:11\u001b[0m\n",
      "\u001b[94mStep: 1677, PSNR Before: 24.915226, PSNR After: 24.915283, PSNR Change: 0.000057, PSNR Diff: 0.009750 (New Max), Reward: 4.58, 12:34:17\u001b[0m\n",
      "\u001b[94mStep: 1690, PSNR Before: 24.915283, PSNR After: 24.915321, PSNR Change: 0.000038, PSNR Diff: 0.009789 (New Max), Reward: 3.05, 12:34:30\u001b[0m\n",
      "\u001b[94mStep: 1692, PSNR Before: 24.915321, PSNR After: 24.915337, PSNR Change: 0.000015, PSNR Diff: 0.009804 (New Max), Reward: 1.22, 12:34:32\u001b[0m\n",
      "\u001b[94mStep: 1701, PSNR Before: 24.915337, PSNR After: 24.915409, PSNR Change: 0.000072, PSNR Diff: 0.009876 (New Max), Reward: 5.80, 12:34:42\u001b[0m\n",
      "\u001b[94mStep: 1706, PSNR Before: 24.915409, PSNR After: 24.915419, PSNR Change: 0.000010, PSNR Diff: 0.009886 (New Max), Reward: 0.76, 12:34:47\u001b[0m\n",
      "\u001b[94mStep: 1707, PSNR Before: 24.915419, PSNR After: 24.915432, PSNR Change: 0.000013, PSNR Diff: 0.009899 (New Max), Reward: 1.07, 12:34:49\u001b[0m\n",
      "\u001b[94mStep: 1713, PSNR Before: 24.915432, PSNR After: 24.915449, PSNR Change: 0.000017, PSNR Diff: 0.009916 (New Max), Reward: 1.37, 12:34:56\u001b[0m\n",
      "\u001b[94mStep: 1714, PSNR Before: 24.915449, PSNR After: 24.915541, PSNR Change: 0.000092, PSNR Diff: 0.010008 (New Max), Reward: 7.32, 12:34:58\u001b[0m\n",
      "\u001b[94mStep: 1722, PSNR Before: 24.915541, PSNR After: 24.915564, PSNR Change: 0.000023, PSNR Diff: 0.010031 (New Max), Reward: 1.83, 12:35:07\u001b[0m\n",
      "\u001b[94mStep: 1724, PSNR Before: 24.915564, PSNR After: 24.915577, PSNR Change: 0.000013, PSNR Diff: 0.010044 (New Max), Reward: 1.07, 12:35:10\u001b[0m\n",
      "\u001b[94mStep: 1728, PSNR Before: 24.915577, PSNR After: 24.915588, PSNR Change: 0.000011, PSNR Diff: 0.010056 (New Max), Reward: 0.92, 12:35:14\u001b[0m\n",
      "\u001b[94mStep: 1733, PSNR Before: 24.915588, PSNR After: 24.915609, PSNR Change: 0.000021, PSNR Diff: 0.010077 (New Max), Reward: 1.68, 12:35:20\u001b[0m\n",
      "\u001b[94mStep: 1739, PSNR Before: 24.915609, PSNR After: 24.915617, PSNR Change: 0.000008, PSNR Diff: 0.010084 (New Max), Reward: 0.61, 12:35:27\u001b[0m\n",
      "\u001b[94mStep: 1743, PSNR Before: 24.915617, PSNR After: 24.915661, PSNR Change: 0.000044, PSNR Diff: 0.010128 (New Max), Reward: 3.51, 12:35:31\u001b[0m\n",
      "\u001b[94mStep: 1745, PSNR Before: 24.915661, PSNR After: 24.915667, PSNR Change: 0.000006, PSNR Diff: 0.010134 (New Max), Reward: 0.46, 12:35:34\u001b[0m\n",
      "\u001b[94mStep: 1746, PSNR Before: 24.915667, PSNR After: 24.915737, PSNR Change: 0.000071, PSNR Diff: 0.010204 (New Max), Reward: 5.65, 12:35:36\u001b[0m\n",
      "\u001b[94mStep: 1755, PSNR Before: 24.915737, PSNR After: 24.915827, PSNR Change: 0.000090, PSNR Diff: 0.010294 (New Max), Reward: 7.17, 12:35:46\u001b[0m\n",
      "\u001b[94mStep: 1757, PSNR Before: 24.915827, PSNR After: 24.915922, PSNR Change: 0.000095, PSNR Diff: 0.010389 (New Max), Reward: 7.63, 12:35:49\u001b[0m\n",
      "\u001b[94mStep: 1768, PSNR Before: 24.915922, PSNR After: 24.915947, PSNR Change: 0.000025, PSNR Diff: 0.010414 (New Max), Reward: 1.98, 12:36:02\u001b[0m\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 1981         |\n",
      "|    total_timesteps      | 1792         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.732321e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -14.6        |\n",
      "|    explained_variance   | 0.0859       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.285        |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.000176    |\n",
      "|    value_loss           | 0.693        |\n",
      "------------------------------------------\n",
      "\u001b[94mStep: 1791, PSNR Before: 24.915947, PSNR After: 24.915991, PSNR Change: 0.000044, PSNR Diff: 0.010458 (New Max), Reward: 3.51, 12:36:30\u001b[0m\n",
      "\u001b[94mStep: 1798, PSNR Before: 24.915991, PSNR After: 24.916016, PSNR Change: 0.000025, PSNR Diff: 0.010483 (New Max), Reward: 1.98, 12:36:38\u001b[0m\n",
      "\u001b[94mStep: 1807, PSNR Before: 24.916016, PSNR After: 24.916145, PSNR Change: 0.000130, PSNR Diff: 0.010612 (New Max), Reward: 10.38, 12:36:47\u001b[0m\n",
      "\u001b[94mStep: 1813, PSNR Before: 24.916145, PSNR After: 24.916218, PSNR Change: 0.000072, PSNR Diff: 0.010685 (New Max), Reward: 5.80, 12:36:53\u001b[0m\n",
      "\u001b[94mStep: 1816, PSNR Before: 24.916218, PSNR After: 24.916264, PSNR Change: 0.000046, PSNR Diff: 0.010731 (New Max), Reward: 3.66, 12:36:57\u001b[0m\n",
      "\u001b[94mStep: 1826, PSNR Before: 24.916264, PSNR After: 24.916296, PSNR Change: 0.000032, PSNR Diff: 0.010763 (New Max), Reward: 2.59, 12:37:08\u001b[0m\n",
      "\u001b[94mStep: 1831, PSNR Before: 24.916296, PSNR After: 24.916328, PSNR Change: 0.000032, PSNR Diff: 0.010796 (New Max), Reward: 2.59, 12:37:13\u001b[0m\n",
      "\u001b[94mStep: 1838, PSNR Before: 24.916328, PSNR After: 24.916346, PSNR Change: 0.000017, PSNR Diff: 0.010813 (New Max), Reward: 1.37, 12:37:20\u001b[0m\n",
      "\u001b[94mStep: 1849, PSNR Before: 24.916346, PSNR After: 24.916409, PSNR Change: 0.000063, PSNR Diff: 0.010876 (New Max), Reward: 5.04, 12:37:32\u001b[0m\n",
      "\u001b[94mStep: 1852, PSNR Before: 24.916409, PSNR After: 24.916418, PSNR Change: 0.000010, PSNR Diff: 0.010885 (New Max), Reward: 0.76, 12:37:35\u001b[0m\n",
      "\u001b[94mStep: 1858, PSNR Before: 24.916418, PSNR After: 24.916424, PSNR Change: 0.000006, PSNR Diff: 0.010891 (New Max), Reward: 0.46, 12:37:42\u001b[0m\n",
      "\u001b[94mStep: 1867, PSNR Before: 24.916424, PSNR After: 24.916456, PSNR Change: 0.000032, PSNR Diff: 0.010923 (New Max), Reward: 2.59, 12:37:51\u001b[0m\n",
      "\u001b[94mStep: 1869, PSNR Before: 24.916456, PSNR After: 24.916517, PSNR Change: 0.000061, PSNR Diff: 0.010984 (New Max), Reward: 4.88, 12:37:53\u001b[0m\n",
      "\u001b[94mStep: 1885, PSNR Before: 24.916517, PSNR After: 24.916527, PSNR Change: 0.000010, PSNR Diff: 0.010994 (New Max), Reward: 0.76, 12:38:10\u001b[0m\n",
      "\u001b[94mStep: 1887, PSNR Before: 24.916527, PSNR After: 24.916553, PSNR Change: 0.000027, PSNR Diff: 0.011021 (New Max), Reward: 2.14, 12:38:13\u001b[0m\n",
      "\u001b[94mStep: 1893, PSNR Before: 24.916553, PSNR After: 24.916594, PSNR Change: 0.000040, PSNR Diff: 0.011061 (New Max), Reward: 3.20, 12:38:19\u001b[0m\n",
      "\u001b[94mStep: 1903, PSNR Before: 24.916594, PSNR After: 24.916649, PSNR Change: 0.000055, PSNR Diff: 0.011116 (New Max), Reward: 4.43, 12:38:29\u001b[0m\n",
      "\u001b[94mStep: 1905, PSNR Before: 24.916649, PSNR After: 24.916651, PSNR Change: 0.000002, PSNR Diff: 0.011118 (New Max), Reward: 0.15, 12:38:32\u001b[0m\n",
      "\u001b[94mStep: 1910, PSNR Before: 24.916651, PSNR After: 24.916664, PSNR Change: 0.000013, PSNR Diff: 0.011131 (New Max), Reward: 1.07, 12:38:37\u001b[0m\n",
      "\u001b[94mStep: 1921, PSNR Before: 24.916664, PSNR After: 24.916668, PSNR Change: 0.000004, PSNR Diff: 0.011135 (New Max), Reward: 0.31, 12:38:48\u001b[0m\n",
      "\u001b[94mStep: 1925, PSNR Before: 24.916668, PSNR After: 24.916698, PSNR Change: 0.000031, PSNR Diff: 0.011166 (New Max), Reward: 2.44, 12:38:53\u001b[0m\n",
      "\u001b[94mStep: 1932, PSNR Before: 24.916698, PSNR After: 24.916729, PSNR Change: 0.000031, PSNR Diff: 0.011196 (New Max), Reward: 2.44, 12:39:00\u001b[0m\n",
      "\u001b[94mStep: 1937, PSNR Before: 24.916729, PSNR After: 24.916817, PSNR Change: 0.000088, PSNR Diff: 0.011284 (New Max), Reward: 7.02, 12:39:06\u001b[0m\n",
      "\u001b[94mStep: 1940, PSNR Before: 24.916817, PSNR After: 24.916857, PSNR Change: 0.000040, PSNR Diff: 0.011324 (New Max), Reward: 3.20, 12:39:09\u001b[0m\n",
      "\u001b[94mStep: 1942, PSNR Before: 24.916857, PSNR After: 24.916943, PSNR Change: 0.000086, PSNR Diff: 0.011410 (New Max), Reward: 6.87, 12:39:12\u001b[0m\n",
      "\u001b[94mStep: 1950, PSNR Before: 24.916943, PSNR After: 24.916973, PSNR Change: 0.000031, PSNR Diff: 0.011440 (New Max), Reward: 2.44, 12:39:20\u001b[0m\n",
      "\u001b[94mStep: 1953, PSNR Before: 24.916973, PSNR After: 24.916990, PSNR Change: 0.000017, PSNR Diff: 0.011457 (New Max), Reward: 1.37, 12:39:24\u001b[0m\n",
      "\u001b[94mStep: 1962, PSNR Before: 24.916990, PSNR After: 24.917011, PSNR Change: 0.000021, PSNR Diff: 0.011478 (New Max), Reward: 1.68, 12:39:33\u001b[0m\n",
      "\u001b[94mStep: 1964, PSNR Before: 24.917011, PSNR After: 24.917086, PSNR Change: 0.000074, PSNR Diff: 0.011553 (New Max), Reward: 5.95, 12:39:36\u001b[0m\n",
      "\u001b[94mStep: 1966, PSNR Before: 24.917086, PSNR After: 24.917133, PSNR Change: 0.000048, PSNR Diff: 0.011600 (New Max), Reward: 3.81, 12:39:38\u001b[0m\n",
      "\u001b[94mStep: 1967, PSNR Before: 24.917133, PSNR After: 24.917202, PSNR Change: 0.000069, PSNR Diff: 0.011669 (New Max), Reward: 5.49, 12:39:40\u001b[0m\n",
      "\u001b[94mStep: 1976, PSNR Before: 24.917202, PSNR After: 24.917223, PSNR Change: 0.000021, PSNR Diff: 0.011690 (New Max), Reward: 1.68, 12:39:49\u001b[0m\n",
      "\u001b[94mStep: 1989, PSNR Before: 24.917223, PSNR After: 24.917231, PSNR Change: 0.000008, PSNR Diff: 0.011698 (New Max), Reward: 0.61, 12:40:02\u001b[0m\n",
      "\u001b[94mStep: 1990, PSNR Before: 24.917231, PSNR After: 24.917257, PSNR Change: 0.000027, PSNR Diff: 0.011724 (New Max), Reward: 2.14, 12:40:04\u001b[0m\n",
      "\u001b[94mStep: 1994, PSNR Before: 24.917257, PSNR After: 24.917295, PSNR Change: 0.000038, PSNR Diff: 0.011763 (New Max), Reward: 3.05, 12:40:09\u001b[0m\n",
      "\u001b[94mStep: 1997, PSNR Before: 24.917295, PSNR After: 24.917305, PSNR Change: 0.000010, PSNR Diff: 0.011772 (New Max), Reward: 0.76, 12:40:13\u001b[0m\n",
      "\u001b[94mStep: 2004, PSNR Before: 24.917305, PSNR After: 24.917307, PSNR Change: 0.000002, PSNR Diff: 0.011774 (New Max), Reward: 0.15, 12:40:20\u001b[0m\n",
      "\u001b[94mStep: 2015, PSNR Before: 24.917307, PSNR After: 24.917315, PSNR Change: 0.000008, PSNR Diff: 0.011782 (New Max), Reward: 0.61, 12:40:32\u001b[0m\n",
      "\u001b[94mStep: 2024, PSNR Before: 24.917315, PSNR After: 24.917318, PSNR Change: 0.000004, PSNR Diff: 0.011786 (New Max), Reward: 0.31, 12:40:41\u001b[0m\n",
      "\u001b[94mStep: 2028, PSNR Before: 24.917318, PSNR After: 24.917339, PSNR Change: 0.000021, PSNR Diff: 0.011806 (New Max), Reward: 1.68, 12:40:46\u001b[0m\n",
      "\u001b[94mStep: 2034, PSNR Before: 24.917339, PSNR After: 24.917370, PSNR Change: 0.000031, PSNR Diff: 0.011837 (New Max), Reward: 2.44, 12:40:53\u001b[0m\n",
      "\u001b[94mStep: 2035, PSNR Before: 24.917370, PSNR After: 24.917397, PSNR Change: 0.000027, PSNR Diff: 0.011864 (New Max), Reward: 2.14, 12:40:55\u001b[0m\n",
      "\u001b[94mStep: 2036, PSNR Before: 24.917397, PSNR After: 24.917400, PSNR Change: 0.000004, PSNR Diff: 0.011868 (New Max), Reward: 0.31, 12:40:56\u001b[0m\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 2263         |\n",
      "|    total_timesteps      | 2048         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.094304e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -14.6        |\n",
      "|    explained_variance   | 0.0711       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.289        |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.000189    |\n",
      "|    value_loss           | 0.649        |\n",
      "------------------------------------------\n",
      "\u001b[94mStep: 2050, PSNR Before: 24.917400, PSNR After: 24.917440, PSNR Change: 0.000040, PSNR Diff: 0.011908 (New Max), Reward: 3.20, 12:41:17\u001b[0m\n",
      "\u001b[94mStep: 2054, PSNR Before: 24.917440, PSNR After: 24.917477, PSNR Change: 0.000036, PSNR Diff: 0.011944 (New Max), Reward: 2.90, 12:41:21\u001b[0m\n",
      "\u001b[94mStep: 2058, PSNR Before: 24.917477, PSNR After: 24.917509, PSNR Change: 0.000032, PSNR Diff: 0.011976 (New Max), Reward: 2.59, 12:41:26\u001b[0m\n",
      "\u001b[94mStep: 2059, PSNR Before: 24.917509, PSNR After: 24.917511, PSNR Change: 0.000002, PSNR Diff: 0.011978 (New Max), Reward: 0.15, 12:41:27\u001b[0m\n",
      "\u001b[94mStep: 2061, PSNR Before: 24.917511, PSNR After: 24.917515, PSNR Change: 0.000004, PSNR Diff: 0.011982 (New Max), Reward: 0.31, 12:41:30\u001b[0m\n",
      "\u001b[94mStep: 2068, PSNR Before: 24.917515, PSNR After: 24.917574, PSNR Change: 0.000059, PSNR Diff: 0.012041 (New Max), Reward: 4.73, 12:41:37\u001b[0m\n",
      "\u001b[94mStep: 2084, PSNR Before: 24.917574, PSNR After: 24.917580, PSNR Change: 0.000006, PSNR Diff: 0.012047 (New Max), Reward: 0.46, 12:41:55\u001b[0m\n",
      "\u001b[94mStep: 2085, PSNR Before: 24.917580, PSNR After: 24.917593, PSNR Change: 0.000013, PSNR Diff: 0.012060 (New Max), Reward: 1.07, 12:41:57\u001b[0m\n",
      "\u001b[94mStep: 2086, PSNR Before: 24.917593, PSNR After: 24.917658, PSNR Change: 0.000065, PSNR Diff: 0.012125 (New Max), Reward: 5.19, 12:41:58\u001b[0m\n",
      "\u001b[94mStep: 2093, PSNR Before: 24.917658, PSNR After: 24.917686, PSNR Change: 0.000029, PSNR Diff: 0.012154 (New Max), Reward: 2.29, 12:42:06\u001b[0m\n",
      "\u001b[94mStep: 2096, PSNR Before: 24.917686, PSNR After: 24.917717, PSNR Change: 0.000031, PSNR Diff: 0.012184 (New Max), Reward: 2.44, 12:42:09\u001b[0m\n",
      "\u001b[94mStep: 2100, PSNR Before: 24.917717, PSNR After: 24.917732, PSNR Change: 0.000015, PSNR Diff: 0.012199 (New Max), Reward: 1.22, 12:42:14\u001b[0m\n",
      "Step: 2100, PSNR Before: 24.917717, PSNR After: 24.917732, PSNR Change: 0.000015, PSNR Diff: 0.012199, Reward: 1.22, 12:42:14\n",
      "\u001b[94mStep: 2107, PSNR Before: 24.917732, PSNR After: 24.917763, PSNR Change: 0.000031, PSNR Diff: 0.012230 (New Max), Reward: 2.44, 12:42:21\u001b[0m\n",
      "\u001b[94mStep: 2110, PSNR Before: 24.917763, PSNR After: 24.917770, PSNR Change: 0.000008, PSNR Diff: 0.012238 (New Max), Reward: 0.61, 12:42:24\u001b[0m\n",
      "\u001b[94mStep: 2119, PSNR Before: 24.917770, PSNR After: 24.917778, PSNR Change: 0.000008, PSNR Diff: 0.012245 (New Max), Reward: 0.61, 12:42:33\u001b[0m\n",
      "\u001b[94mStep: 2126, PSNR Before: 24.917778, PSNR After: 24.917830, PSNR Change: 0.000051, PSNR Diff: 0.012297 (New Max), Reward: 4.12, 12:42:40\u001b[0m\n",
      "\u001b[94mStep: 2127, PSNR Before: 24.917830, PSNR After: 24.917835, PSNR Change: 0.000006, PSNR Diff: 0.012302 (New Max), Reward: 0.46, 12:42:42\u001b[0m\n",
      "\u001b[94mStep: 2145, PSNR Before: 24.917835, PSNR After: 24.917849, PSNR Change: 0.000013, PSNR Diff: 0.012316 (New Max), Reward: 1.07, 12:43:00\u001b[0m\n",
      "\u001b[94mStep: 2146, PSNR Before: 24.917849, PSNR After: 24.917860, PSNR Change: 0.000011, PSNR Diff: 0.012327 (New Max), Reward: 0.92, 12:43:02\u001b[0m\n",
      "\u001b[94mStep: 2148, PSNR Before: 24.917860, PSNR After: 24.917887, PSNR Change: 0.000027, PSNR Diff: 0.012354 (New Max), Reward: 2.14, 12:43:04\u001b[0m\n",
      "\u001b[94mStep: 2162, PSNR Before: 24.917887, PSNR After: 24.917915, PSNR Change: 0.000029, PSNR Diff: 0.012383 (New Max), Reward: 2.29, 12:43:18\u001b[0m\n",
      "\u001b[94mStep: 2165, PSNR Before: 24.917915, PSNR After: 24.917919, PSNR Change: 0.000004, PSNR Diff: 0.012386 (New Max), Reward: 0.31, 12:43:21\u001b[0m\n",
      "\u001b[94mStep: 2167, PSNR Before: 24.917919, PSNR After: 24.917936, PSNR Change: 0.000017, PSNR Diff: 0.012403 (New Max), Reward: 1.37, 12:43:24\u001b[0m\n",
      "\u001b[94mStep: 2169, PSNR Before: 24.917936, PSNR After: 24.918003, PSNR Change: 0.000067, PSNR Diff: 0.012470 (New Max), Reward: 5.34, 12:43:27\u001b[0m\n",
      "\u001b[94mStep: 2170, PSNR Before: 24.918003, PSNR After: 24.918007, PSNR Change: 0.000004, PSNR Diff: 0.012474 (New Max), Reward: 0.31, 12:43:28\u001b[0m\n",
      "\u001b[94mStep: 2175, PSNR Before: 24.918007, PSNR After: 24.918039, PSNR Change: 0.000032, PSNR Diff: 0.012506 (New Max), Reward: 2.59, 12:43:34\u001b[0m\n",
      "\u001b[94mStep: 2182, PSNR Before: 24.918039, PSNR After: 24.918051, PSNR Change: 0.000011, PSNR Diff: 0.012518 (New Max), Reward: 0.92, 12:43:41\u001b[0m\n",
      "\u001b[94mStep: 2200, PSNR Before: 24.918051, PSNR After: 24.918125, PSNR Change: 0.000074, PSNR Diff: 0.012592 (New Max), Reward: 5.95, 12:43:59\u001b[0m\n",
      "Step: 2200, PSNR Before: 24.918051, PSNR After: 24.918125, PSNR Change: 0.000074, PSNR Diff: 0.012592, Reward: 5.95, 12:43:59\n",
      "\u001b[94mStep: 2201, PSNR Before: 24.918125, PSNR After: 24.918310, PSNR Change: 0.000185, PSNR Diff: 0.012777 (New Max), Reward: 14.80, 12:44:01\u001b[0m\n",
      "\u001b[94mStep: 2202, PSNR Before: 24.918310, PSNR After: 24.918344, PSNR Change: 0.000034, PSNR Diff: 0.012812 (New Max), Reward: 2.75, 12:44:02\u001b[0m\n",
      "\u001b[94mStep: 2205, PSNR Before: 24.918344, PSNR After: 24.918362, PSNR Change: 0.000017, PSNR Diff: 0.012829 (New Max), Reward: 1.37, 12:44:06\u001b[0m\n",
      "\u001b[94mStep: 2208, PSNR Before: 24.918362, PSNR After: 24.918423, PSNR Change: 0.000061, PSNR Diff: 0.012890 (New Max), Reward: 4.88, 12:44:10\u001b[0m\n",
      "\u001b[94mStep: 2210, PSNR Before: 24.918423, PSNR After: 24.918510, PSNR Change: 0.000088, PSNR Diff: 0.012978 (New Max), Reward: 7.02, 12:44:12\u001b[0m\n",
      "\u001b[94mStep: 2230, PSNR Before: 24.918510, PSNR After: 24.918575, PSNR Change: 0.000065, PSNR Diff: 0.013042 (New Max), Reward: 5.19, 12:44:32\u001b[0m\n",
      "\u001b[94mStep: 2254, PSNR Before: 24.918575, PSNR After: 24.918613, PSNR Change: 0.000038, PSNR Diff: 0.013081 (New Max), Reward: 3.05, 12:44:56\u001b[0m\n",
      "\u001b[94mStep: 2262, PSNR Before: 24.918613, PSNR After: 24.918667, PSNR Change: 0.000053, PSNR Diff: 0.013134 (New Max), Reward: 4.27, 12:45:05\u001b[0m\n",
      "\u001b[94mStep: 2266, PSNR Before: 24.918667, PSNR After: 24.918686, PSNR Change: 0.000019, PSNR Diff: 0.013153 (New Max), Reward: 1.53, 12:45:09\u001b[0m\n",
      "\u001b[94mStep: 2269, PSNR Before: 24.918686, PSNR After: 24.918688, PSNR Change: 0.000002, PSNR Diff: 0.013155 (New Max), Reward: 0.15, 12:45:13\u001b[0m\n",
      "\u001b[94mStep: 2273, PSNR Before: 24.918688, PSNR After: 24.918737, PSNR Change: 0.000050, PSNR Diff: 0.013205 (New Max), Reward: 3.97, 12:45:17\u001b[0m\n",
      "\u001b[94mStep: 2279, PSNR Before: 24.918737, PSNR After: 24.918739, PSNR Change: 0.000002, PSNR Diff: 0.013206 (New Max), Reward: 0.15, 12:45:23\u001b[0m\n",
      "\u001b[94mStep: 2284, PSNR Before: 24.918739, PSNR After: 24.918770, PSNR Change: 0.000031, PSNR Diff: 0.013237 (New Max), Reward: 2.44, 12:45:29\u001b[0m\n",
      "\u001b[94mStep: 2286, PSNR Before: 24.918770, PSNR After: 24.918879, PSNR Change: 0.000109, PSNR Diff: 0.013346 (New Max), Reward: 8.70, 12:45:31\u001b[0m\n",
      "\u001b[94mStep: 2291, PSNR Before: 24.918879, PSNR After: 24.918880, PSNR Change: 0.000002, PSNR Diff: 0.013348 (New Max), Reward: 0.15, 12:45:37\u001b[0m\n",
      "\u001b[94mStep: 2293, PSNR Before: 24.918880, PSNR After: 24.918928, PSNR Change: 0.000048, PSNR Diff: 0.013395 (New Max), Reward: 3.81, 12:45:39\u001b[0m\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 2545          |\n",
      "|    total_timesteps      | 2304          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1944212e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -14.6         |\n",
      "|    explained_variance   | 0.0782        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 0.375         |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -0.000194     |\n",
      "|    value_loss           | 0.838         |\n",
      "-------------------------------------------\n",
      "\u001b[94mStep: 2301, PSNR Before: 24.918928, PSNR After: 24.918961, PSNR Change: 0.000032, PSNR Diff: 0.013428 (New Max), Reward: 2.59, 12:45:55\u001b[0m\n",
      "\u001b[94mStep: 2306, PSNR Before: 24.918961, PSNR After: 24.919025, PSNR Change: 0.000065, PSNR Diff: 0.013493 (New Max), Reward: 5.19, 12:46:00\u001b[0m\n",
      "\u001b[94mStep: 2310, PSNR Before: 24.919025, PSNR After: 24.919035, PSNR Change: 0.000010, PSNR Diff: 0.013502 (New Max), Reward: 0.76, 12:46:04\u001b[0m\n",
      "\u001b[94mStep: 2315, PSNR Before: 24.919035, PSNR After: 24.919041, PSNR Change: 0.000006, PSNR Diff: 0.013508 (New Max), Reward: 0.46, 12:46:10\u001b[0m\n",
      "\u001b[94mStep: 2317, PSNR Before: 24.919041, PSNR After: 24.919086, PSNR Change: 0.000046, PSNR Diff: 0.013554 (New Max), Reward: 3.66, 12:46:13\u001b[0m\n",
      "\u001b[94mStep: 2331, PSNR Before: 24.919086, PSNR After: 24.919121, PSNR Change: 0.000034, PSNR Diff: 0.013588 (New Max), Reward: 2.75, 12:46:26\u001b[0m\n",
      "\u001b[94mStep: 2347, PSNR Before: 24.919121, PSNR After: 24.919132, PSNR Change: 0.000011, PSNR Diff: 0.013599 (New Max), Reward: 0.92, 12:46:42\u001b[0m\n",
      "\u001b[94mStep: 2349, PSNR Before: 24.919132, PSNR After: 24.919235, PSNR Change: 0.000103, PSNR Diff: 0.013702 (New Max), Reward: 8.24, 12:46:44\u001b[0m\n",
      "\u001b[94mStep: 2353, PSNR Before: 24.919235, PSNR After: 24.919239, PSNR Change: 0.000004, PSNR Diff: 0.013706 (New Max), Reward: 0.31, 12:46:49\u001b[0m\n",
      "\u001b[94mStep: 2357, PSNR Before: 24.919239, PSNR After: 24.919277, PSNR Change: 0.000038, PSNR Diff: 0.013744 (New Max), Reward: 3.05, 12:46:53\u001b[0m\n",
      "\u001b[94mStep: 2358, PSNR Before: 24.919277, PSNR After: 24.919300, PSNR Change: 0.000023, PSNR Diff: 0.013767 (New Max), Reward: 1.83, 12:46:55\u001b[0m\n",
      "\u001b[94mStep: 2364, PSNR Before: 24.919300, PSNR After: 24.919334, PSNR Change: 0.000034, PSNR Diff: 0.013802 (New Max), Reward: 2.75, 12:47:02\u001b[0m\n",
      "\u001b[94mStep: 2370, PSNR Before: 24.919334, PSNR After: 24.919376, PSNR Change: 0.000042, PSNR Diff: 0.013844 (New Max), Reward: 3.36, 12:47:08\u001b[0m\n",
      "\u001b[94mStep: 2388, PSNR Before: 24.919376, PSNR After: 24.919445, PSNR Change: 0.000069, PSNR Diff: 0.013912 (New Max), Reward: 5.49, 12:47:25\u001b[0m\n",
      "\u001b[94mStep: 2391, PSNR Before: 24.919445, PSNR After: 24.919498, PSNR Change: 0.000053, PSNR Diff: 0.013966 (New Max), Reward: 4.27, 12:47:29\u001b[0m\n",
      "\u001b[94mStep: 2395, PSNR Before: 24.919498, PSNR After: 24.919512, PSNR Change: 0.000013, PSNR Diff: 0.013979 (New Max), Reward: 1.07, 12:47:33\u001b[0m\n",
      "\u001b[94mStep: 2399, PSNR Before: 24.919512, PSNR After: 24.919588, PSNR Change: 0.000076, PSNR Diff: 0.014055 (New Max), Reward: 6.10, 12:47:38\u001b[0m\n",
      "\u001b[94mStep: 2400, PSNR Before: 24.919588, PSNR After: 24.919607, PSNR Change: 0.000019, PSNR Diff: 0.014074 (New Max), Reward: 1.53, 12:47:40\u001b[0m\n",
      "Step: 2400, PSNR Before: 24.919588, PSNR After: 24.919607, PSNR Change: 0.000019, PSNR Diff: 0.014074, Reward: 1.53, 12:47:40\n",
      "\u001b[94mStep: 2402, PSNR Before: 24.919607, PSNR After: 24.919672, PSNR Change: 0.000065, PSNR Diff: 0.014139 (New Max), Reward: 5.19, 12:47:42\u001b[0m\n",
      "\u001b[94mStep: 2404, PSNR Before: 24.919672, PSNR After: 24.919699, PSNR Change: 0.000027, PSNR Diff: 0.014166 (New Max), Reward: 2.14, 12:47:45\u001b[0m\n",
      "\u001b[94mStep: 2405, PSNR Before: 24.919699, PSNR After: 24.919735, PSNR Change: 0.000036, PSNR Diff: 0.014202 (New Max), Reward: 2.90, 12:47:47\u001b[0m\n",
      "\u001b[94mStep: 2410, PSNR Before: 24.919735, PSNR After: 24.919775, PSNR Change: 0.000040, PSNR Diff: 0.014242 (New Max), Reward: 3.20, 12:47:52\u001b[0m\n",
      "\u001b[94mStep: 2421, PSNR Before: 24.919775, PSNR After: 24.919798, PSNR Change: 0.000023, PSNR Diff: 0.014265 (New Max), Reward: 1.83, 12:48:03\u001b[0m\n",
      "\u001b[94mStep: 2423, PSNR Before: 24.919798, PSNR After: 24.919806, PSNR Change: 0.000008, PSNR Diff: 0.014273 (New Max), Reward: 0.61, 12:48:06\u001b[0m\n",
      "\u001b[94mStep: 2428, PSNR Before: 24.919806, PSNR After: 24.919819, PSNR Change: 0.000013, PSNR Diff: 0.014286 (New Max), Reward: 1.07, 12:48:11\u001b[0m\n",
      "\u001b[94mStep: 2430, PSNR Before: 24.919819, PSNR After: 24.919834, PSNR Change: 0.000015, PSNR Diff: 0.014301 (New Max), Reward: 1.22, 12:48:14\u001b[0m\n",
      "\u001b[94mStep: 2431, PSNR Before: 24.919834, PSNR After: 24.919899, PSNR Change: 0.000065, PSNR Diff: 0.014366 (New Max), Reward: 5.19, 12:48:16\u001b[0m\n",
      "\u001b[94mStep: 2434, PSNR Before: 24.919899, PSNR After: 24.919920, PSNR Change: 0.000021, PSNR Diff: 0.014387 (New Max), Reward: 1.68, 12:48:19\u001b[0m\n",
      "\u001b[94mStep: 2442, PSNR Before: 24.919920, PSNR After: 24.919937, PSNR Change: 0.000017, PSNR Diff: 0.014404 (New Max), Reward: 1.37, 12:48:28\u001b[0m\n",
      "\u001b[94mStep: 2448, PSNR Before: 24.919937, PSNR After: 24.920033, PSNR Change: 0.000095, PSNR Diff: 0.014500 (New Max), Reward: 7.63, 12:48:35\u001b[0m\n",
      "\u001b[94mStep: 2452, PSNR Before: 24.920033, PSNR After: 24.920063, PSNR Change: 0.000031, PSNR Diff: 0.014530 (New Max), Reward: 2.44, 12:48:39\u001b[0m\n",
      "\u001b[94mStep: 2453, PSNR Before: 24.920063, PSNR After: 24.920080, PSNR Change: 0.000017, PSNR Diff: 0.014547 (New Max), Reward: 1.37, 12:48:41\u001b[0m\n",
      "\u001b[94mStep: 2459, PSNR Before: 24.920080, PSNR After: 24.920099, PSNR Change: 0.000019, PSNR Diff: 0.014566 (New Max), Reward: 1.53, 12:48:47\u001b[0m\n",
      "\u001b[94mStep: 2463, PSNR Before: 24.920099, PSNR After: 24.920128, PSNR Change: 0.000029, PSNR Diff: 0.014595 (New Max), Reward: 2.29, 12:48:52\u001b[0m\n",
      "\u001b[94mStep: 2464, PSNR Before: 24.920128, PSNR After: 24.920189, PSNR Change: 0.000061, PSNR Diff: 0.014656 (New Max), Reward: 4.88, 12:48:54\u001b[0m\n",
      "\u001b[94mStep: 2467, PSNR Before: 24.920189, PSNR After: 24.920218, PSNR Change: 0.000029, PSNR Diff: 0.014685 (New Max), Reward: 2.29, 12:48:57\u001b[0m\n",
      "\u001b[94mStep: 2473, PSNR Before: 24.920218, PSNR After: 24.920237, PSNR Change: 0.000019, PSNR Diff: 0.014704 (New Max), Reward: 1.53, 12:49:04\u001b[0m\n",
      "\u001b[94mStep: 2482, PSNR Before: 24.920237, PSNR After: 24.920387, PSNR Change: 0.000151, PSNR Diff: 0.014854 (New Max), Reward: 12.05, 12:49:13\u001b[0m\n",
      "\u001b[94mStep: 2483, PSNR Before: 24.920387, PSNR After: 24.920425, PSNR Change: 0.000038, PSNR Diff: 0.014893 (New Max), Reward: 3.05, 12:49:15\u001b[0m\n",
      "\u001b[94mStep: 2495, PSNR Before: 24.920425, PSNR After: 24.920456, PSNR Change: 0.000031, PSNR Diff: 0.014923 (New Max), Reward: 2.44, 12:49:27\u001b[0m\n",
      "Step: 2500, PSNR Before: 24.920456, PSNR After: 24.920456, PSNR Change: 0.000000, PSNR Diff: 0.014923, Reward: 0.00, 12:49:32\n",
      "\u001b[94mStep: 2514, PSNR Before: 24.920456, PSNR After: 24.920486, PSNR Change: 0.000031, PSNR Diff: 0.014954 (New Max), Reward: 2.44, 12:49:46\u001b[0m\n",
      "\u001b[94mStep: 2516, PSNR Before: 24.920486, PSNR After: 24.920544, PSNR Change: 0.000057, PSNR Diff: 0.015011 (New Max), Reward: 4.58, 12:49:49\u001b[0m\n",
      "\u001b[94mStep: 2519, PSNR Before: 24.920544, PSNR After: 24.920555, PSNR Change: 0.000011, PSNR Diff: 0.015022 (New Max), Reward: 0.92, 12:49:53\u001b[0m\n",
      "\u001b[94mStep: 2520, PSNR Before: 24.920555, PSNR After: 24.920580, PSNR Change: 0.000025, PSNR Diff: 0.015047 (New Max), Reward: 1.98, 12:49:55\u001b[0m\n",
      "\u001b[94mStep: 2527, PSNR Before: 24.920580, PSNR After: 24.920607, PSNR Change: 0.000027, PSNR Diff: 0.015074 (New Max), Reward: 2.14, 12:50:02\u001b[0m\n",
      "\u001b[94mStep: 2532, PSNR Before: 24.920607, PSNR After: 24.920692, PSNR Change: 0.000086, PSNR Diff: 0.015160 (New Max), Reward: 6.87, 12:50:08\u001b[0m\n",
      "\u001b[94mStep: 2536, PSNR Before: 24.920692, PSNR After: 24.920748, PSNR Change: 0.000055, PSNR Diff: 0.015215 (New Max), Reward: 4.43, 12:50:12\u001b[0m\n",
      "\u001b[94mStep: 2544, PSNR Before: 24.920748, PSNR After: 24.920750, PSNR Change: 0.000002, PSNR Diff: 0.015217 (New Max), Reward: 0.15, 12:50:21\u001b[0m\n",
      "\u001b[94mStep: 2545, PSNR Before: 24.920750, PSNR After: 24.920841, PSNR Change: 0.000092, PSNR Diff: 0.015308 (New Max), Reward: 7.32, 12:50:22\u001b[0m\n",
      "\u001b[94mStep: 2547, PSNR Before: 24.920841, PSNR After: 24.920856, PSNR Change: 0.000015, PSNR Diff: 0.015324 (New Max), Reward: 1.22, 12:50:25\u001b[0m\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 2832         |\n",
      "|    total_timesteps      | 2560         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.322478e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -14.6        |\n",
      "|    explained_variance   | 0.0556       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.377        |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.000216    |\n",
      "|    value_loss           | 0.894        |\n",
      "------------------------------------------\n",
      "\u001b[94mStep: 2557, PSNR Before: 24.920856, PSNR After: 24.920876, PSNR Change: 0.000019, PSNR Diff: 0.015343 (New Max), Reward: 1.53, 12:50:42\u001b[0m\n",
      "\u001b[94mStep: 2559, PSNR Before: 24.920876, PSNR After: 24.920885, PSNR Change: 0.000010, PSNR Diff: 0.015352 (New Max), Reward: 0.76, 12:50:44\u001b[0m\n",
      "\u001b[94mStep: 2561, PSNR Before: 24.920885, PSNR After: 24.920931, PSNR Change: 0.000046, PSNR Diff: 0.015398 (New Max), Reward: 3.66, 12:50:47\u001b[0m\n",
      "\u001b[94mStep: 2563, PSNR Before: 24.920931, PSNR After: 24.920952, PSNR Change: 0.000021, PSNR Diff: 0.015419 (New Max), Reward: 1.68, 12:50:50\u001b[0m\n",
      "\u001b[94mStep: 2564, PSNR Before: 24.920952, PSNR After: 24.920967, PSNR Change: 0.000015, PSNR Diff: 0.015434 (New Max), Reward: 1.22, 12:50:52\u001b[0m\n",
      "\u001b[94mStep: 2566, PSNR Before: 24.920967, PSNR After: 24.920982, PSNR Change: 0.000015, PSNR Diff: 0.015450 (New Max), Reward: 1.22, 12:50:54\u001b[0m\n",
      "\u001b[94mStep: 2568, PSNR Before: 24.920982, PSNR After: 24.921017, PSNR Change: 0.000034, PSNR Diff: 0.015484 (New Max), Reward: 2.75, 12:50:57\u001b[0m\n",
      "\u001b[94mStep: 2577, PSNR Before: 24.921017, PSNR After: 24.921064, PSNR Change: 0.000048, PSNR Diff: 0.015532 (New Max), Reward: 3.81, 12:51:06\u001b[0m\n",
      "\u001b[94mStep: 2582, PSNR Before: 24.921064, PSNR After: 24.921066, PSNR Change: 0.000002, PSNR Diff: 0.015533 (New Max), Reward: 0.15, 12:51:11\u001b[0m\n",
      "\u001b[94mStep: 2589, PSNR Before: 24.921066, PSNR After: 24.921072, PSNR Change: 0.000006, PSNR Diff: 0.015539 (New Max), Reward: 0.46, 12:51:18\u001b[0m\n",
      "\u001b[94mStep: 2592, PSNR Before: 24.921072, PSNR After: 24.921120, PSNR Change: 0.000048, PSNR Diff: 0.015587 (New Max), Reward: 3.81, 12:51:22\u001b[0m\n",
      "\u001b[94mStep: 2594, PSNR Before: 24.921120, PSNR After: 24.921139, PSNR Change: 0.000019, PSNR Diff: 0.015606 (New Max), Reward: 1.53, 12:51:25\u001b[0m\n",
      "\u001b[94mStep: 2595, PSNR Before: 24.921139, PSNR After: 24.921165, PSNR Change: 0.000027, PSNR Diff: 0.015633 (New Max), Reward: 2.14, 12:51:27\u001b[0m\n",
      "\u001b[94mStep: 2601, PSNR Before: 24.921165, PSNR After: 24.921169, PSNR Change: 0.000004, PSNR Diff: 0.015636 (New Max), Reward: 0.31, 12:51:33\u001b[0m\n",
      "\u001b[94mStep: 2602, PSNR Before: 24.921169, PSNR After: 24.921238, PSNR Change: 0.000069, PSNR Diff: 0.015705 (New Max), Reward: 5.49, 12:51:35\u001b[0m\n",
      "\u001b[94mStep: 2604, PSNR Before: 24.921238, PSNR After: 24.921253, PSNR Change: 0.000015, PSNR Diff: 0.015720 (New Max), Reward: 1.22, 12:51:38\u001b[0m\n",
      "\u001b[94mStep: 2606, PSNR Before: 24.921253, PSNR After: 24.921263, PSNR Change: 0.000010, PSNR Diff: 0.015730 (New Max), Reward: 0.76, 12:51:41\u001b[0m\n",
      "\u001b[94mStep: 2621, PSNR Before: 24.921263, PSNR After: 24.921396, PSNR Change: 0.000134, PSNR Diff: 0.015863 (New Max), Reward: 10.68, 12:51:55\u001b[0m\n",
      "\u001b[94mStep: 2624, PSNR Before: 24.921396, PSNR After: 24.921429, PSNR Change: 0.000032, PSNR Diff: 0.015896 (New Max), Reward: 2.59, 12:51:59\u001b[0m\n",
      "\u001b[94mStep: 2626, PSNR Before: 24.921429, PSNR After: 24.921467, PSNR Change: 0.000038, PSNR Diff: 0.015934 (New Max), Reward: 3.05, 12:52:01\u001b[0m\n",
      "\u001b[94mStep: 2627, PSNR Before: 24.921467, PSNR After: 24.921516, PSNR Change: 0.000050, PSNR Diff: 0.015984 (New Max), Reward: 3.97, 12:52:03\u001b[0m\n",
      "\u001b[94mStep: 2629, PSNR Before: 24.921516, PSNR After: 24.921560, PSNR Change: 0.000044, PSNR Diff: 0.016027 (New Max), Reward: 3.51, 12:52:06\u001b[0m\n",
      "\u001b[94mStep: 2632, PSNR Before: 24.921560, PSNR After: 24.921566, PSNR Change: 0.000006, PSNR Diff: 0.016033 (New Max), Reward: 0.46, 12:52:10\u001b[0m\n",
      "\u001b[94mStep: 2633, PSNR Before: 24.921566, PSNR After: 24.921570, PSNR Change: 0.000004, PSNR Diff: 0.016037 (New Max), Reward: 0.31, 12:52:11\u001b[0m\n",
      "\u001b[94mStep: 2638, PSNR Before: 24.921570, PSNR After: 24.921591, PSNR Change: 0.000021, PSNR Diff: 0.016058 (New Max), Reward: 1.68, 12:52:17\u001b[0m\n",
      "\u001b[94mStep: 2642, PSNR Before: 24.921591, PSNR After: 24.921608, PSNR Change: 0.000017, PSNR Diff: 0.016075 (New Max), Reward: 1.37, 12:52:21\u001b[0m\n",
      "\u001b[94mStep: 2657, PSNR Before: 24.921608, PSNR After: 24.921646, PSNR Change: 0.000038, PSNR Diff: 0.016113 (New Max), Reward: 3.05, 12:52:37\u001b[0m\n",
      "\u001b[94mStep: 2664, PSNR Before: 24.921646, PSNR After: 24.921669, PSNR Change: 0.000023, PSNR Diff: 0.016136 (New Max), Reward: 1.83, 12:52:44\u001b[0m\n",
      "\u001b[94mStep: 2678, PSNR Before: 24.921669, PSNR After: 24.921734, PSNR Change: 0.000065, PSNR Diff: 0.016201 (New Max), Reward: 5.19, 12:52:57\u001b[0m\n",
      "\u001b[94mStep: 2681, PSNR Before: 24.921734, PSNR After: 24.921885, PSNR Change: 0.000151, PSNR Diff: 0.016352 (New Max), Reward: 12.05, 12:53:01\u001b[0m\n",
      "\u001b[94mStep: 2683, PSNR Before: 24.921885, PSNR After: 24.921953, PSNR Change: 0.000069, PSNR Diff: 0.016420 (New Max), Reward: 5.49, 12:53:04\u001b[0m\n",
      "\u001b[94mStep: 2686, PSNR Before: 24.921953, PSNR After: 24.921970, PSNR Change: 0.000017, PSNR Diff: 0.016438 (New Max), Reward: 1.37, 12:53:07\u001b[0m\n",
      "\u001b[94mStep: 2691, PSNR Before: 24.921970, PSNR After: 24.921986, PSNR Change: 0.000015, PSNR Diff: 0.016453 (New Max), Reward: 1.22, 12:53:13\u001b[0m\n",
      "\u001b[94mStep: 2692, PSNR Before: 24.921986, PSNR After: 24.922102, PSNR Change: 0.000116, PSNR Diff: 0.016569 (New Max), Reward: 9.31, 12:53:15\u001b[0m\n",
      "\u001b[94mStep: 2698, PSNR Before: 24.922102, PSNR After: 24.922106, PSNR Change: 0.000004, PSNR Diff: 0.016573 (New Max), Reward: 0.31, 12:53:21\u001b[0m\n",
      "\u001b[94mStep: 2704, PSNR Before: 24.922106, PSNR After: 24.922222, PSNR Change: 0.000116, PSNR Diff: 0.016689 (New Max), Reward: 9.31, 12:53:28\u001b[0m\n",
      "\u001b[94mStep: 2706, PSNR Before: 24.922222, PSNR After: 24.922247, PSNR Change: 0.000025, PSNR Diff: 0.016714 (New Max), Reward: 1.98, 12:53:31\u001b[0m\n",
      "\u001b[94mStep: 2717, PSNR Before: 24.922247, PSNR After: 24.922297, PSNR Change: 0.000050, PSNR Diff: 0.016764 (New Max), Reward: 3.97, 12:53:41\u001b[0m\n",
      "\u001b[94mStep: 2722, PSNR Before: 24.922297, PSNR After: 24.922314, PSNR Change: 0.000017, PSNR Diff: 0.016781 (New Max), Reward: 1.37, 12:53:47\u001b[0m\n",
      "\u001b[94mStep: 2728, PSNR Before: 24.922314, PSNR After: 24.922354, PSNR Change: 0.000040, PSNR Diff: 0.016821 (New Max), Reward: 3.20, 12:53:53\u001b[0m\n",
      "\u001b[94mStep: 2730, PSNR Before: 24.922354, PSNR After: 24.922392, PSNR Change: 0.000038, PSNR Diff: 0.016859 (New Max), Reward: 3.05, 12:53:56\u001b[0m\n",
      "\u001b[94mStep: 2738, PSNR Before: 24.922392, PSNR After: 24.922401, PSNR Change: 0.000010, PSNR Diff: 0.016869 (New Max), Reward: 0.76, 12:54:04\u001b[0m\n",
      "\u001b[94mStep: 2751, PSNR Before: 24.922401, PSNR After: 24.922424, PSNR Change: 0.000023, PSNR Diff: 0.016891 (New Max), Reward: 1.83, 12:54:17\u001b[0m\n",
      "\u001b[94mStep: 2752, PSNR Before: 24.922424, PSNR After: 24.922432, PSNR Change: 0.000008, PSNR Diff: 0.016899 (New Max), Reward: 0.61, 12:54:19\u001b[0m\n",
      "\u001b[94mStep: 2762, PSNR Before: 24.922432, PSNR After: 24.922449, PSNR Change: 0.000017, PSNR Diff: 0.016916 (New Max), Reward: 1.37, 12:54:29\u001b[0m\n",
      "\u001b[94mStep: 2764, PSNR Before: 24.922449, PSNR After: 24.922497, PSNR Change: 0.000048, PSNR Diff: 0.016964 (New Max), Reward: 3.81, 12:54:31\u001b[0m\n",
      "\u001b[94mStep: 2771, PSNR Before: 24.922497, PSNR After: 24.922543, PSNR Change: 0.000046, PSNR Diff: 0.017010 (New Max), Reward: 3.66, 12:54:39\u001b[0m\n",
      "\u001b[94mStep: 2781, PSNR Before: 24.922543, PSNR After: 24.922579, PSNR Change: 0.000036, PSNR Diff: 0.017046 (New Max), Reward: 2.90, 12:54:49\u001b[0m\n",
      "\u001b[94mStep: 2791, PSNR Before: 24.922579, PSNR After: 24.922588, PSNR Change: 0.000010, PSNR Diff: 0.017056 (New Max), Reward: 0.76, 12:54:59\u001b[0m\n",
      "\u001b[94mStep: 2792, PSNR Before: 24.922588, PSNR After: 24.922617, PSNR Change: 0.000029, PSNR Diff: 0.017084 (New Max), Reward: 2.29, 12:55:01\u001b[0m\n",
      "\u001b[94mStep: 2798, PSNR Before: 24.922617, PSNR After: 24.922655, PSNR Change: 0.000038, PSNR Diff: 0.017122 (New Max), Reward: 3.05, 12:55:07\u001b[0m\n",
      "\u001b[94mStep: 2807, PSNR Before: 24.922655, PSNR After: 24.922764, PSNR Change: 0.000109, PSNR Diff: 0.017231 (New Max), Reward: 8.70, 12:55:16\u001b[0m\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 3120          |\n",
      "|    total_timesteps      | 2816          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4342368e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -14.6         |\n",
      "|    explained_variance   | 0.0529        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 0.38          |\n",
      "|    n_updates            | 100           |\n",
      "|    policy_gradient_loss | -0.000218     |\n",
      "|    value_loss           | 0.824         |\n",
      "-------------------------------------------\n",
      "\u001b[94mStep: 2813, PSNR Before: 24.922764, PSNR After: 24.922773, PSNR Change: 0.000010, PSNR Diff: 0.017241 (New Max), Reward: 0.76, 12:55:30\u001b[0m\n",
      "\u001b[94mStep: 2830, PSNR Before: 24.922773, PSNR After: 24.922775, PSNR Change: 0.000002, PSNR Diff: 0.017242 (New Max), Reward: 0.15, 12:55:47\u001b[0m\n",
      "\u001b[94mStep: 2833, PSNR Before: 24.922775, PSNR After: 24.922819, PSNR Change: 0.000044, PSNR Diff: 0.017286 (New Max), Reward: 3.51, 12:55:51\u001b[0m\n",
      "\u001b[94mStep: 2844, PSNR Before: 24.922819, PSNR After: 24.922821, PSNR Change: 0.000002, PSNR Diff: 0.017288 (New Max), Reward: 0.15, 12:56:02\u001b[0m\n",
      "\u001b[94mStep: 2846, PSNR Before: 24.922821, PSNR After: 24.922857, PSNR Change: 0.000036, PSNR Diff: 0.017324 (New Max), Reward: 2.90, 12:56:04\u001b[0m\n",
      "\u001b[94mStep: 2849, PSNR Before: 24.922857, PSNR After: 24.922874, PSNR Change: 0.000017, PSNR Diff: 0.017342 (New Max), Reward: 1.37, 12:56:08\u001b[0m\n",
      "\u001b[94mStep: 2853, PSNR Before: 24.922874, PSNR After: 24.922901, PSNR Change: 0.000027, PSNR Diff: 0.017368 (New Max), Reward: 2.14, 12:56:12\u001b[0m\n",
      "\u001b[94mStep: 2867, PSNR Before: 24.922901, PSNR After: 24.922909, PSNR Change: 0.000008, PSNR Diff: 0.017376 (New Max), Reward: 0.61, 12:56:28\u001b[0m\n",
      "\u001b[94mStep: 2868, PSNR Before: 24.922909, PSNR After: 24.922913, PSNR Change: 0.000004, PSNR Diff: 0.017380 (New Max), Reward: 0.31, 12:56:30\u001b[0m\n",
      "\u001b[94mStep: 2869, PSNR Before: 24.922913, PSNR After: 24.922974, PSNR Change: 0.000061, PSNR Diff: 0.017441 (New Max), Reward: 4.88, 12:56:31\u001b[0m\n",
      "\u001b[94mStep: 2876, PSNR Before: 24.922974, PSNR After: 24.923103, PSNR Change: 0.000130, PSNR Diff: 0.017570 (New Max), Reward: 10.38, 12:56:39\u001b[0m\n",
      "\u001b[94mStep: 2881, PSNR Before: 24.923103, PSNR After: 24.923119, PSNR Change: 0.000015, PSNR Diff: 0.017586 (New Max), Reward: 1.22, 12:56:45\u001b[0m\n",
      "\u001b[94mStep: 2882, PSNR Before: 24.923119, PSNR After: 24.923130, PSNR Change: 0.000011, PSNR Diff: 0.017597 (New Max), Reward: 0.92, 12:56:47\u001b[0m\n",
      "\u001b[94mStep: 2890, PSNR Before: 24.923130, PSNR After: 24.923231, PSNR Change: 0.000101, PSNR Diff: 0.017698 (New Max), Reward: 8.09, 12:56:55\u001b[0m\n",
      "\u001b[94mStep: 2897, PSNR Before: 24.923231, PSNR After: 24.923250, PSNR Change: 0.000019, PSNR Diff: 0.017717 (New Max), Reward: 1.53, 12:57:02\u001b[0m\n",
      "\u001b[94mStep: 2899, PSNR Before: 24.923250, PSNR After: 24.923325, PSNR Change: 0.000074, PSNR Diff: 0.017792 (New Max), Reward: 5.95, 12:57:05\u001b[0m\n",
      "\u001b[94mStep: 2912, PSNR Before: 24.923325, PSNR After: 24.923468, PSNR Change: 0.000143, PSNR Diff: 0.017935 (New Max), Reward: 11.44, 12:57:19\u001b[0m\n",
      "\u001b[94mStep: 2915, PSNR Before: 24.923468, PSNR After: 24.923487, PSNR Change: 0.000019, PSNR Diff: 0.017954 (New Max), Reward: 1.53, 12:57:22\u001b[0m\n",
      "\u001b[94mStep: 2919, PSNR Before: 24.923487, PSNR After: 24.923594, PSNR Change: 0.000107, PSNR Diff: 0.018061 (New Max), Reward: 8.54, 12:57:27\u001b[0m\n",
      "\u001b[94mStep: 2925, PSNR Before: 24.923594, PSNR After: 24.923599, PSNR Change: 0.000006, PSNR Diff: 0.018066 (New Max), Reward: 0.46, 12:57:34\u001b[0m\n",
      "\u001b[94mStep: 2929, PSNR Before: 24.923599, PSNR After: 24.923609, PSNR Change: 0.000010, PSNR Diff: 0.018076 (New Max), Reward: 0.76, 12:57:38\u001b[0m\n",
      "\u001b[94mStep: 2933, PSNR Before: 24.923609, PSNR After: 24.923653, PSNR Change: 0.000044, PSNR Diff: 0.018120 (New Max), Reward: 3.51, 12:57:43\u001b[0m\n",
      "\u001b[94mStep: 2934, PSNR Before: 24.923653, PSNR After: 24.923656, PSNR Change: 0.000004, PSNR Diff: 0.018124 (New Max), Reward: 0.31, 12:57:44\u001b[0m\n",
      "\u001b[94mStep: 2947, PSNR Before: 24.923656, PSNR After: 24.923670, PSNR Change: 0.000013, PSNR Diff: 0.018137 (New Max), Reward: 1.07, 12:57:57\u001b[0m\n",
      "\u001b[94mStep: 2948, PSNR Before: 24.923670, PSNR After: 24.923733, PSNR Change: 0.000063, PSNR Diff: 0.018200 (New Max), Reward: 5.04, 12:57:59\u001b[0m\n",
      "\u001b[94mStep: 2954, PSNR Before: 24.923733, PSNR After: 24.923752, PSNR Change: 0.000019, PSNR Diff: 0.018219 (New Max), Reward: 1.53, 12:58:05\u001b[0m\n",
      "\u001b[94mStep: 2958, PSNR Before: 24.923752, PSNR After: 24.923765, PSNR Change: 0.000013, PSNR Diff: 0.018232 (New Max), Reward: 1.07, 12:58:10\u001b[0m\n",
      "\u001b[94mStep: 2962, PSNR Before: 24.923765, PSNR After: 24.923901, PSNR Change: 0.000135, PSNR Diff: 0.018368 (New Max), Reward: 10.83, 12:58:15\u001b[0m\n",
      "\u001b[94mStep: 2969, PSNR Before: 24.923901, PSNR After: 24.923906, PSNR Change: 0.000006, PSNR Diff: 0.018373 (New Max), Reward: 0.46, 12:58:22\u001b[0m\n",
      "\u001b[94mStep: 2973, PSNR Before: 24.923906, PSNR After: 24.923950, PSNR Change: 0.000044, PSNR Diff: 0.018417 (New Max), Reward: 3.51, 12:58:27\u001b[0m\n",
      "\u001b[94mStep: 2975, PSNR Before: 24.923950, PSNR After: 24.923954, PSNR Change: 0.000004, PSNR Diff: 0.018421 (New Max), Reward: 0.31, 12:58:30\u001b[0m\n",
      "\u001b[94mStep: 2979, PSNR Before: 24.923954, PSNR After: 24.923977, PSNR Change: 0.000023, PSNR Diff: 0.018444 (New Max), Reward: 1.83, 12:58:34\u001b[0m\n",
      "\u001b[94mStep: 2980, PSNR Before: 24.923977, PSNR After: 24.924034, PSNR Change: 0.000057, PSNR Diff: 0.018501 (New Max), Reward: 4.58, 12:58:36\u001b[0m\n",
      "\u001b[94mStep: 2987, PSNR Before: 24.924034, PSNR After: 24.924065, PSNR Change: 0.000031, PSNR Diff: 0.018532 (New Max), Reward: 2.44, 12:58:43\u001b[0m\n",
      "\u001b[94mStep: 2999, PSNR Before: 24.924065, PSNR After: 24.924089, PSNR Change: 0.000025, PSNR Diff: 0.018557 (New Max), Reward: 1.98, 12:58:56\u001b[0m\n",
      "\u001b[94mStep: 3007, PSNR Before: 24.924089, PSNR After: 24.924156, PSNR Change: 0.000067, PSNR Diff: 0.018623 (New Max), Reward: 5.34, 12:59:04\u001b[0m\n",
      "\u001b[94mStep: 3008, PSNR Before: 24.924156, PSNR After: 24.924162, PSNR Change: 0.000006, PSNR Diff: 0.018629 (New Max), Reward: 0.46, 12:59:06\u001b[0m\n",
      "\u001b[94mStep: 3013, PSNR Before: 24.924162, PSNR After: 24.924198, PSNR Change: 0.000036, PSNR Diff: 0.018665 (New Max), Reward: 2.90, 12:59:11\u001b[0m\n",
      "\u001b[94mStep: 3014, PSNR Before: 24.924198, PSNR After: 24.924328, PSNR Change: 0.000130, PSNR Diff: 0.018795 (New Max), Reward: 10.38, 12:59:13\u001b[0m\n",
      "\u001b[94mStep: 3020, PSNR Before: 24.924328, PSNR After: 24.924358, PSNR Change: 0.000031, PSNR Diff: 0.018826 (New Max), Reward: 2.44, 12:59:20\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "from sb3_contrib import MaskablePPO\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import torchOptics.optics as tt\n",
    "import torch.nn as nn\n",
    "import torchOptics.metrics as tm\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torchvision\n",
    "import tqdm\n",
    "import time\n",
    "import pandas as pd\n",
    "from sb3_contrib.common.maskable.utils import get_action_masks\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "from stable_baselines3 import PPO\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#      \n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "class BinaryNet(nn.Module):\n",
    "    def __init__(self, num_hologram, final='Sigmoid', in_planes=3,\n",
    "                 channels=[32, 64, 128, 256, 512, 1024, 2048, 4096],\n",
    "                 convReLU=True, convBN=True, poolReLU=True, poolBN=True,\n",
    "                 deconvReLU=True, deconvBN=True):\n",
    "        super(BinaryNet, self).__init__()\n",
    "\n",
    "        def CRB2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True, relu=True, bn=True):\n",
    "            layers = []\n",
    "            layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                 kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                                 bias=bias)]\n",
    "            if relu:\n",
    "                layers += [nn.Tanh()]\n",
    "            if bn:\n",
    "                layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "\n",
    "            cbr = nn.Sequential(*layers)  # * list unpacking\n",
    "\n",
    "            return cbr\n",
    "\n",
    "        def TRB2d(in_channels, out_channels, kernel_size=2, stride=2, bias=True, relu=True, bn=True):\n",
    "            layers = []\n",
    "            layers += [nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                          kernel_size=2, stride=2, padding=0,\n",
    "                                          bias=True)]\n",
    "            if bn:\n",
    "                layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "            if relu:\n",
    "                layers += [nn.ReLU()]\n",
    "\n",
    "            cbr = nn.Sequential(*layers)  # * list unpacking\n",
    "\n",
    "            return cbr\n",
    "\n",
    "        self.enc1_1 = CRB2d(in_planes, channels[0], relu=convReLU, bn=convBN)\n",
    "        self.enc1_2 = CRB2d(channels[0], channels[0], relu=convReLU, bn=convBN)\n",
    "        self.pool1 = CRB2d(channels[0], channels[0], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc2_1 = CRB2d(channels[0], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.enc2_2 = CRB2d(channels[1], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.pool2 = CRB2d(channels[1], channels[1], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc3_1 = CRB2d(channels[1], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.enc3_2 = CRB2d(channels[2], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.pool3 = CRB2d(channels[2], channels[2], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc4_1 = CRB2d(channels[2], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.enc4_2 = CRB2d(channels[3], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.pool4 = CRB2d(channels[3], channels[3], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc5_1 = CRB2d(channels[3], channels[4], relu=convReLU, bn=convBN)\n",
    "        self.enc5_2 = CRB2d(channels[4], channels[4], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv4 = TRB2d(channels[4], channels[3], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec4_1 = CRB2d(channels[4], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.dec4_2 = CRB2d(channels[3], channels[3], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv3 = TRB2d(channels[3], channels[2], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec3_1 = CRB2d(channels[3], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.dec3_2 = CRB2d(channels[2], channels[2], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv2 = TRB2d(channels[2], channels[1], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec2_1 = CRB2d(channels[2], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.dec2_2 = CRB2d(channels[1], channels[1], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv1 = TRB2d(channels[1], channels[0], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec1_1 = CRB2d(channels[1], channels[0], relu=convReLU, bn=convBN)\n",
    "        self.dec1_2 = CRB2d(channels[0], channels[0], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.classifier = CRB2d(channels[0], num_hologram, relu=False, bn=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1_1 = self.enc1_1(x)\n",
    "        enc1_2 = self.enc1_2(enc1_1)\n",
    "        pool1 = self.pool1(enc1_2)\n",
    "\n",
    "        enc2_1 = self.enc2_1(pool1)\n",
    "        enc2_2 = self.enc2_2(enc2_1)\n",
    "        pool2 = self.pool2(enc2_2)\n",
    "\n",
    "        enc3_1 = self.enc3_1(pool2)\n",
    "        enc3_2 = self.enc3_2(enc3_1)\n",
    "        pool3 = self.pool3(enc3_2)\n",
    "\n",
    "        enc4_1 = self.enc4_1(pool3)\n",
    "        enc4_2 = self.enc4_2(enc4_1)\n",
    "        pool4 = self.pool4(enc4_2)\n",
    "\n",
    "        enc5_1 = self.enc5_1(pool4)\n",
    "        enc5_2 = self.enc5_2(enc5_1)\n",
    "\n",
    "        deconv4 = self.deconv4(enc5_2)\n",
    "        concat4 = torch.cat((deconv4, enc4_2), dim=1)\n",
    "        dec4_1 = self.dec4_1(concat4)\n",
    "        dec4_2 = self.dec4_2(dec4_1)\n",
    "\n",
    "        deconv3 = self.deconv3(dec4_2)\n",
    "        concat3 = torch.cat((deconv3, enc3_2), dim=1)\n",
    "        dec3_1 = self.dec3_1(concat3)\n",
    "        dec3_2 = self.dec3_2(dec3_1)\n",
    "\n",
    "        deconv2 = self.deconv2(dec3_2)\n",
    "        concat2 = torch.cat((deconv2, enc2_2), dim=1)\n",
    "        dec2_1 = self.dec2_1(concat2)\n",
    "        dec2_2 = self.dec2_2(dec2_1)\n",
    "\n",
    "        deconv1 = self.deconv1(dec2_2)\n",
    "        concat1 = torch.cat((deconv1, enc1_2), dim=1)\n",
    "        dec1_1 = self.dec1_1(concat1)\n",
    "        dec1_2 = self.dec1_2(dec1_1)\n",
    "\n",
    "        # Final classifier\n",
    "        out = self.classifier(dec1_2)\n",
    "        out = nn.Sigmoid()(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = BinaryNet(num_hologram=8, in_planes=1, convReLU=False,\n",
    "                  convBN=False, poolReLU=False, poolBN=False,\n",
    "                  deconvReLU=False, deconvBN=False).cuda()\n",
    "test = torch.randn(1, 1, 512, 512).cuda()\n",
    "out = model(test)\n",
    "print(out.shape)\n",
    "\n",
    "\n",
    "class Dataset512(Dataset):\n",
    "    def __init__(self, target_dir, meta, transform=None, isTrain=True, padding=0):\n",
    "        self.target_dir = target_dir\n",
    "        self.transform = transform\n",
    "        self.meta = meta\n",
    "        self.isTrain = isTrain\n",
    "        self.target_list = sorted(glob.glob(target_dir+'*.png'))\n",
    "        self.center_crop = torchvision.transforms.CenterCrop(512)\n",
    "        self.random_crop = torchvision.transforms.RandomCrop((512, 512))\n",
    "        self.padding = padding\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        target = tt.imread(self.target_list[idx], meta=meta, gray=True).unsqueeze(0)\n",
    "        if target.shape[-1] < 512 or target.shape[-2] < 512:\n",
    "            target = torchvision.transforms.Resize(512)(target)\n",
    "        if self.isTrain:\n",
    "            target = self.random_crop(target)\n",
    "            target = torchvision.transforms.functional.pad(target, (self.padding, self.padding, self.padding, self.padding))\n",
    "        else:\n",
    "            target = self.center_crop(target)\n",
    "            target = torchvision.transforms.functional.pad(target, (self.padding, self.padding, self.padding, self.padding))\n",
    "        return target\n",
    "\n",
    "\n",
    "# BinaryHologramEnv \n",
    "class BinaryHologramEnv(gym.Env):\n",
    "    def __init__(self, target_function, trainloader, max_steps=10000, T_PSNR=30, T_steps=10, T_PSNR_DIFF=0.1, max_allowed_changes=1):\n",
    "        \"\"\"\n",
    "          .\n",
    "        target_function:   (MSE  PSNR)  .\n",
    "        trainloader:   .\n",
    "        max_steps:   .\n",
    "        T_PSNR:  PSNR .\n",
    "        T_steps: PSNR     .\n",
    "        T_PSNR_DIFF: PSNR  .\n",
    "        max_allowed_changes:        (: 1).\n",
    "        \"\"\"\n",
    "        super(BinaryHologramEnv, self).__init__()\n",
    "\n",
    "        #  : (1, 8, 512, 512)\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(1, 8, 512, 512), dtype=np.float32)\n",
    "\n",
    "        #  :     (512 * 512 * 8)\n",
    "        self.num_pixels = 8 * 512 * 512\n",
    "        self.action_space = spaces.Discrete(self.num_pixels)\n",
    "\n",
    "        #     \n",
    "        self.target_function = target_function\n",
    "        self.trainloader = trainloader\n",
    "\n",
    "        #  \n",
    "        self.max_steps = max_steps\n",
    "        self.T_PSNR = T_PSNR\n",
    "        self.T_steps = T_steps\n",
    "        self.T_PSNR_DIFF = T_PSNR_DIFF\n",
    "        self.max_allowed_changes = max_allowed_changes  #  \n",
    "\n",
    "        #   \n",
    "        self.state = None\n",
    "        self.observation = None\n",
    "        self.steps = 0\n",
    "        self.psnr_sustained_steps = 0\n",
    "\n",
    "        #     \n",
    "        self.data_iter = iter(self.trainloader)\n",
    "        self.target_image = None\n",
    "\n",
    "        #    \n",
    "        self.retry_current_target = False  #    \n",
    "\n",
    "        #    \n",
    "        self.consecutive_fail_count = 0  #   \n",
    "        self.max_consecutive_failures = 0  #     \n",
    "\n",
    "        #  PSNR_DIFF  \n",
    "        self.max_psnr_diff = float('-inf')  #   PSNR_DIFF \n",
    "\n",
    "    def reset(self, seed=None, options=None, z=2e-3):\n",
    "        \"\"\"\n",
    "          .\n",
    "              .\n",
    "        -    . \n",
    "        - BinaryNet    .\n",
    "        -  (state)   .\n",
    "        -  PSNR MSE  .\n",
    "        -      .\n",
    "\n",
    "        Args:\n",
    "            seed (int, optional):   . Default None.\n",
    "            options (dict, optional):  . Default None.\n",
    "            lr (float, optional): . Default 1e-4.\n",
    "            z (float, optional):  . Default 2e-3.\n",
    "\n",
    "        Returns:\n",
    "            observation (np.ndarray):  .\n",
    "            dict:    .\n",
    "        \"\"\"\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        if self.retry_current_target:  #    \n",
    "            self.consecutive_fail_count += 1\n",
    "        else:\n",
    "            self.consecutive_fail_count = 0  #     \n",
    "\n",
    "        self.max_consecutive_failures = max(self.max_consecutive_failures, self.consecutive_fail_count)\n",
    "\n",
    "        if not self.retry_current_target:  #      \n",
    "            try:\n",
    "                self.target_image = next(self.data_iter)\n",
    "            except StopIteration:\n",
    "                self.data_iter = iter(self.trainloader)\n",
    "                self.target_image = next(self.data_iter)\n",
    "\n",
    "        #    PSNR  \n",
    "        self.max_psnr_diff = float('-inf')\n",
    "\n",
    "        self.target_image = self.target_image.cuda()\n",
    "        with torch.no_grad():\n",
    "            model_output = self.target_function(self.target_image)\n",
    "        self.observation = model_output.cpu().numpy()  # (1, 8, 512, 512)\n",
    "\n",
    "        self.steps = 0\n",
    "        self.psnr_sustained_steps = 0\n",
    "        self.state = (self.observation >= 0.5).astype(np.int8)  #  \n",
    "\n",
    "        binary = torch.tensor(self.state, dtype=torch.float32).cuda()\n",
    "        binary = tt.Tensor(binary, meta={'dx': (7.56e-6, 7.56e-6), 'wl': 515e-9})  # meta  \n",
    "\n",
    "        # \n",
    "        sim = tt.simulate(binary, z).abs()**2\n",
    "        result = torch.mean(sim, dim=1, keepdim=True)\n",
    "\n",
    "        # MSE  PSNR \n",
    "        mse = tt.relativeLoss(result, self.target_image, F.mse_loss).detach().cpu().numpy()\n",
    "        self.initial_psnr = tt.relativeLoss(result, self.target_image, tm.get_PSNR)  #  PSNR \n",
    "\n",
    "        print(f\"\\033[91mResetting environment. Consecutive episode failures: {self.consecutive_fail_count}, Max consecutive episode failures: {self.max_consecutive_failures}\\033[0m\")\n",
    "\n",
    "        current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        print(f\"Initial MSE: {mse:.6f}, Initial PSNR: {self.initial_psnr:.6f}, {current_time}\")\n",
    "\n",
    "        self.retry_current_target = False  #      \n",
    "        mask = self.create_action_mask(self.observation)\n",
    "        return self.observation, {\"state\": self.state, \"mask\": mask}\n",
    "\n",
    "\n",
    "    def initialize_state(self, z=2e-3):\n",
    "        \"\"\"\n",
    "          ,     .\n",
    "\n",
    "        Args:\n",
    "            z (float):  . Default 2e-3.\n",
    "\n",
    "        Returns:\n",
    "            observation (np.ndarray):  .\n",
    "            dict:    .\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            #    \n",
    "            model_output = self.target_function(self.target_image)\n",
    "        self.observation = model_output.cpu().numpy()  #  numpy  \n",
    "\n",
    "        #     \n",
    "        self.state = (self.observation >= 0.5).astype(np.int8)\n",
    "\n",
    "        binary = torch.tensor(self.state, dtype=torch.float32).cuda()  #  Torch  \n",
    "        binary = tt.Tensor(binary, meta={'dx': (7.56e-6, 7.56e-6), 'wl': 515e-9})  #   \n",
    "\n",
    "        #  \n",
    "        sim = tt.simulate(binary, z).abs()**2\n",
    "        result = torch.mean(sim, dim=1, keepdim=True)\n",
    "\n",
    "        #  MSE PSNR \n",
    "        mse = tt.relativeLoss(result, self.target_image, F.mse_loss).detach().cpu().numpy()\n",
    "        psnr = tt.relativeLoss(result, self.target_image, tm.get_PSNR)\n",
    "\n",
    "        #   \n",
    "        print(f\"Initial MSE: {mse:.6f}, Initial PSNR: {psnr:.6f}, {datetime.now()}\")\n",
    "\n",
    "        #    \n",
    "        self.simulation_result = result.detach().cpu().numpy()\n",
    "\n",
    "        #  \n",
    "        mask = self.create_action_mask(self.observation)\n",
    "\n",
    "        # (  ) \n",
    "        return self.observation, {\"state\": self.state, \"mask\": mask}\n",
    "\n",
    "    def create_action_mask(self, observation):\n",
    "        \"\"\"\n",
    "            .\n",
    "        -  0.2 ~ 0.8     .\n",
    "\n",
    "        Args:\n",
    "            observation (np.ndarray): .\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray:    1,    0.\n",
    "        \"\"\"\n",
    "        #     \n",
    "        mask = np.zeros(self.num_pixels, dtype=np.int8)\n",
    "\n",
    "        # (1, 8, 512, 512) -> (8, 512, 512) \n",
    "        obs = observation.squeeze()\n",
    "\n",
    "        #      \n",
    "        for channel in range(obs.shape[0]):\n",
    "            indices = np.where((obs[channel] > 0) & (obs[channel] < 1))\n",
    "            for row, col in zip(*indices):\n",
    "                pixel_idx = channel * 512 * 512 + row * 512 + col\n",
    "                mask[pixel_idx] = 1  #   \n",
    "\n",
    "        return mask\n",
    "\n",
    "    def step(self, action, lr=1e-4, z=2e-3):\n",
    "        \"\"\"\n",
    "           .\n",
    "        -  (action) ,   .\n",
    "        -    PSNR (psnr_change)  .\n",
    "        - psnr_change 0     .\n",
    "\n",
    "        Args:\n",
    "            action (np.ndarray):   .\n",
    "            lr (float, optional): . Default 1e-4.\n",
    "            z (float, optional):  . Default 2e-3.\n",
    "\n",
    "        Returns:\n",
    "            observation (np.ndarray):  .\n",
    "            float:  .\n",
    "            bool:  .\n",
    "            bool: Truncated .\n",
    "            dict:   (MSE, PSNR, PSNR_DIFF,   ).\n",
    "        \"\"\"\n",
    "        if self.steps == 0:\n",
    "            print(\"Executing reset logic for the first step\")\n",
    "            self.steps += 1\n",
    "            observation, info = self.initialize_state(z)\n",
    "            return observation, 0.0, False, False, info\n",
    "\n",
    "        #   \n",
    "        mask = self.create_action_mask(self.observation)\n",
    "        if mask.flatten()[action] == 0:\n",
    "            #       \n",
    "            #print(f\"Invalid action taken at step {self.steps}, action: {action}\")\n",
    "            return self.observation, -10.0, False, False, {\"mask\": mask}\n",
    "\n",
    "        #   PSNR \n",
    "        binary_before = torch.tensor(self.state, dtype=torch.float32).cuda()\n",
    "        binary_before = tt.Tensor(binary_before, meta={'dx': (7.56e-6, 7.56e-6), 'wl': 515e-9})\n",
    "        sim_before = tt.simulate(binary_before, z).abs()**2\n",
    "        result_before = torch.mean(sim_before, dim=1, keepdim=True)\n",
    "        psnr_before = tt.relativeLoss(result_before, self.target_image, tm.get_PSNR)\n",
    "\n",
    "        #     \n",
    "        channel = action // (512 * 512)\n",
    "        pixel_index = action % (512 * 512)\n",
    "        row = pixel_index // 512\n",
    "        col = pixel_index % 512\n",
    "\n",
    "        #   \n",
    "        self.state[0, channel, row, col] = 1 - self.state[0, channel, row, col]\n",
    "\n",
    "        #     \n",
    "        binary_after = torch.tensor(self.state, dtype=torch.float32).cuda()\n",
    "        binary_after = tt.Tensor(binary_after, meta={'dx': (7.56e-6, 7.56e-6), 'wl': 515e-9})\n",
    "        sim_after = tt.simulate(binary_after, z).abs()**2\n",
    "        result_after = torch.mean(sim_after, dim=1, keepdim=True)\n",
    "        psnr_after = tt.relativeLoss(result_after, self.target_image, tm.get_PSNR)\n",
    "\n",
    "        # PSNR  \n",
    "        psnr_change = psnr_after - psnr_before\n",
    "\n",
    "        # psnr_change     \n",
    "        if psnr_change < 0:\n",
    "            #    \n",
    "            self.state[0, channel, row, col] = 1 - self.state[0, channel, row, col]\n",
    "            #  \n",
    "            self.steps += 1\n",
    "            # psnr_change   \n",
    "            reward = psnr_change * 80000  #      \n",
    "            #    \n",
    "            return self.observation, reward, False, False, {\"psnr_change\": psnr_change, \"mask\": mask}\n",
    "\n",
    "        # PSNR_CHANGE 0     \n",
    "        #if psnr_change < 0:\n",
    "            #print(f\"Invalid action: PSNR Change {psnr_change:.6f} < 0 at step {self.steps}\")\n",
    "        #    return self.observation, -10.0, False, False, {\"psnr_before\": psnr_before, \"psnr_after\": psnr_after, \"psnr_change\": psnr_change, \"mask\": mask}\n",
    "\n",
    "        #  PSNR_DIFF \n",
    "        psnr_diff = psnr_after - self.initial_psnr\n",
    "        is_max_psnr_diff = psnr_diff > self.max_psnr_diff  #  PSNR_DIFF \n",
    "        self.max_psnr_diff = max(self.max_psnr_diff, psnr_diff)  #  PSNR_DIFF \n",
    "\n",
    "        #  \n",
    "        reward = psnr_change * 80000  # PSNR (psnr_change)  \n",
    "\n",
    "        #   \n",
    "        if psnr_diff < -0.01:\n",
    "            print(f\"\\033[91mEpisode failed: PSNR Diff {psnr_diff:.6f} < -0.01 at step {self.steps}\\033[0m\")\n",
    "            self.retry_current_target = True  #     \n",
    "            return self.observation, -100.0, True, False, {\"psnr_diff\": psnr_diff, \"mask\": None}\n",
    "\n",
    "        #  PSNR_DIFF  \n",
    "        if is_max_psnr_diff:\n",
    "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "            print(\n",
    "                f\"\\033[94mStep: {self.steps}, PSNR Before: {psnr_before:.6f}, PSNR After: {psnr_after:.6f}, \"\n",
    "                f\"PSNR Change: {psnr_change:.6f}, PSNR Diff: {psnr_diff:.6f} (New Max), \"\n",
    "                f\"Reward: {reward:.2f}, {current_time}\\033[0m\"\n",
    "            )\n",
    "\n",
    "        #   (100  )\n",
    "        if self.steps % 100 == 0:\n",
    "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "            print(f\"Step: {self.steps}, PSNR Before: {psnr_before:.6f}, PSNR After: {psnr_after:.6f}, \"\n",
    "                  f\"PSNR Change: {psnr_change:.6f}, PSNR Diff: {psnr_diff:.6f}, Reward: {reward:.2f}, {current_time}\")\n",
    "\n",
    "        #   : PSNR >= T_PSNR  PSNR_DIFF >= T_PSNR_DIFF\n",
    "        terminated = self.steps >= self.max_steps or self.psnr_sustained_steps >= self.T_steps\n",
    "        truncated = self.steps >= self.max_steps\n",
    "\n",
    "        if psnr_after >= self.T_PSNR or psnr_diff >= self.T_PSNR_DIFF:\n",
    "            self.psnr_sustained_steps += 1\n",
    "            if self.psnr_sustained_steps >= self.T_steps:  #   \n",
    "                reward += 100  #     \n",
    "        else:\n",
    "            self.psnr_sustained_steps = 0\n",
    "\n",
    "        #  \n",
    "        mask = self.create_action_mask(self.observation)\n",
    "        info = {\n",
    "            \"psnr_before\": psnr_before,\n",
    "            \"psnr_after\": psnr_after,\n",
    "            \"psnr_change\": psnr_change,\n",
    "            \"psnr_diff\": psnr_diff,\n",
    "            \"mask\": mask\n",
    "        }\n",
    "\n",
    "        del binary_before, binary_after, sim_before, sim_after, result_before, result_after\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        self.steps += 1\n",
    "        return self.observation, reward, terminated, truncated, info\n",
    "\n",
    "\n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_uniform_(m.weight.data, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight.data, 1)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight.data)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "batch_size = 1\n",
    "target_dir = '/nfs/dataset/DIV2K/DIV2K_train_HR/DIV2K_train_HR/'\n",
    "valid_dir = '/nfs/dataset/DIV2K/DIV2K_valid_HR/DIV2K_valid_HR/'\n",
    "meta = {'wl': (515e-9), 'dx': (7.56e-6, 7.56e-6)}  #  \n",
    "padding = 0\n",
    "\n",
    "# Dataset512  \n",
    "train_dataset = Dataset512(target_dir=target_dir, meta=meta, isTrain=True, padding=padding)\n",
    "valid_dataset = Dataset512(target_dir=valid_dir, meta=meta, isTrain=False, padding=padding)\n",
    "\n",
    "# DataLoader \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# BinaryNet  \n",
    "model = BinaryNet(num_hologram=8, in_planes=1, convReLU=False, convBN=False,\n",
    "                  poolReLU=False, poolBN=False, deconvReLU=False, deconvBN=False).cuda()\n",
    "model.load_state_dict(torch.load('result_v/2024-12-19 20:37:52.499731_pre_reinforce_8_0.002/2024-12-19 20:37:52.499731_pre_reinforce_8_0.002'))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "#   \n",
    "def mask_fn(env):\n",
    "    return env.create_action_mask(env.observation)\n",
    "\n",
    "#      \n",
    "env = BinaryHologramEnv(\n",
    "    target_function=model,\n",
    "    trainloader=train_loader,  #  train_loader \n",
    "    max_steps=10000,\n",
    "    T_PSNR=30,\n",
    "    T_steps=10\n",
    ")\n",
    "\n",
    "# ActionMasker  \n",
    "env = ActionMasker(env, mask_fn)\n",
    "\n",
    "# Vectorized  \n",
    "venv = make_vec_env(lambda: env, n_envs=1)\n",
    "venv = VecNormalize(venv, norm_obs=True, norm_reward=True, clip_obs=10.0)\n",
    "\n",
    "# PPO \n",
    "ppo_model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    venv,\n",
    "    verbose=2,\n",
    "    n_steps=256,\n",
    "    batch_size=64,\n",
    "    gamma=0.99,\n",
    "    gae_lambda=0.95,\n",
    "    learning_rate=1e-5,  #  \n",
    "    clip_range=0.2,\n",
    "    vf_coef=0.5,\n",
    "    max_grad_norm=0.2,  # Gradient clipping \n",
    "    tensorboard_log=\"./ppo_with_mask/\"\n",
    ")\n",
    "\n",
    "ppo_model.learn(total_timesteps=10000000)\n",
    "\n",
    "#   \n",
    "ppo_model.save(f\"ppo_with_mask_{current_date}\")\n",
    "\n",
    "\n",
    "# PPO   \n",
    "#policy_kwargs = dict(\n",
    "#    net_arch=[dict(pi=[256, 256], vf=[256, 256])]  #    \n",
    "#)\n",
    "\n",
    "# PPO  \n",
    "#ppo_model = PPO(\n",
    "#    \"MlpPolicy\",  # LSTM    MLP \n",
    "#    venv,\n",
    "#    verbose=2,\n",
    "#    n_steps=256,\n",
    "#    batch_size=64,\n",
    "#    gamma=0.99,\n",
    "#    gae_lambda=0.95,\n",
    "#    learning_rate=1e-5,\n",
    "#    clip_range=0.2,\n",
    "#    vf_coef=0.5,\n",
    "#    max_grad_norm=0.5,  #   \n",
    "#    tensorboard_log=\"./ppo_with_mask/\",\n",
    "#    policy_kwargs=policy_kwargs\n",
    "#)\n",
    "\n",
    "# \n",
    "#ppo_model.learn(total_timesteps=10000000)\n",
    "\n",
    "#  \n",
    "#ppo_model.save(f\"ppo_with_mask_{current_date}\")\n",
    "\n",
    "\n",
    "# PPO \n",
    "#ppo_model = PPO(\n",
    "#    \"MlpPolicy\",\n",
    "#    venv,\n",
    "#    verbose=2,\n",
    "#    n_steps=1024,\n",
    "#    batch_size=64,\n",
    "#    gamma=0.99,\n",
    "#    learning_rate=3e-4,\n",
    "#    tensorboard_log=\"./ppo_with_mask/\"\n",
    "#)\n",
    "\n",
    "#ppo_model.learn(total_timesteps=10000000)\n",
    "\n",
    "#   \n",
    "#ppo_model.save(f\"ppo_with_mask_{current_date}\")\n",
    "\n",
    "#from sb3_contrib import RecurrentPPO\n",
    "\n",
    "#policy_kwargs = dict(\n",
    "#    net_arch=[dict(pi=[256, 256], vf=[256, 256])],  #    \n",
    "#    lstm_hidden_size=128,  # LSTM  \n",
    "#    shared_lstm=False  #  LSTM \n",
    "#)\n",
    "\n",
    "#ppo_model = RecurrentPPO(\n",
    "#    \"MlpLstmPolicy\",\n",
    "#    venv,\n",
    "#    verbose=2,\n",
    "#    n_steps=256,\n",
    "#    batch_size=64,\n",
    "#    gamma=0.99,\n",
    "#    gae_lambda=0.95,\n",
    "#    learning_rate=1e-5,\n",
    "#    clip_range=0.2,\n",
    "#    vf_coef=0.5,\n",
    "#    max_grad_norm=0.5,  #   \n",
    "#    tensorboard_log=\"./ppo_with_mask/\",\n",
    "#    policy_kwargs=policy_kwargs\n",
    "#)\n",
    "\n",
    "\n",
    "# \n",
    "#ppo_model.learn(total_timesteps=10000000)\n",
    "\n",
    "#  \n",
    "#ppo_model.save(f\"ppo_with_mask_{current_date}\")\n",
    "\n",
    "\n",
    "#   \n",
    "#eval_env = make_vec_env(lambda: env, n_envs=1)\n",
    "\n",
    "# EvalCallback \n",
    "#eval_callback = EvalCallback(\n",
    "#    eval_env,\n",
    "#    best_model_save_path='./logs/',\n",
    "#    log_path='./logs/',\n",
    "#    eval_freq=10000,  #   ( )\n",
    "#    deterministic=True,\n",
    "#    render=False\n",
    "#)\n",
    "\n",
    "#ppo_model = PPO(\n",
    "#    \"MlpPolicy\",\n",
    "#    venv,\n",
    "#    verbose=2,\n",
    "#    n_steps=1024,\n",
    "#    batch_size=64,\n",
    "#    gamma=0.99,\n",
    "#    learning_rate=3e-4,\n",
    "#    tensorboard_log=\"./ppo_with_mask/\"\n",
    "#\n",
    "\n",
    "#   ( )\n",
    "#ppo_model.learn(total_timesteps=10000000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dd0c83-99b3-4f86-bc23-89c6b278e3ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e105c7a2-bd3a-440c-9ad3-3ec9a08af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
