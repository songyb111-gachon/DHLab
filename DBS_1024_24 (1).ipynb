{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898d2556-551d-48b6-a8b9-0c2d4a30dbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 메시지는 콘솔과 파일에 동시에 기록됩니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "이 메시지도 로그에 기록됩니다.\n",
      "/usr/local/lib/python3.8/dist-packages/kornia/feature/lightglue.py:30: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24, 1024, 1024])\n",
      "\u001b[40;93m[Episode Start] Currently using dataset file: ('/nfs/dataset/DIV2K/DIV2K_valid_HR/DIV2K_valid_HR/0801.png',), Episode count: 1\u001b[0m\n",
      "\u001b[92mInitial PSNR: 25.759916\u001b[0m\n",
      "Initial MSE: 0.002655\u001b[0m\n",
      "Starting pixel flip optimization for file 801.png with initial PSNR: 25.759916\n",
      "g_change: -0.00000954, steps: 1, Flip Pixel: Channel=15, Row=684, Col=312\n",
      "rgb_change: -0.00000954, steps: 1, Flip Pixel: Channel=15, Row=684, Col=312\n",
      "\n",
      "g_change: 0.00000572, steps: 2, Flip Pixel: Channel=15, Row=418, Col=753\n",
      "rgb_change: 0.00000572, steps: 2, Flip Pixel: Channel=15, Row=418, Col=753\n",
      "\n",
      "b_change: 0.00000000, steps: 3, Flip Pixel: Channel=20, Row=252, Col=781\n",
      "rgb_change: 0.00000000, steps: 3, Flip Pixel: Channel=20, Row=252, Col=781\n",
      "\n",
      "b_change: -0.00000763, steps: 4, Flip Pixel: Channel=16, Row=731, Col=31\n",
      "rgb_change: -0.00000763, steps: 4, Flip Pixel: Channel=16, Row=731, Col=31\n",
      "\n",
      "r_change: 0.00000191, steps: 5, Flip Pixel: Channel=3, Row=44, Col=943\n",
      "rgb_change: 0.00000572, steps: 5, Flip Pixel: Channel=3, Row=44, Col=943\n",
      "\n",
      "r_change: -0.00000572, steps: 6, Flip Pixel: Channel=3, Row=602, Col=462\n",
      "rgb_change: -0.00000572, steps: 6, Flip Pixel: Channel=3, Row=602, Col=462\n",
      "\n",
      "r_change: 0.00000000, steps: 7, Flip Pixel: Channel=4, Row=166, Col=254\n",
      "rgb_change: 0.00000000, steps: 7, Flip Pixel: Channel=4, Row=166, Col=254\n",
      "\n",
      "r_change: 0.00000191, steps: 8, Flip Pixel: Channel=2, Row=222, Col=149\n",
      "rgb_change: 0.00000191, steps: 8, Flip Pixel: Channel=2, Row=222, Col=149\n",
      "\n",
      "r_change: -0.00001335, steps: 9, Flip Pixel: Channel=2, Row=467, Col=360\n",
      "rgb_change: -0.00001335, steps: 9, Flip Pixel: Channel=2, Row=467, Col=360\n",
      "\n",
      "b_change: -0.00002670, steps: 10, Flip Pixel: Channel=17, Row=774, Col=378\n",
      "rgb_change: -0.00001335, steps: 10, Flip Pixel: Channel=17, Row=774, Col=378\n",
      "\n",
      "r_change: -0.00000191, steps: 11, Flip Pixel: Channel=4, Row=83, Col=204\n",
      "rgb_change: 0.00001144, steps: 11, Flip Pixel: Channel=4, Row=83, Col=204\n",
      "\n",
      "r_change: -0.00000381, steps: 12, Flip Pixel: Channel=2, Row=25, Col=449\n",
      "rgb_change: -0.00000381, steps: 12, Flip Pixel: Channel=2, Row=25, Col=449\n",
      "\n",
      "b_change: -0.00002480, steps: 13, Flip Pixel: Channel=17, Row=473, Col=948\n",
      "rgb_change: -0.00001907, steps: 13, Flip Pixel: Channel=17, Row=473, Col=948\n",
      "\n",
      "b_change: -0.00002289, steps: 14, Flip Pixel: Channel=22, Row=5, Col=557\n",
      "rgb_change: -0.00002289, steps: 14, Flip Pixel: Channel=22, Row=5, Col=557\n",
      "\n",
      "b_change: -0.00000572, steps: 15, Flip Pixel: Channel=19, Row=444, Col=824\n",
      "rgb_change: -0.00000572, steps: 15, Flip Pixel: Channel=19, Row=444, Col=824\n",
      "\n",
      "b_change: -0.00001335, steps: 16, Flip Pixel: Channel=16, Row=450, Col=195\n",
      "rgb_change: -0.00001335, steps: 16, Flip Pixel: Channel=16, Row=450, Col=195\n",
      "\n",
      "g_change: -0.00001907, steps: 17, Flip Pixel: Channel=11, Row=444, Col=220\n",
      "rgb_change: -0.00001144, steps: 17, Flip Pixel: Channel=11, Row=444, Col=220\n",
      "\n",
      "g_change: -0.00000572, steps: 18, Flip Pixel: Channel=10, Row=145, Col=72\n",
      "rgb_change: -0.00000572, steps: 18, Flip Pixel: Channel=10, Row=145, Col=72\n",
      "\n",
      "r_change: -0.00000572, steps: 19, Flip Pixel: Channel=1, Row=198, Col=508\n",
      "rgb_change: 0.00000191, steps: 19, Flip Pixel: Channel=1, Row=198, Col=508\n",
      "\n",
      "g_change: -0.00001335, steps: 20, Flip Pixel: Channel=8, Row=57, Col=890\n",
      "rgb_change: -0.00001335, steps: 20, Flip Pixel: Channel=8, Row=57, Col=890\n",
      "\n",
      "g_change: -0.00000572, steps: 21, Flip Pixel: Channel=11, Row=8, Col=848\n",
      "rgb_change: -0.00000572, steps: 21, Flip Pixel: Channel=11, Row=8, Col=848\n",
      "\n",
      "g_change: -0.00000572, steps: 22, Flip Pixel: Channel=10, Row=615, Col=637\n",
      "rgb_change: -0.00000572, steps: 22, Flip Pixel: Channel=10, Row=615, Col=637\n",
      "\n",
      "r_change: -0.00002480, steps: 23, Flip Pixel: Channel=4, Row=866, Col=563\n",
      "rgb_change: -0.00001907, steps: 23, Flip Pixel: Channel=4, Row=866, Col=563\n",
      "\n",
      "b_change: -0.00003815, steps: 24, Flip Pixel: Channel=21, Row=674, Col=433\n",
      "rgb_change: -0.00001907, steps: 24, Flip Pixel: Channel=21, Row=674, Col=433\n",
      "\n",
      "r_change: -0.00002098, steps: 25, Flip Pixel: Channel=1, Row=963, Col=718\n",
      "rgb_change: -0.00000191, steps: 25, Flip Pixel: Channel=1, Row=963, Col=718\n",
      "\n",
      "r_change: -0.00000191, steps: 26, Flip Pixel: Channel=1, Row=927, Col=762\n",
      "rgb_change: -0.00000191, steps: 26, Flip Pixel: Channel=1, Row=927, Col=762\n",
      "\n",
      "g_change: -0.00000191, steps: 27, Flip Pixel: Channel=9, Row=704, Col=849\n",
      "rgb_change: -0.00000191, steps: 27, Flip Pixel: Channel=9, Row=704, Col=849\n",
      "\n",
      "b_change: 0.00000000, steps: 28, Flip Pixel: Channel=17, Row=163, Col=318\n",
      "rgb_change: 0.00000000, steps: 28, Flip Pixel: Channel=17, Row=163, Col=318\n",
      "\n",
      "g_change: 0.00000572, steps: 29, Flip Pixel: Channel=11, Row=274, Col=611\n",
      "rgb_change: 0.00000191, steps: 29, Flip Pixel: Channel=11, Row=274, Col=611\n",
      "\n",
      "r_change: -0.00001717, steps: 30, Flip Pixel: Channel=5, Row=254, Col=1011\n",
      "rgb_change: -0.00001717, steps: 30, Flip Pixel: Channel=5, Row=254, Col=1011\n",
      "\n",
      "g_change: -0.00002670, steps: 31, Flip Pixel: Channel=12, Row=274, Col=343\n",
      "rgb_change: -0.00000763, steps: 31, Flip Pixel: Channel=12, Row=274, Col=343\n",
      "\n",
      "b_change: -0.00000763, steps: 32, Flip Pixel: Channel=19, Row=784, Col=658\n",
      "rgb_change: 0.00000000, steps: 32, Flip Pixel: Channel=19, Row=784, Col=658\n",
      "\n",
      "g_change: 0.00000000, steps: 33, Flip Pixel: Channel=15, Row=242, Col=211\n",
      "rgb_change: 0.00000000, steps: 33, Flip Pixel: Channel=15, Row=242, Col=211\n",
      "\n",
      "r_change: -0.00001526, steps: 34, Flip Pixel: Channel=4, Row=514, Col=930\n",
      "rgb_change: -0.00001526, steps: 34, Flip Pixel: Channel=4, Row=514, Col=930\n",
      "\n",
      "r_change: -0.00000381, steps: 35, Flip Pixel: Channel=5, Row=706, Col=219\n",
      "rgb_change: -0.00000381, steps: 35, Flip Pixel: Channel=5, Row=706, Col=219\n",
      "\n",
      "r_change: 0.00000000, steps: 36, Flip Pixel: Channel=0, Row=698, Col=376\n",
      "rgb_change: 0.00000000, steps: 36, Flip Pixel: Channel=0, Row=698, Col=376\n",
      "\n",
      "g_change: -0.00000763, steps: 37, Flip Pixel: Channel=11, Row=857, Col=870\n",
      "rgb_change: -0.00000763, steps: 37, Flip Pixel: Channel=11, Row=857, Col=870\n",
      "\n",
      "g_change: -0.00000381, steps: 38, Flip Pixel: Channel=14, Row=185, Col=531\n",
      "rgb_change: -0.00000381, steps: 38, Flip Pixel: Channel=14, Row=185, Col=531\n",
      "\n",
      "b_change: -0.00002098, steps: 39, Flip Pixel: Channel=19, Row=145, Col=493\n",
      "rgb_change: -0.00001717, steps: 39, Flip Pixel: Channel=19, Row=145, Col=493\n",
      "\n",
      "r_change: -0.00002289, steps: 40, Flip Pixel: Channel=6, Row=621, Col=365\n",
      "rgb_change: -0.00000381, steps: 40, Flip Pixel: Channel=6, Row=621, Col=365\n",
      "\n",
      "g_change: -0.00000191, steps: 41, Flip Pixel: Channel=9, Row=2, Col=441\n",
      "rgb_change: 0.00000763, steps: 41, Flip Pixel: Channel=9, Row=2, Col=441\n",
      "\n",
      "r_change: 0.00000381, steps: 42, Flip Pixel: Channel=5, Row=157, Col=440\n",
      "rgb_change: 0.00000381, steps: 42, Flip Pixel: Channel=5, Row=157, Col=440\n",
      "\n",
      "b_change: -0.00000191, steps: 43, Flip Pixel: Channel=23, Row=105, Col=784\n",
      "rgb_change: -0.00000191, steps: 43, Flip Pixel: Channel=23, Row=105, Col=784\n",
      "\n",
      "b_change: -0.00001144, steps: 44, Flip Pixel: Channel=17, Row=317, Col=165\n",
      "rgb_change: -0.00001144, steps: 44, Flip Pixel: Channel=17, Row=317, Col=165\n",
      "\n",
      "r_change: -0.00000763, steps: 45, Flip Pixel: Channel=0, Row=669, Col=956\n",
      "rgb_change: 0.00000381, steps: 45, Flip Pixel: Channel=0, Row=669, Col=956\n",
      "\n",
      "b_change: 0.00000000, steps: 46, Flip Pixel: Channel=17, Row=11, Col=488\n",
      "rgb_change: 0.00000000, steps: 46, Flip Pixel: Channel=17, Row=11, Col=488\n",
      "\n",
      "r_change: 0.00000000, steps: 47, Flip Pixel: Channel=0, Row=954, Col=860\n",
      "rgb_change: 0.00000000, steps: 47, Flip Pixel: Channel=0, Row=954, Col=860\n",
      "\n",
      "g_change: 0.00000000, steps: 48, Flip Pixel: Channel=9, Row=666, Col=722\n",
      "rgb_change: 0.00000000, steps: 48, Flip Pixel: Channel=9, Row=666, Col=722\n",
      "\n",
      "g_change: -0.00001144, steps: 49, Flip Pixel: Channel=13, Row=535, Col=950\n",
      "rgb_change: -0.00001144, steps: 49, Flip Pixel: Channel=13, Row=535, Col=950\n",
      "\n",
      "b_change: -0.00000763, steps: 50, Flip Pixel: Channel=19, Row=978, Col=397\n",
      "rgb_change: 0.00000191, steps: 50, Flip Pixel: Channel=19, Row=978, Col=397\n",
      "\n",
      "r_change: -0.00000572, steps: 51, Flip Pixel: Channel=2, Row=602, Col=839\n",
      "rgb_change: -0.00000572, steps: 51, Flip Pixel: Channel=2, Row=602, Col=839\n",
      "\n",
      "r_change: 0.00000191, steps: 52, Flip Pixel: Channel=1, Row=316, Col=979\n",
      "rgb_change: 0.00000191, steps: 52, Flip Pixel: Channel=1, Row=316, Col=979\n",
      "\n",
      "b_change: -0.00001144, steps: 53, Flip Pixel: Channel=18, Row=589, Col=35\n",
      "rgb_change: -0.00001144, steps: 53, Flip Pixel: Channel=18, Row=589, Col=35\n",
      "\n",
      "g_change: -0.00002098, steps: 54, Flip Pixel: Channel=10, Row=618, Col=572\n",
      "rgb_change: -0.00000763, steps: 54, Flip Pixel: Channel=10, Row=618, Col=572\n",
      "\n",
      "g_change: 0.00000000, steps: 55, Flip Pixel: Channel=15, Row=1010, Col=115\n",
      "rgb_change: 0.00000000, steps: 55, Flip Pixel: Channel=15, Row=1010, Col=115\n",
      "\n",
      "b_change: -0.00001144, steps: 56, Flip Pixel: Channel=23, Row=764, Col=138\n",
      "rgb_change: -0.00001144, steps: 56, Flip Pixel: Channel=23, Row=764, Col=138\n",
      "\n",
      "b_change: 0.00000000, steps: 57, Flip Pixel: Channel=22, Row=561, Col=758\n",
      "rgb_change: 0.00000000, steps: 57, Flip Pixel: Channel=22, Row=561, Col=758\n",
      "\n",
      "r_change: -0.00001717, steps: 58, Flip Pixel: Channel=6, Row=467, Col=184\n",
      "rgb_change: -0.00001717, steps: 58, Flip Pixel: Channel=6, Row=467, Col=184\n",
      "\n",
      "g_change: -0.00002098, steps: 59, Flip Pixel: Channel=8, Row=126, Col=793\n",
      "rgb_change: -0.00000381, steps: 59, Flip Pixel: Channel=8, Row=126, Col=793\n",
      "\n",
      "b_change: -0.00000381, steps: 60, Flip Pixel: Channel=17, Row=829, Col=814\n",
      "rgb_change: 0.00000000, steps: 60, Flip Pixel: Channel=17, Row=829, Col=814\n",
      "\n",
      "g_change: 0.00000000, steps: 61, Flip Pixel: Channel=11, Row=163, Col=633\n",
      "rgb_change: 0.00000000, steps: 61, Flip Pixel: Channel=11, Row=163, Col=633\n",
      "\n",
      "b_change: -0.00000381, steps: 62, Flip Pixel: Channel=19, Row=368, Col=267\n",
      "rgb_change: -0.00000381, steps: 62, Flip Pixel: Channel=19, Row=368, Col=267\n",
      "\n",
      "b_change: -0.00000191, steps: 63, Flip Pixel: Channel=22, Row=51, Col=32\n",
      "rgb_change: -0.00000191, steps: 63, Flip Pixel: Channel=22, Row=51, Col=32\n",
      "\n",
      "g_change: -0.00002098, steps: 64, Flip Pixel: Channel=12, Row=753, Col=939\n",
      "rgb_change: -0.00001907, steps: 64, Flip Pixel: Channel=12, Row=753, Col=939\n",
      "\n",
      "b_change: -0.00002289, steps: 65, Flip Pixel: Channel=21, Row=749, Col=265\n",
      "rgb_change: -0.00000381, steps: 65, Flip Pixel: Channel=21, Row=749, Col=265\n",
      "\n",
      "g_change: -0.00000954, steps: 66, Flip Pixel: Channel=10, Row=979, Col=443\n",
      "rgb_change: -0.00000381, steps: 66, Flip Pixel: Channel=10, Row=979, Col=443\n",
      "\n",
      "b_change: -0.00001526, steps: 67, Flip Pixel: Channel=18, Row=539, Col=275\n",
      "rgb_change: -0.00000763, steps: 67, Flip Pixel: Channel=18, Row=539, Col=275\n",
      "\n",
      "r_change: -0.00002098, steps: 68, Flip Pixel: Channel=7, Row=152, Col=738\n",
      "rgb_change: -0.00001144, steps: 68, Flip Pixel: Channel=7, Row=152, Col=738\n",
      "\n",
      "b_change: -0.00002670, steps: 69, Flip Pixel: Channel=16, Row=244, Col=404\n",
      "rgb_change: -0.00001526, steps: 69, Flip Pixel: Channel=16, Row=244, Col=404\n",
      "\n",
      "r_change: -0.00000954, steps: 70, Flip Pixel: Channel=0, Row=220, Col=675\n",
      "rgb_change: 0.00000381, steps: 70, Flip Pixel: Channel=0, Row=220, Col=675\n",
      "\n",
      "r_change: -0.00000191, steps: 71, Flip Pixel: Channel=3, Row=151, Col=884\n",
      "rgb_change: -0.00000191, steps: 71, Flip Pixel: Channel=3, Row=151, Col=884\n",
      "\n",
      "r_change: -0.00000763, steps: 72, Flip Pixel: Channel=3, Row=629, Col=67\n",
      "rgb_change: -0.00000763, steps: 72, Flip Pixel: Channel=3, Row=629, Col=67\n",
      "\n",
      "b_change: -0.00001907, steps: 73, Flip Pixel: Channel=20, Row=913, Col=274\n",
      "rgb_change: -0.00000763, steps: 73, Flip Pixel: Channel=20, Row=913, Col=274\n",
      "\n",
      "b_change: -0.00001144, steps: 74, Flip Pixel: Channel=18, Row=331, Col=257\n",
      "rgb_change: -0.00001144, steps: 74, Flip Pixel: Channel=18, Row=331, Col=257\n",
      "\n",
      "r_change: -0.00001526, steps: 75, Flip Pixel: Channel=7, Row=475, Col=561\n",
      "rgb_change: -0.00000381, steps: 75, Flip Pixel: Channel=7, Row=475, Col=561\n",
      "\n",
      "b_change: -0.00000381, steps: 76, Flip Pixel: Channel=19, Row=717, Col=1005\n",
      "rgb_change: 0.00000000, steps: 76, Flip Pixel: Channel=19, Row=717, Col=1005\n",
      "\n",
      "g_change: -0.00000381, steps: 77, Flip Pixel: Channel=11, Row=198, Col=190\n",
      "rgb_change: -0.00000381, steps: 77, Flip Pixel: Channel=11, Row=198, Col=190\n",
      "\n",
      "g_change: 0.00000572, steps: 78, Flip Pixel: Channel=8, Row=593, Col=79\n",
      "rgb_change: 0.00000572, steps: 78, Flip Pixel: Channel=8, Row=593, Col=79\n",
      "\n",
      "r_change: 0.00000000, steps: 79, Flip Pixel: Channel=4, Row=552, Col=647\n",
      "rgb_change: 0.00000000, steps: 79, Flip Pixel: Channel=4, Row=552, Col=647\n",
      "\n",
      "g_change: -0.00001144, steps: 80, Flip Pixel: Channel=10, Row=611, Col=450\n",
      "rgb_change: -0.00000954, steps: 80, Flip Pixel: Channel=10, Row=611, Col=450\n",
      "\n",
      "b_change: -0.00000954, steps: 81, Flip Pixel: Channel=19, Row=256, Col=394\n",
      "rgb_change: 0.00000000, steps: 81, Flip Pixel: Channel=19, Row=256, Col=394\n",
      "\n",
      "b_change: -0.00000954, steps: 82, Flip Pixel: Channel=23, Row=375, Col=841\n",
      "rgb_change: -0.00000954, steps: 82, Flip Pixel: Channel=23, Row=375, Col=841\n",
      "\n",
      "b_change: -0.00000191, steps: 83, Flip Pixel: Channel=21, Row=795, Col=751\n",
      "rgb_change: -0.00000191, steps: 83, Flip Pixel: Channel=21, Row=795, Col=751\n",
      "\n",
      "r_change: -0.00000763, steps: 84, Flip Pixel: Channel=1, Row=863, Col=278\n",
      "rgb_change: -0.00000572, steps: 84, Flip Pixel: Channel=1, Row=863, Col=278\n",
      "\n",
      "b_change: -0.00000191, steps: 85, Flip Pixel: Channel=16, Row=215, Col=205\n",
      "rgb_change: 0.00000191, steps: 85, Flip Pixel: Channel=16, Row=215, Col=205\n",
      "\n",
      "b_change: -0.00000191, steps: 86, Flip Pixel: Channel=18, Row=625, Col=146\n",
      "rgb_change: -0.00000191, steps: 86, Flip Pixel: Channel=18, Row=625, Col=146\n",
      "\n",
      "b_change: -0.00000381, steps: 87, Flip Pixel: Channel=20, Row=382, Col=375\n",
      "rgb_change: -0.00000381, steps: 87, Flip Pixel: Channel=20, Row=382, Col=375\n",
      "\n",
      "b_change: 0.00000000, steps: 88, Flip Pixel: Channel=19, Row=968, Col=742\n",
      "rgb_change: 0.00000000, steps: 88, Flip Pixel: Channel=19, Row=968, Col=742\n",
      "\n",
      "r_change: -0.00000954, steps: 89, Flip Pixel: Channel=4, Row=91, Col=885\n",
      "rgb_change: -0.00000954, steps: 89, Flip Pixel: Channel=4, Row=91, Col=885\n",
      "\n",
      "g_change: -0.00001907, steps: 90, Flip Pixel: Channel=10, Row=827, Col=203\n",
      "rgb_change: -0.00001144, steps: 90, Flip Pixel: Channel=10, Row=827, Col=203\n",
      "\n",
      "r_change: -0.00001335, steps: 91, Flip Pixel: Channel=2, Row=846, Col=907\n",
      "rgb_change: -0.00000191, steps: 91, Flip Pixel: Channel=2, Row=846, Col=907\n",
      "\n",
      "b_change: -0.00000191, steps: 92, Flip Pixel: Channel=16, Row=328, Col=404\n",
      "rgb_change: 0.00000000, steps: 92, Flip Pixel: Channel=16, Row=328, Col=404\n",
      "\n",
      "r_change: -0.00000191, steps: 93, Flip Pixel: Channel=2, Row=378, Col=586\n",
      "rgb_change: -0.00000191, steps: 93, Flip Pixel: Channel=2, Row=378, Col=586\n",
      "\n",
      "b_change: -0.00002098, steps: 94, Flip Pixel: Channel=18, Row=311, Col=274\n",
      "rgb_change: -0.00001907, steps: 94, Flip Pixel: Channel=18, Row=311, Col=274\n",
      "\n",
      "r_change: -0.00001907, steps: 95, Flip Pixel: Channel=5, Row=338, Col=934\n",
      "rgb_change: -0.00000191, steps: 95, Flip Pixel: Channel=5, Row=338, Col=934\n",
      "\n",
      "b_change: -0.00000191, steps: 96, Flip Pixel: Channel=20, Row=707, Col=952\n",
      "rgb_change: 0.00000000, steps: 96, Flip Pixel: Channel=20, Row=707, Col=952\n",
      "\n",
      "g_change: -0.00000763, steps: 97, Flip Pixel: Channel=11, Row=665, Col=757\n",
      "rgb_change: -0.00000763, steps: 97, Flip Pixel: Channel=11, Row=665, Col=757\n",
      "\n",
      "b_change: -0.00002098, steps: 98, Flip Pixel: Channel=23, Row=415, Col=517\n",
      "rgb_change: -0.00001526, steps: 98, Flip Pixel: Channel=23, Row=415, Col=517\n",
      "\n",
      "r_change: -0.00001526, steps: 99, Flip Pixel: Channel=2, Row=620, Col=665\n",
      "rgb_change: -0.00000191, steps: 99, Flip Pixel: Channel=2, Row=620, Col=665\n",
      "\n",
      "b_change: -0.00000381, steps: 100, Flip Pixel: Channel=22, Row=968, Col=978\n",
      "rgb_change: -0.00000191, steps: 100, Flip Pixel: Channel=22, Row=968, Col=978\n",
      "\n",
      "g_change: -0.00000763, steps: 101, Flip Pixel: Channel=8, Row=159, Col=258\n",
      "rgb_change: -0.00000381, steps: 101, Flip Pixel: Channel=8, Row=159, Col=258\n",
      "\n",
      "r_change: -0.00001144, steps: 102, Flip Pixel: Channel=6, Row=33, Col=594\n",
      "rgb_change: -0.00000763, steps: 102, Flip Pixel: Channel=6, Row=33, Col=594\n",
      "\n",
      "g_change: -0.00001907, steps: 103, Flip Pixel: Channel=8, Row=790, Col=476\n",
      "rgb_change: -0.00001335, steps: 103, Flip Pixel: Channel=8, Row=790, Col=476\n",
      "\n",
      "r_change: -0.00003052, steps: 104, Flip Pixel: Channel=6, Row=670, Col=15\n",
      "rgb_change: -0.00001526, steps: 104, Flip Pixel: Channel=6, Row=670, Col=15\n",
      "\n",
      "g_change: -0.00001526, steps: 105, Flip Pixel: Channel=12, Row=467, Col=922\n",
      "rgb_change: 0.00000000, steps: 105, Flip Pixel: Channel=12, Row=467, Col=922\n",
      "\n",
      "b_change: -0.00001526, steps: 106, Flip Pixel: Channel=18, Row=61, Col=709\n",
      "rgb_change: -0.00001526, steps: 106, Flip Pixel: Channel=18, Row=61, Col=709\n",
      "\n",
      "b_change: -0.00000191, steps: 107, Flip Pixel: Channel=21, Row=985, Col=706\n",
      "rgb_change: -0.00000191, steps: 107, Flip Pixel: Channel=21, Row=985, Col=706\n",
      "\n",
      "r_change: 0.00000000, steps: 108, Flip Pixel: Channel=1, Row=815, Col=565\n",
      "rgb_change: 0.00000572, steps: 108, Flip Pixel: Channel=1, Row=815, Col=565\n",
      "\n",
      "g_change: 0.00000381, steps: 109, Flip Pixel: Channel=8, Row=700, Col=720\n",
      "rgb_change: 0.00000381, steps: 109, Flip Pixel: Channel=8, Row=700, Col=720\n",
      "\n",
      "r_change: -0.00001144, steps: 110, Flip Pixel: Channel=3, Row=804, Col=440\n",
      "rgb_change: -0.00001144, steps: 110, Flip Pixel: Channel=3, Row=804, Col=440\n",
      "\n",
      "g_change: -0.00001717, steps: 111, Flip Pixel: Channel=8, Row=169, Col=961\n",
      "rgb_change: -0.00000381, steps: 111, Flip Pixel: Channel=8, Row=169, Col=961\n",
      "\n",
      "b_change: -0.00000381, steps: 112, Flip Pixel: Channel=19, Row=892, Col=710\n",
      "rgb_change: 0.00000000, steps: 112, Flip Pixel: Channel=19, Row=892, Col=710\n",
      "\n",
      "g_change: -0.00000381, steps: 113, Flip Pixel: Channel=14, Row=987, Col=631\n",
      "rgb_change: -0.00000381, steps: 113, Flip Pixel: Channel=14, Row=987, Col=631\n",
      "\n",
      "r_change: -0.00000572, steps: 114, Flip Pixel: Channel=6, Row=264, Col=36\n",
      "rgb_change: -0.00000381, steps: 114, Flip Pixel: Channel=6, Row=264, Col=36\n",
      "\n",
      "b_change: -0.00002098, steps: 115, Flip Pixel: Channel=22, Row=633, Col=201\n",
      "rgb_change: -0.00001907, steps: 115, Flip Pixel: Channel=22, Row=633, Col=201\n",
      "\n",
      "b_change: -0.00000954, steps: 116, Flip Pixel: Channel=18, Row=459, Col=393\n",
      "rgb_change: -0.00000954, steps: 116, Flip Pixel: Channel=18, Row=459, Col=393\n",
      "\n",
      "r_change: -0.00002098, steps: 117, Flip Pixel: Channel=7, Row=496, Col=724\n",
      "rgb_change: -0.00001144, steps: 117, Flip Pixel: Channel=7, Row=496, Col=724\n",
      "\n",
      "b_change: -0.00001907, steps: 118, Flip Pixel: Channel=16, Row=831, Col=311\n",
      "rgb_change: -0.00000954, steps: 118, Flip Pixel: Channel=16, Row=831, Col=311\n",
      "\n",
      "b_change: -0.00000381, steps: 119, Flip Pixel: Channel=22, Row=887, Col=706\n",
      "rgb_change: -0.00000381, steps: 119, Flip Pixel: Channel=22, Row=887, Col=706\n",
      "\n",
      "b_change: -0.00000191, steps: 120, Flip Pixel: Channel=23, Row=319, Col=63\n",
      "rgb_change: -0.00000191, steps: 120, Flip Pixel: Channel=23, Row=319, Col=63\n",
      "\n",
      "r_change: -0.00000191, steps: 121, Flip Pixel: Channel=2, Row=468, Col=518\n",
      "rgb_change: -0.00000191, steps: 121, Flip Pixel: Channel=2, Row=468, Col=518\n",
      "\n",
      "r_change: -0.00000191, steps: 122, Flip Pixel: Channel=0, Row=558, Col=700\n",
      "rgb_change: -0.00000191, steps: 122, Flip Pixel: Channel=0, Row=558, Col=700\n",
      "\n",
      "b_change: -0.00002480, steps: 123, Flip Pixel: Channel=16, Row=276, Col=308\n",
      "rgb_change: -0.00002480, steps: 123, Flip Pixel: Channel=16, Row=276, Col=308\n",
      "\n",
      "b_change: -0.00000381, steps: 124, Flip Pixel: Channel=18, Row=727, Col=283\n",
      "rgb_change: -0.00000381, steps: 124, Flip Pixel: Channel=18, Row=727, Col=283\n",
      "\n",
      "g_change: -0.00000954, steps: 125, Flip Pixel: Channel=13, Row=946, Col=957\n",
      "rgb_change: -0.00000381, steps: 125, Flip Pixel: Channel=13, Row=946, Col=957\n",
      "\n",
      "b_change: -0.00000381, steps: 126, Flip Pixel: Channel=20, Row=795, Col=286\n",
      "rgb_change: 0.00000000, steps: 126, Flip Pixel: Channel=20, Row=795, Col=286\n",
      "\n",
      "r_change: 0.00001335, steps: 127, Flip Pixel: Channel=2, Row=1016, Col=106\n",
      "rgb_change: 0.00000954, steps: 127, Flip Pixel: Channel=2, Row=1016, Col=106\n",
      "\n",
      "r_change: 0.00000954, steps: 128, Flip Pixel: Channel=6, Row=430, Col=965\n",
      "rgb_change: 0.00000954, steps: 128, Flip Pixel: Channel=6, Row=430, Col=965\n",
      "\n",
      "g_change: -0.00001717, steps: 129, Flip Pixel: Channel=11, Row=744, Col=302\n",
      "rgb_change: -0.00001717, steps: 129, Flip Pixel: Channel=11, Row=744, Col=302\n",
      "\n",
      "r_change: -0.00001907, steps: 130, Flip Pixel: Channel=4, Row=780, Col=565\n",
      "rgb_change: 0.00000000, steps: 130, Flip Pixel: Channel=4, Row=780, Col=565\n",
      "\n",
      "r_change: -0.00000381, steps: 131, Flip Pixel: Channel=3, Row=588, Col=731\n",
      "rgb_change: -0.00000381, steps: 131, Flip Pixel: Channel=3, Row=588, Col=731\n",
      "\n",
      "r_change: -0.00001144, steps: 132, Flip Pixel: Channel=5, Row=277, Col=635\n",
      "rgb_change: -0.00001144, steps: 132, Flip Pixel: Channel=5, Row=277, Col=635\n",
      "\n",
      "r_change: -0.00000572, steps: 133, Flip Pixel: Channel=7, Row=922, Col=759\n",
      "rgb_change: -0.00000572, steps: 133, Flip Pixel: Channel=7, Row=922, Col=759\n",
      "\n",
      "r_change: -0.00000381, steps: 134, Flip Pixel: Channel=5, Row=275, Col=722\n",
      "rgb_change: -0.00000381, steps: 134, Flip Pixel: Channel=5, Row=275, Col=722\n",
      "\n",
      "b_change: -0.00001907, steps: 135, Flip Pixel: Channel=21, Row=732, Col=117\n",
      "rgb_change: -0.00001335, steps: 135, Flip Pixel: Channel=21, Row=732, Col=117\n",
      "\n",
      "g_change: -0.00001907, steps: 136, Flip Pixel: Channel=10, Row=141, Col=162\n",
      "rgb_change: -0.00000381, steps: 136, Flip Pixel: Channel=10, Row=141, Col=162\n",
      "\n",
      "g_change: -0.00000572, steps: 137, Flip Pixel: Channel=15, Row=65, Col=156\n",
      "rgb_change: -0.00000572, steps: 137, Flip Pixel: Channel=15, Row=65, Col=156\n",
      "\n",
      "b_change: -0.00000572, steps: 138, Flip Pixel: Channel=18, Row=439, Col=508\n",
      "rgb_change: -0.00000191, steps: 138, Flip Pixel: Channel=18, Row=439, Col=508\n",
      "\n",
      "r_change: -0.00000381, steps: 139, Flip Pixel: Channel=5, Row=379, Col=119\n",
      "rgb_change: -0.00000191, steps: 139, Flip Pixel: Channel=5, Row=379, Col=119\n",
      "\n",
      "r_change: -0.00001335, steps: 140, Flip Pixel: Channel=4, Row=956, Col=302\n",
      "rgb_change: -0.00001335, steps: 140, Flip Pixel: Channel=4, Row=956, Col=302\n",
      "\n",
      "r_change: 0.00000191, steps: 141, Flip Pixel: Channel=5, Row=272, Col=834\n",
      "rgb_change: 0.00000191, steps: 141, Flip Pixel: Channel=5, Row=272, Col=834\n",
      "\n",
      "b_change: -0.00001144, steps: 142, Flip Pixel: Channel=16, Row=572, Col=636\n",
      "rgb_change: -0.00001144, steps: 142, Flip Pixel: Channel=16, Row=572, Col=636\n",
      "\n",
      "g_change: -0.00003052, steps: 143, Flip Pixel: Channel=8, Row=766, Col=406\n",
      "rgb_change: -0.00001526, steps: 143, Flip Pixel: Channel=8, Row=766, Col=406\n",
      "\n",
      "r_change: -0.00003052, steps: 144, Flip Pixel: Channel=2, Row=317, Col=210\n",
      "rgb_change: -0.00001335, steps: 144, Flip Pixel: Channel=2, Row=317, Col=210\n",
      "\n",
      "r_change: -0.00000572, steps: 145, Flip Pixel: Channel=2, Row=107, Col=503\n",
      "rgb_change: -0.00000572, steps: 145, Flip Pixel: Channel=2, Row=107, Col=503\n",
      "\n",
      "b_change: -0.00000763, steps: 146, Flip Pixel: Channel=23, Row=697, Col=706\n",
      "rgb_change: 0.00000000, steps: 146, Flip Pixel: Channel=23, Row=697, Col=706\n",
      "\n",
      "r_change: 0.00000000, steps: 147, Flip Pixel: Channel=0, Row=382, Col=380\n",
      "rgb_change: 0.00000000, steps: 147, Flip Pixel: Channel=0, Row=382, Col=380\n",
      "\n",
      "g_change: -0.00000381, steps: 148, Flip Pixel: Channel=14, Row=886, Col=1016\n",
      "rgb_change: -0.00000191, steps: 148, Flip Pixel: Channel=14, Row=886, Col=1016\n",
      "\n",
      "g_change: 0.00000000, steps: 149, Flip Pixel: Channel=12, Row=592, Col=588\n",
      "rgb_change: 0.00000000, steps: 149, Flip Pixel: Channel=12, Row=592, Col=588\n",
      "\n",
      "b_change: -0.00000763, steps: 150, Flip Pixel: Channel=23, Row=555, Col=220\n",
      "rgb_change: -0.00000381, steps: 150, Flip Pixel: Channel=23, Row=555, Col=220\n",
      "\n",
      "g_change: -0.00001335, steps: 151, Flip Pixel: Channel=11, Row=590, Col=401\n",
      "rgb_change: -0.00000381, steps: 151, Flip Pixel: Channel=11, Row=590, Col=401\n",
      "\n",
      "g_change: 0.00000763, steps: 152, Flip Pixel: Channel=13, Row=952, Col=385\n",
      "rgb_change: 0.00000763, steps: 152, Flip Pixel: Channel=13, Row=952, Col=385\n",
      "\n",
      "r_change: 0.00000572, steps: 153, Flip Pixel: Channel=1, Row=669, Col=562\n",
      "rgb_change: 0.00000572, steps: 153, Flip Pixel: Channel=1, Row=669, Col=562\n",
      "\n",
      "b_change: -0.00000191, steps: 154, Flip Pixel: Channel=19, Row=1007, Col=933\n",
      "rgb_change: -0.00000191, steps: 154, Flip Pixel: Channel=19, Row=1007, Col=933\n",
      "\n",
      "g_change: -0.00000572, steps: 155, Flip Pixel: Channel=12, Row=140, Col=385\n",
      "rgb_change: -0.00000572, steps: 155, Flip Pixel: Channel=12, Row=140, Col=385\n",
      "\n",
      "b_change: -0.00002098, steps: 156, Flip Pixel: Channel=16, Row=318, Col=813\n",
      "rgb_change: -0.00001717, steps: 156, Flip Pixel: Channel=16, Row=318, Col=813\n",
      "\n",
      "r_change: -0.00002861, steps: 157, Flip Pixel: Channel=5, Row=550, Col=307\n",
      "rgb_change: -0.00001335, steps: 157, Flip Pixel: Channel=5, Row=550, Col=307\n",
      "\n",
      "g_change: -0.00001526, steps: 158, Flip Pixel: Channel=14, Row=618, Col=720\n",
      "rgb_change: -0.00000572, steps: 158, Flip Pixel: Channel=14, Row=618, Col=720\n",
      "\n",
      "r_change: -0.00001526, steps: 159, Flip Pixel: Channel=4, Row=544, Col=470\n",
      "rgb_change: -0.00001335, steps: 159, Flip Pixel: Channel=4, Row=544, Col=470\n",
      "\n",
      "b_change: -0.00001335, steps: 160, Flip Pixel: Channel=20, Row=402, Col=247\n",
      "rgb_change: -0.00000191, steps: 160, Flip Pixel: Channel=20, Row=402, Col=247\n",
      "\n",
      "g_change: -0.00001335, steps: 161, Flip Pixel: Channel=10, Row=21, Col=436\n",
      "rgb_change: -0.00001335, steps: 161, Flip Pixel: Channel=10, Row=21, Col=436\n",
      "\n",
      "g_change: 0.00000000, steps: 162, Flip Pixel: Channel=13, Row=10, Col=1015\n",
      "rgb_change: 0.00000000, steps: 162, Flip Pixel: Channel=13, Row=10, Col=1015\n",
      "\n",
      "g_change: -0.00001335, steps: 163, Flip Pixel: Channel=12, Row=629, Col=417\n",
      "rgb_change: -0.00001335, steps: 163, Flip Pixel: Channel=12, Row=629, Col=417\n",
      "\n",
      "b_change: -0.00002861, steps: 164, Flip Pixel: Channel=23, Row=834, Col=928\n",
      "rgb_change: -0.00001907, steps: 164, Flip Pixel: Channel=23, Row=834, Col=928\n",
      "\n",
      "g_change: -0.00003242, steps: 165, Flip Pixel: Channel=14, Row=714, Col=334\n",
      "rgb_change: -0.00001335, steps: 165, Flip Pixel: Channel=14, Row=714, Col=334\n",
      "\n",
      "b_change: -0.00001335, steps: 166, Flip Pixel: Channel=19, Row=134, Col=72\n",
      "rgb_change: 0.00000191, steps: 166, Flip Pixel: Channel=19, Row=134, Col=72\n",
      "\n",
      "b_change: -0.00001526, steps: 167, Flip Pixel: Channel=17, Row=25, Col=944\n",
      "rgb_change: -0.00001526, steps: 167, Flip Pixel: Channel=17, Row=25, Col=944\n",
      "\n",
      "r_change: -0.00001907, steps: 168, Flip Pixel: Channel=5, Row=917, Col=709\n",
      "rgb_change: -0.00000954, steps: 168, Flip Pixel: Channel=5, Row=917, Col=709\n",
      "\n",
      "g_change: -0.00000954, steps: 169, Flip Pixel: Channel=11, Row=264, Col=63\n",
      "rgb_change: -0.00000191, steps: 169, Flip Pixel: Channel=11, Row=264, Col=63\n",
      "\n",
      "g_change: -0.00002861, steps: 170, Flip Pixel: Channel=8, Row=286, Col=461\n",
      "rgb_change: -0.00002861, steps: 170, Flip Pixel: Channel=8, Row=286, Col=461\n",
      "\n",
      "b_change: -0.00004005, steps: 171, Flip Pixel: Channel=18, Row=437, Col=59\n",
      "rgb_change: -0.00001526, steps: 171, Flip Pixel: Channel=18, Row=437, Col=59\n",
      "\n",
      "g_change: -0.00001144, steps: 172, Flip Pixel: Channel=13, Row=428, Col=963\n",
      "rgb_change: 0.00000000, steps: 172, Flip Pixel: Channel=13, Row=428, Col=963\n",
      "\n",
      "g_change: -0.00000381, steps: 173, Flip Pixel: Channel=11, Row=1002, Col=584\n",
      "rgb_change: -0.00000381, steps: 173, Flip Pixel: Channel=11, Row=1002, Col=584\n",
      "\n",
      "g_change: -0.00001526, steps: 174, Flip Pixel: Channel=9, Row=587, Col=996\n",
      "rgb_change: -0.00001526, steps: 174, Flip Pixel: Channel=9, Row=587, Col=996\n",
      "\n",
      "g_change: 0.00000000, steps: 175, Flip Pixel: Channel=8, Row=559, Col=859\n",
      "rgb_change: 0.00000000, steps: 175, Flip Pixel: Channel=8, Row=559, Col=859\n",
      "\n",
      "b_change: -0.00000763, steps: 176, Flip Pixel: Channel=17, Row=974, Col=831\n",
      "rgb_change: -0.00000763, steps: 176, Flip Pixel: Channel=17, Row=974, Col=831\n",
      "\n",
      "b_change: -0.00000954, steps: 177, Flip Pixel: Channel=22, Row=106, Col=540\n",
      "rgb_change: -0.00000954, steps: 177, Flip Pixel: Channel=22, Row=106, Col=540\n",
      "\n",
      "b_change: -0.00001144, steps: 178, Flip Pixel: Channel=22, Row=269, Col=478\n",
      "rgb_change: -0.00001144, steps: 178, Flip Pixel: Channel=22, Row=269, Col=478\n",
      "\n",
      "g_change: -0.00001144, steps: 179, Flip Pixel: Channel=12, Row=728, Col=599\n",
      "rgb_change: 0.00000000, steps: 179, Flip Pixel: Channel=12, Row=728, Col=599\n",
      "\n",
      "g_change: 0.00000000, steps: 180, Flip Pixel: Channel=12, Row=711, Col=627\n",
      "rgb_change: 0.00000000, steps: 180, Flip Pixel: Channel=12, Row=711, Col=627\n",
      "\n",
      "g_change: -0.00001526, steps: 181, Flip Pixel: Channel=10, Row=74, Col=972\n",
      "rgb_change: -0.00001526, steps: 181, Flip Pixel: Channel=10, Row=74, Col=972\n",
      "\n",
      "b_change: -0.00002289, steps: 182, Flip Pixel: Channel=23, Row=86, Col=739\n",
      "rgb_change: -0.00001144, steps: 182, Flip Pixel: Channel=23, Row=86, Col=739\n",
      "\n",
      "r_change: -0.00001526, steps: 183, Flip Pixel: Channel=0, Row=580, Col=39\n",
      "rgb_change: -0.00000763, steps: 183, Flip Pixel: Channel=0, Row=580, Col=39\n",
      "\n",
      "g_change: -0.00000763, steps: 184, Flip Pixel: Channel=12, Row=424, Col=680\n",
      "rgb_change: -0.00000191, steps: 184, Flip Pixel: Channel=12, Row=424, Col=680\n",
      "\n",
      "b_change: -0.00000381, steps: 185, Flip Pixel: Channel=19, Row=429, Col=139\n",
      "rgb_change: -0.00000381, steps: 185, Flip Pixel: Channel=19, Row=429, Col=139\n",
      "\n",
      "b_change: 0.00000000, steps: 186, Flip Pixel: Channel=19, Row=550, Col=688\n",
      "rgb_change: 0.00000000, steps: 186, Flip Pixel: Channel=19, Row=550, Col=688\n",
      "\n",
      "r_change: -0.00001144, steps: 187, Flip Pixel: Channel=3, Row=912, Col=57\n",
      "rgb_change: -0.00001144, steps: 187, Flip Pixel: Channel=3, Row=912, Col=57\n",
      "\n",
      "r_change: 0.00000000, steps: 188, Flip Pixel: Channel=0, Row=57, Col=854\n",
      "rgb_change: 0.00000000, steps: 188, Flip Pixel: Channel=0, Row=57, Col=854\n",
      "\n",
      "g_change: 0.00000000, steps: 189, Flip Pixel: Channel=14, Row=976, Col=945\n",
      "rgb_change: -0.00000191, steps: 189, Flip Pixel: Channel=14, Row=976, Col=945\n",
      "\n",
      "b_change: -0.00000381, steps: 190, Flip Pixel: Channel=23, Row=57, Col=666\n",
      "rgb_change: -0.00000381, steps: 190, Flip Pixel: Channel=23, Row=57, Col=666\n",
      "\n",
      "r_change: 0.00000000, steps: 191, Flip Pixel: Channel=5, Row=594, Col=747\n",
      "rgb_change: 0.00000000, steps: 191, Flip Pixel: Channel=5, Row=594, Col=747\n",
      "\n",
      "b_change: -0.00001717, steps: 192, Flip Pixel: Channel=18, Row=67, Col=444\n",
      "rgb_change: -0.00001907, steps: 192, Flip Pixel: Channel=18, Row=67, Col=444\n",
      "\n",
      "b_change: -0.00000381, steps: 193, Flip Pixel: Channel=21, Row=125, Col=550\n",
      "rgb_change: -0.00000381, steps: 193, Flip Pixel: Channel=21, Row=125, Col=550\n",
      "\n",
      "r_change: -0.00000191, steps: 194, Flip Pixel: Channel=1, Row=215, Col=837\n",
      "rgb_change: 0.00000000, steps: 194, Flip Pixel: Channel=1, Row=215, Col=837\n",
      "\n",
      "r_change: 0.00000000, steps: 195, Flip Pixel: Channel=0, Row=356, Col=400\n",
      "rgb_change: 0.00000000, steps: 195, Flip Pixel: Channel=0, Row=356, Col=400\n",
      "\n",
      "g_change: 0.00000763, steps: 196, Flip Pixel: Channel=14, Row=874, Col=868\n",
      "rgb_change: 0.00000763, steps: 196, Flip Pixel: Channel=14, Row=874, Col=868\n",
      "\n",
      "b_change: 0.00000000, steps: 197, Flip Pixel: Channel=22, Row=170, Col=797\n",
      "rgb_change: 0.00000000, steps: 197, Flip Pixel: Channel=22, Row=170, Col=797\n",
      "\n",
      "b_change: -0.00001526, steps: 198, Flip Pixel: Channel=18, Row=60, Col=611\n",
      "rgb_change: -0.00001526, steps: 198, Flip Pixel: Channel=18, Row=60, Col=611\n",
      "\n",
      "g_change: -0.00001144, steps: 199, Flip Pixel: Channel=8, Row=332, Col=47\n",
      "rgb_change: 0.00000191, steps: 199, Flip Pixel: Channel=8, Row=332, Col=47\n",
      "\n",
      "r_change: -0.00001144, steps: 200, Flip Pixel: Channel=2, Row=70, Col=256\n",
      "rgb_change: -0.00001144, steps: 200, Flip Pixel: Channel=2, Row=70, Col=256\n",
      "\n",
      "g_change: -0.00002098, steps: 201, Flip Pixel: Channel=13, Row=560, Col=880\n",
      "rgb_change: -0.00000954, steps: 201, Flip Pixel: Channel=13, Row=560, Col=880\n",
      "\n",
      "r_change: -0.00001144, steps: 202, Flip Pixel: Channel=7, Row=848, Col=262\n",
      "rgb_change: -0.00000572, steps: 202, Flip Pixel: Channel=7, Row=848, Col=262\n",
      "\n",
      "r_change: 0.00000191, steps: 203, Flip Pixel: Channel=7, Row=99, Col=646\n",
      "rgb_change: 0.00000191, steps: 203, Flip Pixel: Channel=7, Row=99, Col=646\n",
      "\n",
      "b_change: 0.00000000, steps: 204, Flip Pixel: Channel=20, Row=758, Col=703\n",
      "rgb_change: 0.00000000, steps: 204, Flip Pixel: Channel=20, Row=758, Col=703\n",
      "\n",
      "r_change: -0.00001144, steps: 205, Flip Pixel: Channel=4, Row=500, Col=417\n",
      "rgb_change: -0.00001144, steps: 205, Flip Pixel: Channel=4, Row=500, Col=417\n",
      "\n",
      "r_change: 0.00000000, steps: 206, Flip Pixel: Channel=7, Row=480, Col=629\n",
      "rgb_change: 0.00000000, steps: 206, Flip Pixel: Channel=7, Row=480, Col=629\n",
      "\n",
      "g_change: -0.00000191, steps: 207, Flip Pixel: Channel=8, Row=226, Col=421\n",
      "rgb_change: -0.00000191, steps: 207, Flip Pixel: Channel=8, Row=226, Col=421\n",
      "\n",
      "b_change: -0.00000763, steps: 208, Flip Pixel: Channel=16, Row=724, Col=612\n",
      "rgb_change: -0.00000381, steps: 208, Flip Pixel: Channel=16, Row=724, Col=612\n",
      "\n",
      "b_change: -0.00000954, steps: 209, Flip Pixel: Channel=22, Row=480, Col=419\n",
      "rgb_change: -0.00000954, steps: 209, Flip Pixel: Channel=22, Row=480, Col=419\n",
      "\n",
      "r_change: -0.00001144, steps: 210, Flip Pixel: Channel=2, Row=134, Col=251\n",
      "rgb_change: 0.00000000, steps: 210, Flip Pixel: Channel=2, Row=134, Col=251\n",
      "\n",
      "r_change: 0.00000572, steps: 211, Flip Pixel: Channel=0, Row=767, Col=98\n",
      "rgb_change: 0.00000572, steps: 211, Flip Pixel: Channel=0, Row=767, Col=98\n",
      "\n",
      "r_change: 0.00000000, steps: 212, Flip Pixel: Channel=1, Row=692, Col=226\n",
      "rgb_change: 0.00000000, steps: 212, Flip Pixel: Channel=1, Row=692, Col=226\n",
      "\n",
      "r_change: -0.00001717, steps: 213, Flip Pixel: Channel=7, Row=932, Col=393\n",
      "rgb_change: -0.00001717, steps: 213, Flip Pixel: Channel=7, Row=932, Col=393\n",
      "\n",
      "g_change: -0.00002098, steps: 214, Flip Pixel: Channel=14, Row=77, Col=2\n",
      "rgb_change: -0.00000572, steps: 214, Flip Pixel: Channel=14, Row=77, Col=2\n",
      "\n",
      "r_change: -0.00000763, steps: 215, Flip Pixel: Channel=0, Row=768, Col=778\n",
      "rgb_change: 0.00000000, steps: 215, Flip Pixel: Channel=0, Row=768, Col=778\n",
      "\n",
      "b_change: 0.00000000, steps: 216, Flip Pixel: Channel=22, Row=427, Col=590\n",
      "rgb_change: 0.00000000, steps: 216, Flip Pixel: Channel=22, Row=427, Col=590\n",
      "\n",
      "r_change: 0.00000191, steps: 217, Flip Pixel: Channel=0, Row=675, Col=409\n",
      "rgb_change: 0.00000000, steps: 217, Flip Pixel: Channel=0, Row=675, Col=409\n",
      "\n",
      "r_change: 0.00000000, steps: 218, Flip Pixel: Channel=0, Row=940, Col=1001\n",
      "rgb_change: 0.00000000, steps: 218, Flip Pixel: Channel=0, Row=940, Col=1001\n",
      "\n",
      "g_change: -0.00000572, steps: 219, Flip Pixel: Channel=13, Row=357, Col=864\n",
      "rgb_change: 0.00000000, steps: 219, Flip Pixel: Channel=13, Row=357, Col=864\n",
      "\n",
      "g_change: 0.00000000, steps: 220, Flip Pixel: Channel=15, Row=314, Col=897\n",
      "rgb_change: 0.00000000, steps: 220, Flip Pixel: Channel=15, Row=314, Col=897\n",
      "\n",
      "r_change: -0.00000954, steps: 221, Flip Pixel: Channel=3, Row=842, Col=389\n",
      "rgb_change: -0.00001335, steps: 221, Flip Pixel: Channel=3, Row=842, Col=389\n",
      "\n",
      "b_change: -0.00001717, steps: 222, Flip Pixel: Channel=22, Row=729, Col=285\n",
      "rgb_change: -0.00000763, steps: 222, Flip Pixel: Channel=22, Row=729, Col=285\n",
      "\n",
      "r_change: -0.00001717, steps: 223, Flip Pixel: Channel=4, Row=75, Col=360\n",
      "rgb_change: -0.00001335, steps: 223, Flip Pixel: Channel=4, Row=75, Col=360\n",
      "\n",
      "r_change: 0.00000000, steps: 224, Flip Pixel: Channel=0, Row=731, Col=799\n",
      "rgb_change: 0.00000000, steps: 224, Flip Pixel: Channel=0, Row=731, Col=799\n",
      "\n",
      "b_change: 0.00000000, steps: 225, Flip Pixel: Channel=21, Row=119, Col=986\n",
      "rgb_change: 0.00000000, steps: 225, Flip Pixel: Channel=21, Row=119, Col=986\n",
      "\n",
      "r_change: -0.00000763, steps: 226, Flip Pixel: Channel=4, Row=234, Col=731\n",
      "rgb_change: -0.00000763, steps: 226, Flip Pixel: Channel=4, Row=234, Col=731\n",
      "\n",
      "r_change: -0.00001526, steps: 227, Flip Pixel: Channel=3, Row=401, Col=391\n",
      "rgb_change: -0.00001526, steps: 227, Flip Pixel: Channel=3, Row=401, Col=391\n",
      "\n",
      "g_change: -0.00001717, steps: 228, Flip Pixel: Channel=15, Row=1008, Col=222\n",
      "rgb_change: 0.00000000, steps: 228, Flip Pixel: Channel=15, Row=1008, Col=222\n",
      "\n",
      "g_change: -0.00001335, steps: 229, Flip Pixel: Channel=14, Row=82, Col=428\n",
      "rgb_change: -0.00001335, steps: 229, Flip Pixel: Channel=14, Row=82, Col=428\n",
      "\n",
      "r_change: -0.00001717, steps: 230, Flip Pixel: Channel=3, Row=108, Col=75\n",
      "rgb_change: -0.00000572, steps: 230, Flip Pixel: Channel=3, Row=108, Col=75\n",
      "\n",
      "b_change: -0.00001717, steps: 231, Flip Pixel: Channel=18, Row=833, Col=695\n",
      "rgb_change: -0.00001335, steps: 231, Flip Pixel: Channel=18, Row=833, Col=695\n",
      "\n",
      "r_change: -0.00001717, steps: 232, Flip Pixel: Channel=4, Row=341, Col=194\n",
      "rgb_change: -0.00000572, steps: 232, Flip Pixel: Channel=4, Row=341, Col=194\n",
      "\n",
      "r_change: -0.00000763, steps: 233, Flip Pixel: Channel=6, Row=98, Col=846\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "from utils.logger import setup_logger\n",
    "\n",
    "# 로거 설정\n",
    "log_file = setup_logger()\n",
    "\n",
    "# 테스트 출력\n",
    "print(\"이 메시지는 콘솔과 파일에 동시에 기록됩니다.\")\n",
    "logging.info(\"이 메시지도 로그에 기록됩니다.\")\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import BaseCallback, CallbackList\n",
    "\n",
    "import torchOptics.optics as tt\n",
    "import torchOptics.metrics as tm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from env_1024_24 import BinaryHologramEnv\n",
    "\n",
    "IPS = 1024  #이미지 픽셀 사이즈\n",
    "CH = 24  #채널\n",
    "RW = 800  #보상\n",
    "\n",
    "class BinaryNet(nn.Module):\n",
    "    def __init__(self, num_hologram, final='Sigmoid', in_planes=3,\n",
    "                 channels=[32, 64, 128, 256, 512, 1024, 2048, 4096],\n",
    "                 convReLU=True, convBN=True, poolReLU=True, poolBN=True,\n",
    "                 deconvReLU=True, deconvBN=True):\n",
    "        super(BinaryNet, self).__init__()\n",
    "\n",
    "        def CRB2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True, relu=True, bn=True):\n",
    "            layers = []\n",
    "            layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                 kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                                 bias=bias)]\n",
    "            if relu:\n",
    "                layers += [nn.Tanh()]\n",
    "            if bn:\n",
    "                layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "\n",
    "            cbr = nn.Sequential(*layers)  # *으로 list unpacking\n",
    "\n",
    "            return cbr\n",
    "\n",
    "        def TRB2d(in_channels, out_channels, kernel_size=2, stride=2, bias=True, relu=True, bn=True):\n",
    "            layers = []\n",
    "            layers += [nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                          kernel_size=2, stride=2, padding=0,\n",
    "                                          bias=True)]\n",
    "            if bn:\n",
    "                layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "            if relu:\n",
    "                layers += [nn.ReLU()]\n",
    "\n",
    "            cbr = nn.Sequential(*layers)  # *으로 list unpacking\n",
    "\n",
    "            return cbr\n",
    "\n",
    "        self.enc1_1 = CRB2d(in_planes, channels[0], relu=convReLU, bn=convBN)\n",
    "        self.enc1_2 = CRB2d(channels[0], channels[0], relu=convReLU, bn=convBN)\n",
    "        self.pool1 = CRB2d(channels[0], channels[0], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc2_1 = CRB2d(channels[0], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.enc2_2 = CRB2d(channels[1], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.pool2 = CRB2d(channels[1], channels[1], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc3_1 = CRB2d(channels[1], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.enc3_2 = CRB2d(channels[2], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.pool3 = CRB2d(channels[2], channels[2], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc4_1 = CRB2d(channels[2], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.enc4_2 = CRB2d(channels[3], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.pool4 = CRB2d(channels[3], channels[3], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc5_1 = CRB2d(channels[3], channels[4], relu=convReLU, bn=convBN)\n",
    "        self.enc5_2 = CRB2d(channels[4], channels[4], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv4 = TRB2d(channels[4], channels[3], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec4_1 = CRB2d(channels[4], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.dec4_2 = CRB2d(channels[3], channels[3], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv3 = TRB2d(channels[3], channels[2], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec3_1 = CRB2d(channels[3], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.dec3_2 = CRB2d(channels[2], channels[2], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv2 = TRB2d(channels[2], channels[1], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec2_1 = CRB2d(channels[2], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.dec2_2 = CRB2d(channels[1], channels[1], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv1 = TRB2d(channels[1], channels[0], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec1_1 = CRB2d(channels[1], channels[0], relu=convReLU, bn=convBN)\n",
    "        self.dec1_2 = CRB2d(channels[0], channels[0], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.classifier = CRB2d(channels[0], num_hologram, relu=False, bn=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1_1 = self.enc1_1(x)\n",
    "        enc1_2 = self.enc1_2(enc1_1)\n",
    "        pool1 = self.pool1(enc1_2)\n",
    "\n",
    "        enc2_1 = self.enc2_1(pool1)\n",
    "        enc2_2 = self.enc2_2(enc2_1)\n",
    "        pool2 = self.pool2(enc2_2)\n",
    "\n",
    "        enc3_1 = self.enc3_1(pool2)\n",
    "        enc3_2 = self.enc3_2(enc3_1)\n",
    "        pool3 = self.pool3(enc3_2)\n",
    "\n",
    "        enc4_1 = self.enc4_1(pool3)\n",
    "        enc4_2 = self.enc4_2(enc4_1)\n",
    "        pool4 = self.pool4(enc4_2)\n",
    "\n",
    "        enc5_1 = self.enc5_1(pool4)\n",
    "        enc5_2 = self.enc5_2(enc5_1)\n",
    "\n",
    "        deconv4 = self.deconv4(enc5_2)\n",
    "        concat4 = torch.cat((deconv4, enc4_2), dim=1)\n",
    "        dec4_1 = self.dec4_1(concat4)\n",
    "        dec4_2 = self.dec4_2(dec4_1)\n",
    "\n",
    "        deconv3 = self.deconv3(dec4_2)\n",
    "        concat3 = torch.cat((deconv3, enc3_2), dim=1)\n",
    "        dec3_1 = self.dec3_1(concat3)\n",
    "        dec3_2 = self.dec3_2(dec3_1)\n",
    "\n",
    "        deconv2 = self.deconv2(dec3_2)\n",
    "        concat2 = torch.cat((deconv2, enc2_2), dim=1)\n",
    "        dec2_1 = self.dec2_1(concat2)\n",
    "        dec2_2 = self.dec2_2(dec2_1)\n",
    "\n",
    "        deconv1 = self.deconv1(dec2_2)\n",
    "        concat1 = torch.cat((deconv1, enc1_2), dim=1)\n",
    "        dec1_1 = self.dec1_1(concat1)\n",
    "        dec1_2 = self.dec1_2(dec1_1)\n",
    "\n",
    "        # Final classifier\n",
    "        out = self.classifier(dec1_2)\n",
    "        out = nn.Sigmoid()(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = BinaryNet(num_hologram=CH, in_planes=3, convReLU=False,\n",
    "                  convBN=False, poolReLU=False, poolBN=False,\n",
    "                  deconvReLU=False, deconvBN=False).cuda()\n",
    "test = torch.randn(1, 3, IPS, IPS).cuda()\n",
    "out = model(test)\n",
    "print(out.shape)\n",
    "\n",
    "class Dataset512(Dataset):\n",
    "    def __init__(self, target_dir, meta, transform=None, isTrain=True, padding=0):\n",
    "        self.target_dir = target_dir\n",
    "        self.transform = transform\n",
    "        self.meta = meta\n",
    "        self.isTrain = isTrain\n",
    "        self.target_list = sorted(glob.glob(target_dir+'*.png'))\n",
    "        self.center_crop = torchvision.transforms.CenterCrop(IPS)\n",
    "        self.random_crop = torchvision.transforms.RandomCrop((IPS, IPS))\n",
    "        self.padding = padding\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        target = tt.imread(self.target_list[idx], meta=self.meta)\n",
    "        if target.shape[-1] < IPS or target.shape[-2] < IPS:\n",
    "            target = torchvision.transforms.Resize(IPS)(target)\n",
    "        if self.isTrain:\n",
    "            target = self.random_crop(target)\n",
    "            target = torchvision.transforms.functional.pad(target, (self.padding, self.padding, self.padding, self.padding))\n",
    "        else:\n",
    "            target = self.center_crop(target)\n",
    "            target = torchvision.transforms.functional.pad(target, (self.padding, self.padding, self.padding, self.padding))\n",
    "        # 데이터와 파일 경로를 함께 반환\n",
    "        return target, self.target_list[idx]\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def optimize_with_random_pixel_flips(env, z=2e-3, pixel_pitch=7.56e-6):\n",
    "    db_num = 800\n",
    "    max_datasets = 800  # 최대 데이터셋 처리 개수\n",
    "    output_bins = np.linspace(0, 1.0, 11)  # pre-model output 값의 범위 설정\n",
    "    bin_counts = defaultdict(int)  # 각 범위에 해당하는 전체 픽셀 수\n",
    "    improved_bin_counts = defaultdict(int)  # PSNR이 개선된 픽셀 수\n",
    "    psnr_improvements = defaultdict(list)  # 각 범위에서 PSNR 개선량 저장\n",
    "\n",
    "    while db_num <= max_datasets:\n",
    "        try:\n",
    "            obs, info = env.reset()\n",
    "            db_num += 1\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during reset: {e}\")\n",
    "            break\n",
    "\n",
    "        total_start_time = time.time()\n",
    "\n",
    "        current_state = obs[\"state\"]\n",
    "        target_image = obs[\"target_image\"]\n",
    "        target_image_cuda = torch.tensor(target_image, dtype=torch.float32).cuda()\n",
    "        initial_psnr = env.initial_psnr  # 초기 PSNR\n",
    "        previous_psnr = initial_psnr\n",
    "        steps = 0\n",
    "        flip_count = 0\n",
    "        psnr_after = 0\n",
    "\n",
    "        meta = {'wl': (638e-9, 515e-9, 450e-9), 'dx': (pixel_pitch, pixel_pitch)}\n",
    "        rmeta = {'wl': (638e-9), 'dx': (pixel_pitch, pixel_pitch)}\n",
    "        gmeta = {'wl': (515e-9), 'dx': (pixel_pitch, pixel_pitch)}\n",
    "        bmeta = {'wl': (450e-9), 'dx': (pixel_pitch, pixel_pitch)}\n",
    "\n",
    "        rgbchannel = current_state.shape[1]\n",
    "\n",
    "        rchannel = int(rgbchannel / 3)\n",
    "        gchannel = int(rgbchannel * 2 / 3)\n",
    "\n",
    "        red = current_state[:, :rchannel, :, :]\n",
    "        green = current_state[:, rchannel:gchannel, :, :]\n",
    "        blue = current_state[:, gchannel:, :, :]\n",
    "\n",
    "        red = tt.Tensor(red, meta=rmeta)\n",
    "        green = tt.Tensor(green, meta=gmeta)\n",
    "        blue = tt.Tensor(blue, meta=bmeta)\n",
    "\n",
    "        rsim = tt.simulate(red, z).abs() ** 2\n",
    "        gsim = tt.simulate(green, z).abs() ** 2\n",
    "        bsim = tt.simulate(blue, z).abs() ** 2\n",
    "\n",
    "        rmean = torch.mean(rsim, dim=1, keepdim=True)\n",
    "        gmean = torch.mean(gsim, dim=1, keepdim=True)\n",
    "        bmean = torch.mean(bsim, dim=1, keepdim=True)\n",
    "\n",
    "        rgb = torch.cat([rmean, gmean, bmean], dim=1)\n",
    "        rgb = tt.Tensor(rgb, meta=meta)\n",
    "\n",
    "        # Pre-model output 계산\n",
    "        pre_model_output = obs[\"pre_model\"].squeeze()  # 필요 시 차원 축소\n",
    "\n",
    "        # 초기화: 특정 범위 값의 픽셀 개수와 PSNR 개선량 저장\n",
    "        bin_counts = defaultdict(int)  # 각 범위에 해당하는 전체 픽셀 수\n",
    "        improved_bin_counts = defaultdict(int)  # PSNR이 개선된 픽셀 수\n",
    "        psnr_improvements = defaultdict(list)  # 각 범위에서 PSNR 개선량 저장\n",
    "\n",
    "        # 각 범위 값의 픽셀 개수 계산\n",
    "        for i in range(len(output_bins) - 1):\n",
    "            bin_counts[i] = np.logical_and(\n",
    "                pre_model_output >= output_bins[i],\n",
    "                pre_model_output < output_bins[i + 1]\n",
    "            ).sum()\n",
    "\n",
    "        # 다음 출력 기준 PSNR 값 리스트 설정\n",
    "        next_print_thresholds = [initial_psnr + i * 0.01 for i in range(1, 101)]  # 최대 10.0 상승까지 출력\n",
    "\n",
    "        print(f\"Starting pixel flip optimization for file {db_num}.png with initial PSNR: {initial_psnr:.6f}\")\n",
    "\n",
    "        # 픽셀 크기 정보 가져오기\n",
    "        num_channels, img_height, img_width = current_state.shape[1:]\n",
    "        all_pixels = np.arange(num_channels * img_height * img_width)\n",
    "        np.random.shuffle(all_pixels)  # 랜덤 순서로 픽셀 섞기\n",
    "\n",
    "        for attempt, pixel in enumerate(all_pixels):\n",
    "            channel = pixel // (img_height * img_width)\n",
    "            pixel_index = pixel % (img_height * img_width)\n",
    "            row = pixel_index // img_width\n",
    "            col = pixel_index % img_width\n",
    "\n",
    "            # 현재 상태의 픽셀 값을 플립\n",
    "            current_state[0, channel, row, col] = 1 - current_state[0, channel, row, col]\n",
    "            steps += 1\n",
    "\n",
    "            meta = {'wl': (638e-9, 515e-9, 450e-9), 'dx': (pixel_pitch, pixel_pitch)}\n",
    "            rmeta = {'wl': (638e-9), 'dx': (pixel_pitch, pixel_pitch)}\n",
    "            gmeta = {'wl': (515e-9), 'dx': (pixel_pitch, pixel_pitch)}\n",
    "            bmeta = {'wl': (450e-9), 'dx': (pixel_pitch, pixel_pitch)}\n",
    "\n",
    "            rgbchannel = current_state.shape[1]\n",
    "\n",
    "            rchannel = int(rgbchannel / 3)\n",
    "            gchannel = int(rgbchannel * 2 / 3)\n",
    "\n",
    "            # 조건에 따라 연산 수행\n",
    "            if channel < rchannel:\n",
    "                # Red 채널 범위일 때, rmean만 갱신\n",
    "                red = current_state[:, :rchannel, :, :]\n",
    "                red = tt.Tensor(red, meta=rmeta)\n",
    "                rsim = tt.simulate(red, z).abs() ** 2\n",
    "                rmean = torch.mean(rsim, dim=1, keepdim=True)\n",
    "                rgb = torch.cat([rmean, gmean, bmean], dim=1)\n",
    "                rgb = tt.Tensor(rgb, meta=meta)\n",
    "                psnr_after = tt.relativeLoss(rgb, target_image_cuda, tm.get_PSNR)  # 초기 PSNR 저장\n",
    "                psnr_change = psnr_after - previous_psnr\n",
    "                print(f\"r_change: {psnr_change:.8f}, steps: {steps}, Flip Pixel: Channel={channel}, Row={row}, Col={col}\")\n",
    "\n",
    "            elif rchannel <= channel < gchannel:\n",
    "                # Green 채널 범위일 때, gmean만 갱신\n",
    "                green = current_state[:, rchannel:gchannel, :, :]\n",
    "                green = tt.Tensor(green, meta=gmeta)\n",
    "                gsim = tt.simulate(green, z).abs() ** 2\n",
    "                gmean = torch.mean(gsim, dim=1, keepdim=True)\n",
    "                rgb = torch.cat([rmean, gmean, bmean], dim=1)\n",
    "                rgb = tt.Tensor(rgb, meta=meta)\n",
    "                psnr_after = tt.relativeLoss(rgb, target_image_cuda, tm.get_PSNR)  # 초기 PSNR 저장\n",
    "                psnr_change = psnr_after - previous_psnr\n",
    "                print(f\"g_change: {psnr_change:.8f}, steps: {steps}, Flip Pixel: Channel={channel}, Row={row}, Col={col}\")\n",
    "\n",
    "            elif gchannel <= channel:\n",
    "                # Blue 채널 범위일 때, bmean만 갱신\n",
    "                blue = current_state[:, gchannel:, :, :]\n",
    "                blue = tt.Tensor(blue, meta=bmeta)\n",
    "                bsim = tt.simulate(blue, z).abs() ** 2\n",
    "                bmean = torch.mean(bsim, dim=1, keepdim=True)\n",
    "                rgb = torch.cat([rmean, gmean, bmean], dim=1)\n",
    "                rgb = tt.Tensor(rgb, meta=meta)\n",
    "                psnr_after = tt.relativeLoss(rgb, target_image_cuda, tm.get_PSNR)  # 초기 PSNR 저장\n",
    "                psnr_change = psnr_after - previous_psnr\n",
    "                print(f\"b_change: {psnr_change:.8f}, steps: {steps}, Flip Pixel: Channel={channel}, Row={row}, Col={col}\")\n",
    "\n",
    "            red = current_state[:, :rchannel, :, :]\n",
    "            green = current_state[:, rchannel:gchannel, :, :]\n",
    "            blue = current_state[:, gchannel:, :, :]\n",
    "\n",
    "            red = tt.Tensor(red, meta=rmeta)\n",
    "            green = tt.Tensor(green, meta=gmeta)\n",
    "            blue = tt.Tensor(blue, meta=bmeta)\n",
    "\n",
    "            rsim = tt.simulate(red, z).abs() ** 2\n",
    "            gsim = tt.simulate(green, z).abs() ** 2\n",
    "            bsim = tt.simulate(blue, z).abs() ** 2\n",
    "\n",
    "            rmean = torch.mean(rsim, dim=1, keepdim=True)\n",
    "            gmean = torch.mean(gsim, dim=1, keepdim=True)\n",
    "            bmean = torch.mean(bsim, dim=1, keepdim=True)\n",
    "\n",
    "            # RGB 결합\n",
    "            rgb = torch.cat([rmean, gmean, bmean], dim=1)\n",
    "            rgb = tt.Tensor(rgb, meta=meta)\n",
    "\n",
    "            psnr_after = tt.relativeLoss(rgb, target_image_cuda, tm.get_PSNR)  # 초기 PSNR 저장\n",
    "\n",
    "            psnr_change = psnr_after - previous_psnr\n",
    "            print(f\"rgb_change: {psnr_change:.8f}, steps: {steps}, Flip Pixel: Channel={channel}, Row={row}, Col={col}\\n\")\n",
    "\n",
    "            # PSNR이 개선되었는지 확인\n",
    "            if psnr_after > previous_psnr:\n",
    "                flip_count += 1\n",
    "\n",
    "                # 현재 PSNR 값이 출력 기준을 충족했는지 확인\n",
    "                while next_print_thresholds and psnr_after >= next_print_thresholds[0]:\n",
    "                    threshold = next_print_thresholds.pop(0)\n",
    "                    psnr_change = psnr_after - previous_psnr\n",
    "                    psnr_diff = psnr_after - initial_psnr\n",
    "                    success_ratio = flip_count / steps\n",
    "                    data_processing_time = time.time() - total_start_time\n",
    "                    print(\n",
    "                        f\"Step: {steps}\"\n",
    "                        f\"\\nPSNR Before: {previous_psnr:.6f} | PSNR After: {psnr_after:.6f} | Change: {psnr_change:.6f} | Diff: {psnr_diff:.6f}\"\n",
    "                        f\"\\nSuccess Ratio: {success_ratio:.6f} | Flip Count: {flip_count}\"\n",
    "                        f\"\\nFlip Pixel: Channel={channel}, Row={row}, Col={col}\"\n",
    "                        f\"\\nTime taken for this data: {data_processing_time:.2f} seconds\"\n",
    "                    )\n",
    "                    total_improved_pixels = sum(improved_bin_counts.values())\n",
    "                    for i in range(len(output_bins) - 1):\n",
    "                        total_count = bin_counts[i]\n",
    "                        improved_count = improved_bin_counts[i]\n",
    "                        improved_ratio = improved_count / total_count if total_count > 0 else 0\n",
    "                        range_improved_ratio = improved_count / total_improved_pixels if total_improved_pixels > 0 else 0\n",
    "                        total_psnr_improvement = sum(psnr_improvements[i]) if improved_count > 0 else 0\n",
    "                        avg_psnr_improvement = total_psnr_improvement / improved_count if improved_count > 0 else 0\n",
    "\n",
    "                        print(f\"Range {output_bins[i]:.1f}-{output_bins[i + 1]:.1f}: \"\n",
    "                              f\"Total Pixels = {total_count}, Improved Pixels = {improved_count}, \"\n",
    "                              f\"Improvement Ratio (in range) = {improved_ratio:.6f}, \"\n",
    "                              f\"Improvement Ratio (to total improved) = {range_improved_ratio:.6f}, \"\n",
    "                              f\"Total PSNR Improvement = {total_psnr_improvement:.6f}, \"\n",
    "                              f\"Average PSNR Improvement = {avg_psnr_improvement:.8f}\")\n",
    "\n",
    "                    print(\"\\n\")\n",
    "\n",
    "                # 플립 성공 픽셀의 pre-model output 값 확인\n",
    "                pre_value = pre_model_output[channel, row, col]\n",
    "\n",
    "                # 범위에 따른 카운트 증가\n",
    "                for i in range(len(output_bins) - 1):\n",
    "                    if output_bins[i] <= pre_value < output_bins[i + 1]:\n",
    "                        bin_counts[i] += 1  # 해당 범위 픽셀 수 증가\n",
    "                        if psnr_after > previous_psnr:\n",
    "                            improved_bin_counts[i] += 1  # 개선된 픽셀 수 증가\n",
    "                            psnr_improvements[i].append(psnr_after - previous_psnr)  # PSNR 개선량 저장\n",
    "                        break\n",
    "\n",
    "                previous_psnr = psnr_after\n",
    "\n",
    "            else:\n",
    "                # PSNR이 개선되지 않았으면 플립 롤백\n",
    "                current_state[0, channel, row, col] = 1 - current_state[0, channel, row, col]\n",
    "\n",
    "        # 성공 비율 계산\n",
    "        success_ratio = flip_count / steps if steps > 0 else 0\n",
    "\n",
    "        # 최종 결과 출력\n",
    "        psnr_diff = psnr_after - initial_psnr\n",
    "        data_processing_time = time.time() - total_start_time\n",
    "        print(\n",
    "            f\"Step: {steps}\"\n",
    "            f\"\\nPSNR Before: {previous_psnr:.6f} | PSNR After: {psnr_after:.6f} | Change: {psnr_diff:.6f}\"\n",
    "            f\"\\nSuccess Ratio: {success_ratio:.6f} | Flip Count: {flip_count}\"\n",
    "            f\"\\nFlip Pixel: Channel={channel}, Row={row}, Col={col}\"\n",
    "            f\"\\nTime taken for this data: {data_processing_time:.2f} seconds\"\n",
    "        )\n",
    "        print(f\"{db_num}.png Optimization completed. Final PSNR improvement: {psnr_diff:.6f}\")\n",
    "        print(f\"Time taken for this data: {data_processing_time:.2f} seconds\\n\")\n",
    "        print(\"Pre-model output range statistics:\")\n",
    "\n",
    "        # Reconstructed RGB 이미지를 matplotlib에 맞게 정규화\n",
    "        rgb_np = rgb.cpu().numpy().squeeze().transpose(1, 2, 0)  # (H, W, C)로 변환\n",
    "        rgb_np = np.clip(rgb_np, 0, 1)  # 값이 [0, 1] 범위 내에 있도록 제한\n",
    "\n",
    "        target_np = target_image.cpu().numpy().squeeze().transpose(1, 2, 0) # (H, W, C)로 변환\n",
    "        if target_np.max() > 1.0:  # 만약 target 이미지 값이 [0, 255] 범위라면\n",
    "            target_np = np.clip(target_np / 255.0, 0, 1)  # [0, 1]로 정규화\n",
    "\n",
    "        # 이미지 출력 및 저장\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        # Reconstructed RGB 이미지 출력\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(rgb_np)  # Reconstructed RGB 이미지 출력\n",
    "        plt.title(\"Reconstructed RGB Image\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Target RGB 이미지 출력\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(target_np)  # Target RGB 이미지 출력\n",
    "        plt.title(\"Target RGB Image\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # 화면에 출력\n",
    "        plt.show()\n",
    "\n",
    "        # 이미지 저장\n",
    "        save_path = f\"output_images/episode_{db_num}_comparison.png\"\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)  # 저장 디렉토리 생성\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "        print(f\"이미지가 저장되었습니다: {save_path}\")\n",
    "\n",
    "        total_improved_pixels = sum(improved_bin_counts.values())\n",
    "        for i in range(len(output_bins) - 1):\n",
    "            total_count = bin_counts[i]\n",
    "            improved_count = improved_bin_counts[i]\n",
    "            improved_ratio = improved_count / total_count if total_count > 0 else 0\n",
    "            range_improved_ratio = improved_count / total_improved_pixels if total_improved_pixels > 0 else 0\n",
    "            total_psnr_improvement = sum(psnr_improvements[i]) if improved_count > 0 else 0\n",
    "            avg_psnr_improvement = total_psnr_improvement / improved_count if improved_count > 0 else 0\n",
    "\n",
    "            print(f\"Range {output_bins[i]:.1f}-{output_bins[i + 1]:.1f}: \"\n",
    "                  f\"Total Pixels = {total_count}, Improved Pixels = {improved_count}, \"\n",
    "                  f\"Improvement Ratio (in range) = {improved_ratio:.6f}, \"\n",
    "                  f\"Improvement Ratio (to total improved) = {range_improved_ratio:.6f}, \"\n",
    "                  f\"Total PSNR Improvement = {total_psnr_improvement:.6f}, \"\n",
    "                  f\"Average PSNR Improvement = {avg_psnr_improvement:.8f}\")\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "batch_size = 1\n",
    "#target_dir = 'dataset1/'\n",
    "target_dir = '/nfs/dataset/DIV2K/DIV2K_train_HR/DIV2K_train_HR/'\n",
    "valid_dir = '/nfs/dataset/DIV2K/DIV2K_valid_HR/DIV2K_valid_HR/'\n",
    "meta = {'wl' : (638e-9, 515e-9, 450e-9), 'dx':(7.56e-6, 7.56e-6)}\n",
    "padding = 0\n",
    "\n",
    "# Dataset512 클래스 사용\n",
    "train_dataset = Dataset512(target_dir=target_dir, meta=meta, isTrain=False, padding=padding) #센터크롭\n",
    "#train_dataset = Dataset512(target_dir=target_dir, meta=meta, isTrain=True, padding=padding) #랜덤크롭\n",
    "valid_dataset = Dataset512(target_dir=valid_dir, meta=meta, isTrain=False, padding=padding)\n",
    "\n",
    "# DataLoader 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "#train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# BinaryNet 모델 로드\n",
    "model = BinaryNet(num_hologram=CH, in_planes=3, convReLU=False, convBN=False,\n",
    "                  poolReLU=False, poolBN=False, deconvReLU=False, deconvBN=False).cuda()\n",
    "model.load_state_dict(torch.load('result_v/2024-10-17 14_27_01.569309_1018_proposed_7.56e-6_24_0.002'))\n",
    "model.eval()\n",
    "\n",
    "# 환경 생성에 새로운 데이터 로더 적용\n",
    "env = BinaryHologramEnv(\n",
    "    target_function=model,\n",
    "    trainloader=valid_loader,\n",
    ")\n",
    "\n",
    "optimize_with_random_pixel_flips(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e415ab67-0c5d-4737-8491-00d42b3b8375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f393a31-b04d-4f0c-b904-f40fa5428626",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
