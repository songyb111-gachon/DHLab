{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e3bb6ba70918dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T07:50:49.917672Z",
     "start_time": "2024-12-17T07:50:49.704223Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/kornia/feature/lightglue.py:30: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 128, 128])\n",
      "Using cuda device\n",
      "Initial MSE: 0.003386, Initial PSNR: 23.341049, 08:27:07\n",
      "Logging to ./ppo_with_mask/RecurrentPPO_35\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.003386, Initial PSNR: 23.341049, 2024-12-23 08:27:07.614790\n",
      "Step: 100, MSE: 0.003933, PSNR: 22.691204, PSNR Diff: -0.649845, Changes: 4, Reward: -4.55, 08:27:09\n",
      "Episode failed: PSNR Diff -1.002575 < -1 at step 165\n",
      "Initial MSE: 0.001719, Initial PSNR: 25.492575, 08:27:10\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.001719, Initial PSNR: 25.492575, 2024-12-23 08:27:10.675499\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 166      |\n",
      "|    ep_rew_mean     | -757     |\n",
      "| time/              |          |\n",
      "|    fps             | 47       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 256      |\n",
      "---------------------------------\n",
      "Step: 100, MSE: 0.001964, PSNR: 24.913910, PSNR Diff: -0.578665, Changes: 6, Reward: -4.05, 08:27:21\n",
      "Step: 200, MSE: 0.002164, PSNR: 24.494667, PSNR Diff: -0.997908, Changes: 6, Reward: -6.99, 08:27:23\n",
      "Episode failed: PSNR Diff -1.001318 < -1 at step 202\n",
      "Initial MSE: 0.010106, Initial PSNR: 19.954092, 08:27:23\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.010106, Initial PSNR: 19.954092, 2024-12-23 08:27:23.257170\n",
      "Step: 100, MSE: 0.010741, PSNR: 19.689688, PSNR Diff: -0.264404, Changes: 5, Reward: -1.85, 08:27:25\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 184          |\n",
      "|    ep_rew_mean          | -856         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 26           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 512          |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.601741e+29 |\n",
      "|    clip_fraction        | 0.902        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.09e+04    |\n",
      "|    explained_variance   | -0.0887      |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.27e+12     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | 1.65e+11     |\n",
      "|    value_loss           | 0.54         |\n",
      "------------------------------------------\n",
      "Step: 200, MSE: 0.011292, PSNR: 19.472275, PSNR Diff: -0.481817, Changes: 5, Reward: -3.37, 08:27:35\n",
      "Step: 300, MSE: 0.011861, PSNR: 19.258657, PSNR Diff: -0.695435, Changes: 4, Reward: -4.87, 08:27:37\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 184          |\n",
      "|    ep_rew_mean          | -856         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 23           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 32           |\n",
      "|    total_timesteps      | 768          |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.238995e+20 |\n",
      "|    clip_fraction        | 0.89         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.09e+04    |\n",
      "|    explained_variance   | -8.08        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 9.66e+07     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | 5.11e+18     |\n",
      "|    value_loss           | 0.13         |\n",
      "------------------------------------------\n",
      "Step: 400, MSE: 0.012368, PSNR: 19.077164, PSNR Diff: -0.876928, Changes: 3, Reward: -6.14, 08:27:48\n",
      "Episode failed: PSNR Diff -1.008329 < -1 at step 479\n",
      "Initial MSE: 0.003618, Initial PSNR: 22.811487, 08:27:50\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.003618, Initial PSNR: 22.811487, 2024-12-23 08:27:50.162284\n",
      "Step: 100, MSE: 0.004153, PSNR: 22.212179, PSNR Diff: -0.599308, Changes: 5, Reward: -4.20, 08:27:52\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 283           |\n",
      "|    ep_rew_mean          | -1.23e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 22            |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 46            |\n",
      "|    total_timesteps      | 1024          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9079227e+21 |\n",
      "|    clip_fraction        | 0.892         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | 0.756         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 7.52e+04      |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | 4.1e+19       |\n",
      "|    value_loss           | 0.0882        |\n",
      "-------------------------------------------\n",
      "Episode failed: PSNR Diff -1.005690 < -1 at step 183\n",
      "Initial MSE: 0.007825, Initial PSNR: 20.502323, 08:28:02\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.007825, Initial PSNR: 20.502323, 2024-12-23 08:28:02.822944\n",
      "Step: 100, MSE: 0.008504, PSNR: 20.141117, PSNR Diff: -0.361206, Changes: 3, Reward: -2.53, 08:28:04\n",
      "Step: 200, MSE: 0.009012, PSNR: 19.889122, PSNR Diff: -0.613201, Changes: 5, Reward: -4.29, 08:28:06\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 258          |\n",
      "|    ep_rew_mean          | -1.13e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 60           |\n",
      "|    total_timesteps      | 1280         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.237154e+21 |\n",
      "|    clip_fraction        | 0.883        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.09e+04    |\n",
      "|    explained_variance   | 0.875        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 4.69e+06     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | 6.58e+17     |\n",
      "|    value_loss           | 0.14         |\n",
      "------------------------------------------\n",
      "Step: 300, MSE: 0.009469, PSNR: 19.674314, PSNR Diff: -0.828009, Changes: 2, Reward: -5.80, 08:28:17\n",
      "Episode failed: PSNR Diff -1.002665 < -1 at step 369\n",
      "Initial MSE: 0.003328, Initial PSNR: 23.728935, 08:28:18\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.003328, Initial PSNR: 23.728935, 2024-12-23 08:28:18.601805\n",
      "Step: 100, MSE: 0.004184, PSNR: 22.735394, PSNR Diff: -0.993542, Changes: 3, Reward: -6.95, 08:28:20\n",
      "Episode failed: PSNR Diff -1.006725 < -1 at step 101\n",
      "Initial MSE: 0.003165, Initial PSNR: 24.962727, 08:28:20\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.003165, Initial PSNR: 24.962727, 2024-12-23 08:28:20.464913\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 251          |\n",
      "|    ep_rew_mean          | -1.11e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 20           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 73           |\n",
      "|    total_timesteps      | 1536         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.644337e+21 |\n",
      "|    clip_fraction        | 0.88         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.09e+04    |\n",
      "|    explained_variance   | -0.397       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 65           |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | 4.11e+19     |\n",
      "|    value_loss           | 0.057        |\n",
      "------------------------------------------\n",
      "Step: 100, MSE: 0.003432, PSNR: 24.610813, PSNR Diff: -0.351913, Changes: 4, Reward: -2.46, 08:28:30\n",
      "Step: 200, MSE: 0.003703, PSNR: 24.280748, PSNR Diff: -0.681978, Changes: 6, Reward: -4.77, 08:28:31\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 251           |\n",
      "|    ep_rew_mean          | -1.11e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 20            |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 86            |\n",
      "|    total_timesteps      | 1792          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.3392606e+27 |\n",
      "|    clip_fraction        | 0.89          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | -5.76         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | -0.162        |\n",
      "|    n_updates            | 60            |\n",
      "|    policy_gradient_loss | 6.74e+14      |\n",
      "|    value_loss           | 0.147         |\n",
      "-------------------------------------------\n",
      "Episode failed: PSNR Diff -1.000860 < -1 at step 298\n",
      "Initial MSE: 0.001805, Initial PSNR: 21.846907, 08:28:42\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.001805, Initial PSNR: 21.846907, 2024-12-23 08:28:42.174820\n",
      "Step: 100, MSE: 0.001881, PSNR: 21.666695, PSNR Diff: -0.180212, Changes: 2, Reward: -1.26, 08:28:43\n",
      "Step: 200, MSE: 0.001973, PSNR: 21.459805, PSNR Diff: -0.387102, Changes: 5, Reward: -2.71, 08:28:45\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 258           |\n",
      "|    ep_rew_mean          | -1.13e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 20            |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 99            |\n",
      "|    total_timesteps      | 2048          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1313354e+19 |\n",
      "|    clip_fraction        | 0.889         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | -0.0507       |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 5.72e+07      |\n",
      "|    n_updates            | 70            |\n",
      "|    policy_gradient_loss | 3.05e+15      |\n",
      "|    value_loss           | 0.044         |\n",
      "-------------------------------------------\n",
      "Step: 300, MSE: 0.002061, PSNR: 21.271233, PSNR Diff: -0.575674, Changes: 4, Reward: -4.03, 08:28:56\n",
      "Step: 400, MSE: 0.002144, PSNR: 21.099716, PSNR Diff: -0.747190, Changes: 6, Reward: -5.23, 08:28:57\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 258            |\n",
      "|    ep_rew_mean          | -1.13e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 20             |\n",
      "|    iterations           | 9              |\n",
      "|    time_elapsed         | 112            |\n",
      "|    total_timesteps      | 2304           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 505296800000.0 |\n",
      "|    clip_fraction        | 0.89           |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -9.09e+04      |\n",
      "|    explained_variance   | 0.804          |\n",
      "|    learning_rate        | 1e-05          |\n",
      "|    loss                 | -0.0912        |\n",
      "|    n_updates            | 80             |\n",
      "|    policy_gradient_loss | 4.44e+09       |\n",
      "|    value_loss           | 0.0481         |\n",
      "--------------------------------------------\n",
      "Step: 500, MSE: 0.002248, PSNR: 20.893196, PSNR Diff: -0.953711, Changes: 4, Reward: -6.68, 08:29:08\n",
      "Episode failed: PSNR Diff -1.000675 < -1 at step 533\n",
      "Initial MSE: 0.002903, Initial PSNR: 24.089256, 08:29:08\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002903, Initial PSNR: 24.089256, 2024-12-23 08:29:08.948437\n",
      "Step: 100, MSE: 0.003107, PSNR: 23.793625, PSNR Diff: -0.295631, Changes: 3, Reward: -2.07, 08:29:10\n",
      "Step: 200, MSE: 0.003299, PSNR: 23.533871, PSNR Diff: -0.555386, Changes: 4, Reward: -3.89, 08:29:12\n",
      "---------------------------------------------\n",
      "| rollout/                |                 |\n",
      "|    ep_len_mean          | 292             |\n",
      "|    ep_rew_mean          | -1.24e+03       |\n",
      "| time/                   |                 |\n",
      "|    fps                  | 20              |\n",
      "|    iterations           | 10              |\n",
      "|    time_elapsed         | 125             |\n",
      "|    total_timesteps      | 2560            |\n",
      "| train/                  |                 |\n",
      "|    approx_kl            | 6582186000000.0 |\n",
      "|    clip_fraction        | 0.889           |\n",
      "|    clip_range           | 0.2             |\n",
      "|    entropy_loss         | -9.09e+04       |\n",
      "|    explained_variance   | 0.597           |\n",
      "|    learning_rate        | 1e-05           |\n",
      "|    loss                 | 0.128           |\n",
      "|    n_updates            | 90              |\n",
      "|    policy_gradient_loss | 1.38e+05        |\n",
      "|    value_loss           | 0.0406          |\n",
      "---------------------------------------------\n",
      "Step: 300, MSE: 0.003513, PSNR: 23.260805, PSNR Diff: -0.828451, Changes: 4, Reward: -5.80, 08:29:22\n",
      "Episode failed: PSNR Diff -1.001858 < -1 at step 379\n",
      "Initial MSE: 0.000619, Initial PSNR: 24.210548, 08:29:24\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.000619, Initial PSNR: 24.210548, 2024-12-23 08:29:24.307597\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 302          |\n",
      "|    ep_rew_mean          | -1.28e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 20           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 138          |\n",
      "|    total_timesteps      | 2816         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.815667e+23 |\n",
      "|    clip_fraction        | 0.893        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.09e+04    |\n",
      "|    explained_variance   | -0.56        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | -0.131       |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | 2.21e+22     |\n",
      "|    value_loss           | 0.0335       |\n",
      "------------------------------------------\n",
      "Step: 100, MSE: 0.000701, PSNR: 23.666924, PSNR Diff: -0.543625, Changes: 5, Reward: -3.81, 08:29:34\n",
      "Step: 200, MSE: 0.000773, PSNR: 23.242813, PSNR Diff: -0.967735, Changes: 4, Reward: -6.77, 08:29:36\n",
      "Episode failed: PSNR Diff -1.000559 < -1 at step 208\n",
      "Initial MSE: 0.004747, Initial PSNR: 22.745523, 08:29:36\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.004747, Initial PSNR: 22.745523, 2024-12-23 08:29:36.366211\n",
      "Step: 100, MSE: 0.005764, PSNR: 21.902420, PSNR Diff: -0.843103, Changes: 8, Reward: -5.90, 08:29:38\n",
      "Episode failed: PSNR Diff -1.000444 < -1 at step 128\n",
      "Initial MSE: 0.005655, Initial PSNR: 22.475874, 08:29:38\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.005655, Initial PSNR: 22.475874, 2024-12-23 08:29:38.779277\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 278           |\n",
      "|    ep_rew_mean          | -1.19e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 20            |\n",
      "|    iterations           | 12            |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 3072          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.4906877e+26 |\n",
      "|    clip_fraction        | 0.889         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | -0.381        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | -0.0332       |\n",
      "|    n_updates            | 110           |\n",
      "|    policy_gradient_loss | 4.75e+18      |\n",
      "|    value_loss           | 0.0535        |\n",
      "-------------------------------------------\n",
      "Step: 100, MSE: 0.006361, PSNR: 21.964779, PSNR Diff: -0.511095, Changes: 6, Reward: -3.58, 08:29:48\n",
      "Step: 200, MSE: 0.006933, PSNR: 21.590786, PSNR Diff: -0.885088, Changes: 4, Reward: -6.20, 08:29:50\n",
      "Episode failed: PSNR Diff -1.003849 < -1 at step 238\n",
      "Initial MSE: 0.002417, Initial PSNR: 24.228298, 08:29:51\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002417, Initial PSNR: 24.228298, 2024-12-23 08:29:51.783366\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 275           |\n",
      "|    ep_rew_mean          | -1.18e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 20            |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 165           |\n",
      "|    total_timesteps      | 3328          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.2390115e+20 |\n",
      "|    clip_fraction        | 0.889         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | 0.789         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 441           |\n",
      "|    n_updates            | 120           |\n",
      "|    policy_gradient_loss | 9.72e+15      |\n",
      "|    value_loss           | 0.0875        |\n",
      "-------------------------------------------\n",
      "Step: 100, MSE: 0.002679, PSNR: 23.782173, PSNR Diff: -0.446125, Changes: 6, Reward: -3.12, 08:30:02\n",
      "Step: 200, MSE: 0.002948, PSNR: 23.366150, PSNR Diff: -0.862148, Changes: 6, Reward: -6.04, 08:30:03\n",
      "Episode failed: PSNR Diff -1.004410 < -1 at step 235\n",
      "Initial MSE: 0.002905, Initial PSNR: 25.265793, 08:30:04\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002905, Initial PSNR: 25.265793, 2024-12-23 08:30:04.391129\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 272           |\n",
      "|    ep_rew_mean          | -1.17e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 20            |\n",
      "|    iterations           | 14            |\n",
      "|    time_elapsed         | 178           |\n",
      "|    total_timesteps      | 3584          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 76406810000.0 |\n",
      "|    clip_fraction        | 0.886         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | -0.0135       |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 41            |\n",
      "|    n_updates            | 130           |\n",
      "|    policy_gradient_loss | 2.66e+13      |\n",
      "|    value_loss           | 0.059         |\n",
      "-------------------------------------------\n",
      "Step: 100, MSE: 0.003084, PSNR: 25.006466, PSNR Diff: -0.259327, Changes: 4, Reward: -1.82, 08:30:14\n",
      "Step: 200, MSE: 0.003297, PSNR: 24.716259, PSNR Diff: -0.549534, Changes: 4, Reward: -3.85, 08:30:16\n",
      "Step: 300, MSE: 0.003508, PSNR: 24.447050, PSNR Diff: -0.818743, Changes: 5, Reward: -5.73, 08:30:18\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 272           |\n",
      "|    ep_rew_mean          | -1.17e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 20            |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 191           |\n",
      "|    total_timesteps      | 3840          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3529001e+16 |\n",
      "|    clip_fraction        | 0.891         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | -0.474        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 0.76          |\n",
      "|    n_updates            | 140           |\n",
      "|    policy_gradient_loss | 2.92e+14      |\n",
      "|    value_loss           | 0.0647        |\n",
      "-------------------------------------------\n",
      "Episode failed: PSNR Diff -1.002554 < -1 at step 393\n",
      "Initial MSE: 0.000875, Initial PSNR: 21.038300, 08:30:28\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.000875, Initial PSNR: 21.038300, 2024-12-23 08:30:28.992404\n",
      "Step: 100, MSE: 0.000986, PSNR: 20.520882, PSNR Diff: -0.517418, Changes: 5, Reward: -3.62, 08:30:30\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 280        |\n",
      "|    ep_rew_mean          | -1.2e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 19         |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 204        |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 13436763.0 |\n",
      "|    clip_fraction        | 0.885      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -9.09e+04  |\n",
      "|    explained_variance   | 0.774      |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | -0.171     |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | 9.31e+13   |\n",
      "|    value_loss           | 0.0449     |\n",
      "----------------------------------------\n",
      "Step: 200, MSE: 0.001096, PSNR: 20.059925, PSNR Diff: -0.978374, Changes: 3, Reward: -6.85, 08:30:40\n",
      "Episode failed: PSNR Diff -1.000477 < -1 at step 204\n",
      "Initial MSE: 0.004311, Initial PSNR: 23.271210, 08:30:40\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.004311, Initial PSNR: 23.271210, 2024-12-23 08:30:40.944604\n",
      "Step: 100, MSE: 0.004619, PSNR: 22.971685, PSNR Diff: -0.299524, Changes: 6, Reward: -2.10, 08:30:42\n",
      "Step: 200, MSE: 0.004948, PSNR: 22.673088, PSNR Diff: -0.598122, Changes: 4, Reward: -4.19, 08:30:44\n",
      "---------------------------------------------\n",
      "| rollout/                |                 |\n",
      "|    ep_len_mean          | 275             |\n",
      "|    ep_rew_mean          | -1.18e+03       |\n",
      "| time/                   |                 |\n",
      "|    fps                  | 19              |\n",
      "|    iterations           | 17              |\n",
      "|    time_elapsed         | 218             |\n",
      "|    total_timesteps      | 4352            |\n",
      "| train/                  |                 |\n",
      "|    approx_kl            | 8608642000000.0 |\n",
      "|    clip_fraction        | 0.889           |\n",
      "|    clip_range           | 0.2             |\n",
      "|    entropy_loss         | -9.09e+04       |\n",
      "|    explained_variance   | 0.712           |\n",
      "|    learning_rate        | 1e-05           |\n",
      "|    loss                 | -0.0286         |\n",
      "|    n_updates            | 160             |\n",
      "|    policy_gradient_loss | 1.22e+10        |\n",
      "|    value_loss           | 0.0504          |\n",
      "---------------------------------------------\n",
      "Step: 300, MSE: 0.005288, PSNR: 22.384140, PSNR Diff: -0.887070, Changes: 5, Reward: -6.21, 08:30:55\n",
      "Episode failed: PSNR Diff -1.003408 < -1 at step 334\n",
      "Initial MSE: 0.002927, Initial PSNR: 23.731396, 08:30:56\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002927, Initial PSNR: 23.731396, 2024-12-23 08:30:56.340863\n",
      "Step: 100, MSE: 0.003633, PSNR: 22.793238, PSNR Diff: -0.938158, Changes: 3, Reward: -6.57, 08:30:58\n",
      "Episode failed: PSNR Diff -1.004887 < -1 at step 111\n",
      "Initial MSE: 0.006528, Initial PSNR: 21.852150, 08:30:58\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.006528, Initial PSNR: 21.852150, 2024-12-23 08:30:58.571307\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 269           |\n",
      "|    ep_rew_mean          | -1.15e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 232           |\n",
      "|    total_timesteps      | 4608          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7940685e+23 |\n",
      "|    clip_fraction        | 0.891         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | 0.855         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | -0.141        |\n",
      "|    n_updates            | 170           |\n",
      "|    policy_gradient_loss | 1.32e+22      |\n",
      "|    value_loss           | 0.0441        |\n",
      "-------------------------------------------\n",
      "Step: 100, MSE: 0.006982, PSNR: 21.560448, PSNR Diff: -0.291702, Changes: 7, Reward: -2.04, 08:31:08\n",
      "Step: 200, MSE: 0.007476, PSNR: 21.263096, PSNR Diff: -0.589054, Changes: 7, Reward: -4.12, 08:31:10\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 269       |\n",
      "|    ep_rew_mean          | -1.15e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 19        |\n",
      "|    iterations           | 19        |\n",
      "|    time_elapsed         | 244       |\n",
      "|    total_timesteps      | 4864      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 34902.633 |\n",
      "|    clip_fraction        | 0.889     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -9.09e+04 |\n",
      "|    explained_variance   | 0.56      |\n",
      "|    learning_rate        | 1e-05     |\n",
      "|    loss                 | -0.184    |\n",
      "|    n_updates            | 180       |\n",
      "|    policy_gradient_loss | 1.1e+10   |\n",
      "|    value_loss           | 0.107     |\n",
      "---------------------------------------\n",
      "Step: 300, MSE: 0.007946, PSNR: 20.998524, PSNR Diff: -0.853626, Changes: 6, Reward: -5.98, 08:31:20\n",
      "Episode failed: PSNR Diff -1.005724 < -1 at step 363\n",
      "Initial MSE: 0.001989, Initial PSNR: 26.267349, 08:31:22\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.001989, Initial PSNR: 26.267349, 2024-12-23 08:31:22.209617\n",
      "Step: 100, MSE: 0.002208, PSNR: 25.814255, PSNR Diff: -0.453094, Changes: 5, Reward: -3.17, 08:31:24\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 274          |\n",
      "|    ep_rew_mean          | -1.17e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 258          |\n",
      "|    total_timesteps      | 5120         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2147052700.0 |\n",
      "|    clip_fraction        | 0.888        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.09e+04    |\n",
      "|    explained_variance   | -0.293       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.0333       |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | 2.03e+11     |\n",
      "|    value_loss           | 0.0729       |\n",
      "------------------------------------------\n",
      "Step: 200, MSE: 0.002446, PSNR: 25.368290, PSNR Diff: -0.899059, Changes: 4, Reward: -6.29, 08:31:34\n",
      "Episode failed: PSNR Diff -1.007320 < -1 at step 226\n",
      "Initial MSE: 0.001251, Initial PSNR: 26.192444, 08:31:34\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.001251, Initial PSNR: 26.192444, 2024-12-23 08:31:34.943270\n",
      "Step: 100, MSE: 0.001331, PSNR: 25.922758, PSNR Diff: -0.269686, Changes: 4, Reward: -1.89, 08:31:36\n",
      "Step: 200, MSE: 0.001426, PSNR: 25.623648, PSNR Diff: -0.568796, Changes: 5, Reward: -3.98, 08:31:38\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 272          |\n",
      "|    ep_rew_mean          | -1.16e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 271          |\n",
      "|    total_timesteps      | 5376         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.683551e+24 |\n",
      "|    clip_fraction        | 0.895        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.09e+04    |\n",
      "|    explained_variance   | -0.508       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.86e+13     |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | 4.21e+14     |\n",
      "|    value_loss           | 0.0974       |\n",
      "------------------------------------------\n",
      "Step: 300, MSE: 0.001516, PSNR: 25.357311, PSNR Diff: -0.835133, Changes: 6, Reward: -5.85, 08:31:48\n",
      "Episode failed: PSNR Diff -1.002544 < -1 at step 357\n",
      "Initial MSE: 0.005357, Initial PSNR: 22.292507, 08:31:49\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.005357, Initial PSNR: 22.292507, 2024-12-23 08:31:49.436886\n",
      "Step: 100, MSE: 0.005996, PSNR: 21.802891, PSNR Diff: -0.489616, Changes: 6, Reward: -3.43, 08:31:51\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 276       |\n",
      "|    ep_rew_mean          | -1.17e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 19        |\n",
      "|    iterations           | 22        |\n",
      "|    time_elapsed         | 284       |\n",
      "|    total_timesteps      | 5632      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 46126.824 |\n",
      "|    clip_fraction        | 0.885     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -9.09e+04 |\n",
      "|    explained_variance   | -1.72     |\n",
      "|    learning_rate        | 1e-05     |\n",
      "|    loss                 | -0.175    |\n",
      "|    n_updates            | 210       |\n",
      "|    policy_gradient_loss | 1.38e+06  |\n",
      "|    value_loss           | 0.0542    |\n",
      "---------------------------------------\n",
      "Step: 200, MSE: 0.006557, PSNR: 21.414049, PSNR Diff: -0.878458, Changes: 3, Reward: -6.15, 08:32:01\n",
      "Episode failed: PSNR Diff -1.001844 < -1 at step 230\n",
      "Initial MSE: 0.000818, Initial PSNR: 27.501745, 08:32:01\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.000818, Initial PSNR: 27.501745, 2024-12-23 08:32:01.994458\n",
      "Step: 100, MSE: 0.000925, PSNR: 26.971020, PSNR Diff: -0.530725, Changes: 5, Reward: -3.72, 08:32:03\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 274           |\n",
      "|    ep_rew_mean          | -1.16e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 296           |\n",
      "|    total_timesteps      | 5888          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.5141264e+21 |\n",
      "|    clip_fraction        | 0.887         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | 0.542         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 4.86e+14      |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | 4.71e+13      |\n",
      "|    value_loss           | 0.0837        |\n",
      "-------------------------------------------\n",
      "Episode failed: PSNR Diff -1.001863 < -1 at step 193\n",
      "Initial MSE: 0.021908, Initial PSNR: 16.593969, 08:32:13\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.021908, Initial PSNR: 16.593969, 2024-12-23 08:32:13.491102\n",
      "Step: 100, MSE: 0.022194, PSNR: 16.537588, PSNR Diff: -0.056381, Changes: 4, Reward: -0.39, 08:32:15\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 270         |\n",
      "|    ep_rew_mean          | -1.15e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 309         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.21007e+23 |\n",
      "|    clip_fraction        | 0.888       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.09e+04   |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.135       |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | 8.73e+18    |\n",
      "|    value_loss           | 0.0579      |\n",
      "-----------------------------------------\n",
      "Step: 200, MSE: 0.022459, PSNR: 16.486071, PSNR Diff: -0.107899, Changes: 4, Reward: -0.76, 08:32:25\n",
      "Step: 300, MSE: 0.022797, PSNR: 16.421179, PSNR Diff: -0.172791, Changes: 7, Reward: -1.21, 08:32:27\n",
      "Step: 400, MSE: 0.023121, PSNR: 16.359846, PSNR Diff: -0.234123, Changes: 8, Reward: -1.64, 08:32:29\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 270          |\n",
      "|    ep_rew_mean          | -1.15e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 323          |\n",
      "|    total_timesteps      | 6400         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.982524e+20 |\n",
      "|    clip_fraction        | 0.896        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.09e+04    |\n",
      "|    explained_variance   | 0.903        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.19e+03     |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | 5.77e+13     |\n",
      "|    value_loss           | 0.023        |\n",
      "------------------------------------------\n",
      "Step: 500, MSE: 0.023469, PSNR: 16.295097, PSNR Diff: -0.298872, Changes: 3, Reward: -2.09, 08:32:40\n",
      "Step: 600, MSE: 0.023837, PSNR: 16.227440, PSNR Diff: -0.366529, Changes: 3, Reward: -2.57, 08:32:42\n",
      "Step: 700, MSE: 0.024105, PSNR: 16.178909, PSNR Diff: -0.415060, Changes: 4, Reward: -2.91, 08:32:44\n",
      "----------------------------------------------\n",
      "| rollout/                |                  |\n",
      "|    ep_len_mean          | 270              |\n",
      "|    ep_rew_mean          | -1.15e+03        |\n",
      "| time/                   |                  |\n",
      "|    fps                  | 19               |\n",
      "|    iterations           | 26               |\n",
      "|    time_elapsed         | 337              |\n",
      "|    total_timesteps      | 6656             |\n",
      "| train/                  |                  |\n",
      "|    approx_kl            | 43707085000000.0 |\n",
      "|    clip_fraction        | 0.89             |\n",
      "|    clip_range           | 0.2              |\n",
      "|    entropy_loss         | -9.09e+04        |\n",
      "|    explained_variance   | 0.146            |\n",
      "|    learning_rate        | 1e-05            |\n",
      "|    loss                 | 2.39e+14         |\n",
      "|    n_updates            | 250              |\n",
      "|    policy_gradient_loss | 1.03e+13         |\n",
      "|    value_loss           | 0.0125           |\n",
      "----------------------------------------------\n",
      "Step: 800, MSE: 0.024454, PSNR: 16.116524, PSNR Diff: -0.477446, Changes: 7, Reward: -3.34, 08:32:55\n",
      "Step: 900, MSE: 0.024736, PSNR: 16.066784, PSNR Diff: -0.527185, Changes: 4, Reward: -3.69, 08:32:57\n",
      "-----------------------------------------------\n",
      "| rollout/                |                   |\n",
      "|    ep_len_mean          | 270               |\n",
      "|    ep_rew_mean          | -1.15e+03         |\n",
      "| time/                   |                   |\n",
      "|    fps                  | 19                |\n",
      "|    iterations           | 27                |\n",
      "|    time_elapsed         | 351               |\n",
      "|    total_timesteps      | 6912              |\n",
      "| train/                  |                   |\n",
      "|    approx_kl            | 258978320000000.0 |\n",
      "|    clip_fraction        | 0.894             |\n",
      "|    clip_range           | 0.2               |\n",
      "|    entropy_loss         | -9.09e+04         |\n",
      "|    explained_variance   | 0.198             |\n",
      "|    learning_rate        | 1e-05             |\n",
      "|    loss                 | 3.66e+13          |\n",
      "|    n_updates            | 260               |\n",
      "|    policy_gradient_loss | 9.16e+11          |\n",
      "|    value_loss           | 0.0151            |\n",
      "-----------------------------------------------\n",
      "Step: 1000, MSE: 0.025021, PSNR: 16.016977, PSNR Diff: -0.576992, Changes: 7, Reward: -4.04, 08:33:07\n",
      "Initial MSE: 0.007454, Initial PSNR: 21.276396, 08:33:07\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.007454, Initial PSNR: 21.276396, 2024-12-23 08:33:07.880815\n",
      "Step: 100, MSE: 0.008272, PSNR: 20.823704, PSNR Diff: -0.452692, Changes: 4, Reward: -3.17, 08:33:09\n",
      "Step: 200, MSE: 0.009096, PSNR: 20.411430, PSNR Diff: -0.864965, Changes: 6, Reward: -6.05, 08:33:11\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 302           |\n",
      "|    ep_rew_mean          | -1.19e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 28            |\n",
      "|    time_elapsed         | 364           |\n",
      "|    total_timesteps      | 7168          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.6442815e+16 |\n",
      "|    clip_fraction        | 0.888         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | 0.683         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 0.0522        |\n",
      "|    n_updates            | 270           |\n",
      "|    policy_gradient_loss | 4.71e+09      |\n",
      "|    value_loss           | 0.032         |\n",
      "-------------------------------------------\n",
      "Episode failed: PSNR Diff -1.004215 < -1 at step 238\n",
      "Initial MSE: 0.008695, Initial PSNR: 20.607145, 08:33:20\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.008695, Initial PSNR: 20.607145, 2024-12-23 08:33:20.493970\n",
      "Step: 100, MSE: 0.009081, PSNR: 20.418520, PSNR Diff: -0.188625, Changes: 3, Reward: -1.32, 08:33:21\n",
      "Step: 200, MSE: 0.009466, PSNR: 20.238537, PSNR Diff: -0.368608, Changes: 8, Reward: -2.58, 08:33:23\n",
      "----------------------------------------------\n",
      "| rollout/                |                  |\n",
      "|    ep_len_mean          | 300              |\n",
      "|    ep_rew_mean          | -1.19e+03        |\n",
      "| time/                   |                  |\n",
      "|    fps                  | 19               |\n",
      "|    iterations           | 29               |\n",
      "|    time_elapsed         | 377              |\n",
      "|    total_timesteps      | 7424             |\n",
      "| train/                  |                  |\n",
      "|    approx_kl            | 72102630000000.0 |\n",
      "|    clip_fraction        | 0.887            |\n",
      "|    clip_range           | 0.2              |\n",
      "|    entropy_loss         | -9.09e+04        |\n",
      "|    explained_variance   | 0.0958           |\n",
      "|    learning_rate        | 1e-05            |\n",
      "|    loss                 | 7.07e+08         |\n",
      "|    n_updates            | 280              |\n",
      "|    policy_gradient_loss | 1e+12            |\n",
      "|    value_loss           | 0.0609           |\n",
      "----------------------------------------------\n",
      "Step: 300, MSE: 0.009827, PSNR: 20.075674, PSNR Diff: -0.531471, Changes: 5, Reward: -3.72, 08:33:34\n",
      "Step: 400, MSE: 0.010209, PSNR: 19.910191, PSNR Diff: -0.696955, Changes: 5, Reward: -4.88, 08:33:35\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 300           |\n",
      "|    ep_rew_mean          | -1.19e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 30            |\n",
      "|    time_elapsed         | 390           |\n",
      "|    total_timesteps      | 7680          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5613657e+29 |\n",
      "|    clip_fraction        | 0.892         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | 0.856         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | -0.163        |\n",
      "|    n_updates            | 290           |\n",
      "|    policy_gradient_loss | 6.53e+21      |\n",
      "|    value_loss           | 0.0365        |\n",
      "-------------------------------------------\n",
      "Step: 500, MSE: 0.010574, PSNR: 19.757637, PSNR Diff: -0.849508, Changes: 7, Reward: -5.95, 08:33:46\n",
      "Episode failed: PSNR Diff -1.001223 < -1 at step 593\n",
      "Initial MSE: 0.001656, Initial PSNR: 25.299110, 08:33:48\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.001656, Initial PSNR: 25.299110, 2024-12-23 08:33:48.518896\n",
      "Step: 100, MSE: 0.001936, PSNR: 24.621414, PSNR Diff: -0.677696, Changes: 4, Reward: -4.74, 08:33:50\n",
      "---------------------------------------------\n",
      "| rollout/                |                 |\n",
      "|    ep_len_mean          | 311             |\n",
      "|    ep_rew_mean          | -1.23e+03       |\n",
      "| time/                   |                 |\n",
      "|    fps                  | 19              |\n",
      "|    iterations           | 31              |\n",
      "|    time_elapsed         | 403             |\n",
      "|    total_timesteps      | 7936            |\n",
      "| train/                  |                 |\n",
      "|    approx_kl            | 1830662200000.0 |\n",
      "|    clip_fraction        | 0.897           |\n",
      "|    clip_range           | 0.2             |\n",
      "|    entropy_loss         | -9.09e+04       |\n",
      "|    explained_variance   | -0.539          |\n",
      "|    learning_rate        | 1e-05           |\n",
      "|    loss                 | 0.0342          |\n",
      "|    n_updates            | 300             |\n",
      "|    policy_gradient_loss | 1.07e+11        |\n",
      "|    value_loss           | 0.0762          |\n",
      "---------------------------------------------\n",
      "Episode failed: PSNR Diff -1.001768 < -1 at step 153\n",
      "Initial MSE: 0.002213, Initial PSNR: 24.611717, 08:33:59\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002213, Initial PSNR: 24.611717, 2024-12-23 08:33:59.873003\n",
      "Step: 100, MSE: 0.002479, PSNR: 24.119019, PSNR Diff: -0.492699, Changes: 6, Reward: -3.45, 08:34:01\n",
      "Step: 200, MSE: 0.002722, PSNR: 23.712988, PSNR Diff: -0.898729, Changes: 4, Reward: -6.29, 08:34:03\n",
      "Episode failed: PSNR Diff -1.000847 < -1 at step 222\n",
      "Initial MSE: 0.000924, Initial PSNR: 25.736652, 08:34:03\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.000924, Initial PSNR: 25.736652, 2024-12-23 08:34:03.696953\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 302           |\n",
      "|    ep_rew_mean          | -1.2e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 32            |\n",
      "|    time_elapsed         | 417           |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 40459776000.0 |\n",
      "|    clip_fraction        | 0.881         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | -2.28         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1e+05         |\n",
      "|    n_updates            | 310           |\n",
      "|    policy_gradient_loss | 3.78e+09      |\n",
      "|    value_loss           | 0.166         |\n",
      "-------------------------------------------\n",
      "Step: 100, MSE: 0.001053, PSNR: 25.167492, PSNR Diff: -0.569160, Changes: 7, Reward: -3.98, 08:34:13\n",
      "Episode failed: PSNR Diff -1.003601 < -1 at step 195\n",
      "Initial MSE: 0.001907, Initial PSNR: 26.261848, 08:34:15\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.001907, Initial PSNR: 26.261848, 2024-12-23 08:34:15.275338\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 298           |\n",
      "|    ep_rew_mean          | -1.19e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 33            |\n",
      "|    time_elapsed         | 429           |\n",
      "|    total_timesteps      | 8448          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1096381e+16 |\n",
      "|    clip_fraction        | 0.886         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | -1.37         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | -0.117        |\n",
      "|    n_updates            | 320           |\n",
      "|    policy_gradient_loss | 1.03e+05      |\n",
      "|    value_loss           | 0.0846        |\n",
      "-------------------------------------------\n",
      "Step: 100, MSE: 0.002113, PSNR: 25.816652, PSNR Diff: -0.445196, Changes: 2, Reward: -3.12, 08:34:25\n",
      "Step: 200, MSE: 0.002265, PSNR: 25.515228, PSNR Diff: -0.746620, Changes: 7, Reward: -5.23, 08:34:27\n",
      "Episode failed: PSNR Diff -1.005733 < -1 at step 274\n",
      "Initial MSE: 0.000361, Initial PSNR: 20.938511, 08:34:28\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.000361, Initial PSNR: 20.938511, 2024-12-23 08:34:28.432243\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 298          |\n",
      "|    ep_rew_mean          | -1.19e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 442          |\n",
      "|    total_timesteps      | 8704         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.180276e+19 |\n",
      "|    clip_fraction        | 0.888        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.09e+04    |\n",
      "|    explained_variance   | 0.941        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 4.41e+04     |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | 1.18e+18     |\n",
      "|    value_loss           | 0.0294       |\n",
      "------------------------------------------\n",
      "Step: 100, MSE: 0.000380, PSNR: 20.721687, PSNR Diff: -0.216824, Changes: 4, Reward: -1.52, 08:34:37\n",
      "Step: 200, MSE: 0.000395, PSNR: 20.545626, PSNR Diff: -0.392885, Changes: 5, Reward: -2.75, 08:34:39\n",
      "Step: 300, MSE: 0.000415, PSNR: 20.339413, PSNR Diff: -0.599098, Changes: 4, Reward: -4.19, 08:34:40\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 298          |\n",
      "|    ep_rew_mean          | -1.19e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 454          |\n",
      "|    total_timesteps      | 8960         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.725062e+19 |\n",
      "|    clip_fraction        | 0.897        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.09e+04    |\n",
      "|    explained_variance   | -1.8         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | -0.182       |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | 8.64e+12     |\n",
      "|    value_loss           | 0.0584       |\n",
      "------------------------------------------\n",
      "Step: 400, MSE: 0.000431, PSNR: 20.170900, PSNR Diff: -0.767611, Changes: 5, Reward: -5.37, 08:34:51\n",
      "Step: 500, MSE: 0.000451, PSNR: 19.976559, PSNR Diff: -0.961952, Changes: 4, Reward: -6.73, 08:34:52\n",
      "Episode failed: PSNR Diff -1.003035 < -1 at step 520\n",
      "Initial MSE: 0.002033, Initial PSNR: 23.497700, 08:34:52\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002033, Initial PSNR: 23.497700, 2024-12-23 08:34:52.895386\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 305        |\n",
      "|    ep_rew_mean          | -1.22e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 19         |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 466        |\n",
      "|    total_timesteps      | 9216       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 97676380.0 |\n",
      "|    clip_fraction        | 0.881      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -9.09e+04  |\n",
      "|    explained_variance   | -0.0555    |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 0.188      |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | 3.45e+07   |\n",
      "|    value_loss           | 0.0229     |\n",
      "----------------------------------------\n",
      "Step: 100, MSE: 0.002527, PSNR: 22.553394, PSNR Diff: -0.944305, Changes: 5, Reward: -6.61, 08:35:03\n",
      "Episode failed: PSNR Diff -1.002604 < -1 at step 108\n",
      "Initial MSE: 0.003940, Initial PSNR: 22.840748, 08:35:03\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.003940, Initial PSNR: 22.840748, 2024-12-23 08:35:03.390725\n",
      "Step: 100, MSE: 0.004198, PSNR: 22.565685, PSNR Diff: -0.275063, Changes: 6, Reward: -1.93, 08:35:05\n",
      "Step: 200, MSE: 0.004464, PSNR: 22.299217, PSNR Diff: -0.541531, Changes: 6, Reward: -3.79, 08:35:06\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 299           |\n",
      "|    ep_rew_mean          | -1.2e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 37            |\n",
      "|    time_elapsed         | 479           |\n",
      "|    total_timesteps      | 9472          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 21319705000.0 |\n",
      "|    clip_fraction        | 0.892         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | -0.707        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | -0.0362       |\n",
      "|    n_updates            | 360           |\n",
      "|    policy_gradient_loss | 1.63e+10      |\n",
      "|    value_loss           | 0.0648        |\n",
      "-------------------------------------------\n",
      "Step: 300, MSE: 0.004713, PSNR: 22.063265, PSNR Diff: -0.777483, Changes: 7, Reward: -5.44, 08:35:16\n",
      "Episode failed: PSNR Diff -1.004757 < -1 at step 389\n",
      "Initial MSE: 0.003568, Initial PSNR: 24.057175, 08:35:18\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.003568, Initial PSNR: 24.057175, 2024-12-23 08:35:18.342580\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 302           |\n",
      "|    ep_rew_mean          | -1.21e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 38            |\n",
      "|    time_elapsed         | 492           |\n",
      "|    total_timesteps      | 9728          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1753579e+24 |\n",
      "|    clip_fraction        | 0.895         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | 0.674         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.08          |\n",
      "|    n_updates            | 370           |\n",
      "|    policy_gradient_loss | 1.03e+21      |\n",
      "|    value_loss           | 0.0635        |\n",
      "-------------------------------------------\n",
      "Step: 100, MSE: 0.004012, PSNR: 23.548107, PSNR Diff: -0.509068, Changes: 4, Reward: -3.56, 08:35:28\n",
      "Episode failed: PSNR Diff -1.002651 < -1 at step 198\n",
      "Initial MSE: 0.002383, Initial PSNR: 23.899052, 08:35:29\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002383, Initial PSNR: 23.899052, 2024-12-23 08:35:29.891951\n",
      "Step: 100, MSE: 0.002873, PSNR: 23.086100, PSNR Diff: -0.812952, Changes: 1, Reward: -5.69, 08:35:31\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 299            |\n",
      "|    ep_rew_mean          | -1.2e+03       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 19             |\n",
      "|    iterations           | 39             |\n",
      "|    time_elapsed         | 505            |\n",
      "|    total_timesteps      | 9984           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 440786600000.0 |\n",
      "|    clip_fraction        | 0.892          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -9.09e+04      |\n",
      "|    explained_variance   | -2.15          |\n",
      "|    learning_rate        | 1e-05          |\n",
      "|    loss                 | 1.1e+12        |\n",
      "|    n_updates            | 380            |\n",
      "|    policy_gradient_loss | 6.2e+12        |\n",
      "|    value_loss           | 0.0548         |\n",
      "--------------------------------------------\n",
      "Episode failed: PSNR Diff -1.011185 < -1 at step 137\n",
      "Initial MSE: 0.002688, Initial PSNR: 23.767742, 08:35:40\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002688, Initial PSNR: 23.767742, 2024-12-23 08:35:40.836696\n",
      "Step: 100, MSE: 0.002916, PSNR: 23.413736, PSNR Diff: -0.354006, Changes: 4, Reward: -2.48, 08:35:42\n",
      "Step: 200, MSE: 0.003153, PSNR: 23.074188, PSNR Diff: -0.693554, Changes: 5, Reward: -4.85, 08:35:44\n",
      "----------------------------------------------\n",
      "| rollout/                |                  |\n",
      "|    ep_len_mean          | 294              |\n",
      "|    ep_rew_mean          | -1.18e+03        |\n",
      "| time/                   |                  |\n",
      "|    fps                  | 19               |\n",
      "|    iterations           | 40               |\n",
      "|    time_elapsed         | 518              |\n",
      "|    total_timesteps      | 10240            |\n",
      "| train/                  |                  |\n",
      "|    approx_kl            | 55256575000000.0 |\n",
      "|    clip_fraction        | 0.893            |\n",
      "|    clip_range           | 0.2              |\n",
      "|    entropy_loss         | -9.09e+04        |\n",
      "|    explained_variance   | -0.108           |\n",
      "|    learning_rate        | 1e-05            |\n",
      "|    loss                 | -0.131           |\n",
      "|    n_updates            | 390              |\n",
      "|    policy_gradient_loss | 2.8e+08          |\n",
      "|    value_loss           | 0.0801           |\n",
      "----------------------------------------------\n",
      "Step: 300, MSE: 0.003373, PSNR: 22.781088, PSNR Diff: -0.986654, Changes: 7, Reward: -6.91, 08:35:55\n",
      "Episode failed: PSNR Diff -1.002258 < -1 at step 309\n",
      "Initial MSE: 0.007028, Initial PSNR: 21.531406, 08:35:55\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.007028, Initial PSNR: 21.531406, 2024-12-23 08:35:55.801030\n",
      "Step: 100, MSE: 0.008038, PSNR: 20.948471, PSNR Diff: -0.582935, Changes: 4, Reward: -4.08, 08:35:57\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 294           |\n",
      "|    ep_rew_mean          | -1.19e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 41            |\n",
      "|    time_elapsed         | 532           |\n",
      "|    total_timesteps      | 10496         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.1472675e+20 |\n",
      "|    clip_fraction        | 0.891         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | -1.09         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | -0.00183      |\n",
      "|    n_updates            | 400           |\n",
      "|    policy_gradient_loss | 1.23e+18      |\n",
      "|    value_loss           | 0.0461        |\n",
      "-------------------------------------------\n",
      "Step: 200, MSE: 0.008845, PSNR: 20.532806, PSNR Diff: -0.998600, Changes: 7, Reward: -6.99, 08:36:08\n",
      "Episode failed: PSNR Diff -1.008154 < -1 at step 201\n",
      "Initial MSE: 0.002951, Initial PSNR: 20.691441, 08:36:08\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002951, Initial PSNR: 20.691441, 2024-12-23 08:36:08.262701\n",
      "Step: 100, MSE: 0.003157, PSNR: 20.398781, PSNR Diff: -0.292660, Changes: 5, Reward: -2.05, 08:36:10\n",
      "Step: 200, MSE: 0.003377, PSNR: 20.105156, PSNR Diff: -0.586285, Changes: 8, Reward: -4.10, 08:36:11\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 292            |\n",
      "|    ep_rew_mean          | -1.18e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 19             |\n",
      "|    iterations           | 42             |\n",
      "|    time_elapsed         | 545            |\n",
      "|    total_timesteps      | 10752          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 860776900000.0 |\n",
      "|    clip_fraction        | 0.891          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -9.09e+04      |\n",
      "|    explained_variance   | 0.643          |\n",
      "|    learning_rate        | 1e-05          |\n",
      "|    loss                 | 0.015          |\n",
      "|    n_updates            | 410            |\n",
      "|    policy_gradient_loss | 1.01e+10       |\n",
      "|    value_loss           | 0.0904         |\n",
      "--------------------------------------------\n",
      "Step: 300, MSE: 0.003613, PSNR: 19.811878, PSNR Diff: -0.879562, Changes: 3, Reward: -6.16, 08:36:22\n",
      "Episode failed: PSNR Diff -1.004763 < -1 at step 343\n",
      "Initial MSE: 0.004380, Initial PSNR: 23.447611, 08:36:22\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.004380, Initial PSNR: 23.447611, 2024-12-23 08:36:22.840744\n",
      "Step: 100, MSE: 0.005179, PSNR: 22.720530, PSNR Diff: -0.727081, Changes: 7, Reward: -5.09, 08:36:24\n",
      "Episode failed: PSNR Diff -1.002781 < -1 at step 155\n",
      "Initial MSE: 0.002279, Initial PSNR: 24.442272, 08:36:25\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002279, Initial PSNR: 24.442272, 2024-12-23 08:36:25.591829\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 290          |\n",
      "|    ep_rew_mean          | -1.18e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 558          |\n",
      "|    total_timesteps      | 11008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.662049e+19 |\n",
      "|    clip_fraction        | 0.886        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.09e+04    |\n",
      "|    explained_variance   | -0.222       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 6.63e+09     |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | 3.77e+12     |\n",
      "|    value_loss           | 0.0332       |\n",
      "------------------------------------------\n",
      "Step: 100, MSE: 0.002605, PSNR: 23.860300, PSNR Diff: -0.581972, Changes: 2, Reward: -4.07, 08:36:35\n",
      "Episode failed: PSNR Diff -1.003372 < -1 at step 189\n",
      "Initial MSE: 0.003548, Initial PSNR: 24.500721, 08:36:37\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.003548, Initial PSNR: 24.500721, 2024-12-23 08:36:37.343863\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 287            |\n",
      "|    ep_rew_mean          | -1.17e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 19             |\n",
      "|    iterations           | 44             |\n",
      "|    time_elapsed         | 571            |\n",
      "|    total_timesteps      | 11264          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 834568800000.0 |\n",
      "|    clip_fraction        | 0.884          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -9.09e+04      |\n",
      "|    explained_variance   | 0.171          |\n",
      "|    learning_rate        | 1e-05          |\n",
      "|    loss                 | 8.82e+04       |\n",
      "|    n_updates            | 430            |\n",
      "|    policy_gradient_loss | 3.92e+12       |\n",
      "|    value_loss           | 0.0879         |\n",
      "--------------------------------------------\n",
      "Step: 100, MSE: 0.003787, PSNR: 24.216669, PSNR Diff: -0.284052, Changes: 7, Reward: -1.99, 08:36:47\n",
      "Step: 200, MSE: 0.003973, PSNR: 24.009142, PSNR Diff: -0.491579, Changes: 6, Reward: -3.44, 08:36:49\n",
      "Step: 300, MSE: 0.004124, PSNR: 23.846897, PSNR Diff: -0.653824, Changes: 6, Reward: -4.58, 08:36:51\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 287            |\n",
      "|    ep_rew_mean          | -1.17e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 19             |\n",
      "|    iterations           | 45             |\n",
      "|    time_elapsed         | 584            |\n",
      "|    total_timesteps      | 11520          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 103386440000.0 |\n",
      "|    clip_fraction        | 0.891          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -9.09e+04      |\n",
      "|    explained_variance   | 0.941          |\n",
      "|    learning_rate        | 1e-05          |\n",
      "|    loss                 | 0.682          |\n",
      "|    n_updates            | 440            |\n",
      "|    policy_gradient_loss | 1.31e+10       |\n",
      "|    value_loss           | 0.0337         |\n",
      "--------------------------------------------\n",
      "Step: 400, MSE: 0.004287, PSNR: 23.678694, PSNR Diff: -0.822027, Changes: 5, Reward: -5.75, 08:37:01\n",
      "Episode failed: PSNR Diff -1.000233 < -1 at step 487\n",
      "Initial MSE: 0.000448, Initial PSNR: 17.824612, 08:37:03\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.000448, Initial PSNR: 17.824612, 2024-12-23 08:37:03.396558\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 292          |\n",
      "|    ep_rew_mean          | -1.19e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 597          |\n",
      "|    total_timesteps      | 11776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1103998000.0 |\n",
      "|    clip_fraction        | 0.881        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.09e+04    |\n",
      "|    explained_variance   | -0.49        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.0657       |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | 7.07e+10     |\n",
      "|    value_loss           | 0.0433       |\n",
      "------------------------------------------\n",
      "Step: 100, MSE: 0.000479, PSNR: 17.526499, PSNR Diff: -0.298113, Changes: 8, Reward: -2.09, 08:37:13\n",
      "Step: 200, MSE: 0.000517, PSNR: 17.201084, PSNR Diff: -0.623528, Changes: 4, Reward: -4.36, 08:37:15\n",
      "Step: 300, MSE: 0.000546, PSNR: 16.958935, PSNR Diff: -0.865677, Changes: 6, Reward: -6.06, 08:37:16\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 292          |\n",
      "|    ep_rew_mean          | -1.19e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 610          |\n",
      "|    total_timesteps      | 12032        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.990953e+22 |\n",
      "|    clip_fraction        | 0.893        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.09e+04    |\n",
      "|    explained_variance   | -1.75        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 6.42e+05     |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | 1.83e+20     |\n",
      "|    value_loss           | 0.0963       |\n",
      "------------------------------------------\n",
      "Episode failed: PSNR Diff -1.001013 < -1 at step 365\n",
      "Initial MSE: 0.002071, Initial PSNR: 23.057629, 08:37:26\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002071, Initial PSNR: 23.057629, 2024-12-23 08:37:26.852599\n",
      "Step: 100, MSE: 0.002382, PSNR: 22.448856, PSNR Diff: -0.608772, Changes: 4, Reward: -4.26, 08:37:28\n",
      "Episode failed: PSNR Diff -1.006922 < -1 at step 174\n",
      "Initial MSE: 0.000360, Initial PSNR: 13.544583, 08:37:29\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.000360, Initial PSNR: 13.544583, 2024-12-23 08:37:29.415163\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 291           |\n",
      "|    ep_rew_mean          | -1.19e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 48            |\n",
      "|    time_elapsed         | 623           |\n",
      "|    total_timesteps      | 12288         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 15598781000.0 |\n",
      "|    clip_fraction        | 0.887         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | -0.971        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 3.58e+10      |\n",
      "|    n_updates            | 470           |\n",
      "|    policy_gradient_loss | 2.93e+13      |\n",
      "|    value_loss           | 0.0403        |\n",
      "-------------------------------------------\n",
      "Step: 100, MSE: 0.000383, PSNR: 13.273674, PSNR Diff: -0.270909, Changes: 4, Reward: -1.90, 08:37:39\n",
      "Step: 200, MSE: 0.000400, PSNR: 13.082389, PSNR Diff: -0.462194, Changes: 5, Reward: -3.24, 08:37:40\n",
      "Step: 300, MSE: 0.000421, PSNR: 12.859909, PSNR Diff: -0.684674, Changes: 6, Reward: -4.79, 08:37:42\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 291          |\n",
      "|    ep_rew_mean          | -1.19e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 635          |\n",
      "|    total_timesteps      | 12544        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.568799e+16 |\n",
      "|    clip_fraction        | 0.883        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.09e+04    |\n",
      "|    explained_variance   | 0.00137      |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 2.1e+10      |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | 1.93e+12     |\n",
      "|    value_loss           | 0.0778       |\n",
      "------------------------------------------\n",
      "Step: 400, MSE: 0.000440, PSNR: 12.664623, PSNR Diff: -0.879960, Changes: 5, Reward: -6.16, 08:37:52\n",
      "Episode failed: PSNR Diff -1.005876 < -1 at step 448\n",
      "Initial MSE: 0.004352, Initial PSNR: 23.475361, 08:37:53\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.004352, Initial PSNR: 23.475361, 2024-12-23 08:37:53.549168\n",
      "Step: 100, MSE: 0.005403, PSNR: 22.536022, PSNR Diff: -0.939339, Changes: 5, Reward: -6.58, 08:37:55\n",
      "Episode failed: PSNR Diff -1.002750 < -1 at step 108\n",
      "Initial MSE: 0.006961, Initial PSNR: 21.573324, 08:37:55\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.006961, Initial PSNR: 21.573324, 2024-12-23 08:37:55.726107\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 290           |\n",
      "|    ep_rew_mean          | -1.19e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 50            |\n",
      "|    time_elapsed         | 649           |\n",
      "|    total_timesteps      | 12800         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 96301340000.0 |\n",
      "|    clip_fraction        | 0.884         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | -1.94         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | -0.0785       |\n",
      "|    n_updates            | 490           |\n",
      "|    policy_gradient_loss | 5.87e+06      |\n",
      "|    value_loss           | 0.019         |\n",
      "-------------------------------------------\n",
      "Step: 100, MSE: 0.007296, PSNR: 21.369213, PSNR Diff: -0.204111, Changes: 4, Reward: -1.43, 08:38:05\n",
      "Step: 200, MSE: 0.007701, PSNR: 21.134398, PSNR Diff: -0.438927, Changes: 4, Reward: -3.07, 08:38:07\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 290           |\n",
      "|    ep_rew_mean          | -1.19e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 51            |\n",
      "|    time_elapsed         | 661           |\n",
      "|    total_timesteps      | 13056         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7103153e+22 |\n",
      "|    clip_fraction        | 0.883         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | 0.887         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 6.21e+22      |\n",
      "|    n_updates            | 500           |\n",
      "|    policy_gradient_loss | 1.63e+21      |\n",
      "|    value_loss           | 0.124         |\n",
      "-------------------------------------------\n",
      "Step: 300, MSE: 0.008030, PSNR: 20.953009, PSNR Diff: -0.620316, Changes: 5, Reward: -4.34, 08:38:17\n",
      "Step: 400, MSE: 0.008352, PSNR: 20.782085, PSNR Diff: -0.791239, Changes: 5, Reward: -5.54, 08:38:19\n",
      "Step: 500, MSE: 0.008663, PSNR: 20.623135, PSNR Diff: -0.950190, Changes: 4, Reward: -6.65, 08:38:21\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 290          |\n",
      "|    ep_rew_mean          | -1.19e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 674          |\n",
      "|    total_timesteps      | 13312        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1727382300.0 |\n",
      "|    clip_fraction        | 0.884        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.09e+04    |\n",
      "|    explained_variance   | 0.799        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.0624       |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | 3.25e+12     |\n",
      "|    value_loss           | 0.0441       |\n",
      "------------------------------------------\n",
      "Episode failed: PSNR Diff -1.002243 < -1 at step 534\n",
      "Initial MSE: 0.007000, Initial PSNR: 21.446293, 08:38:31\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.007000, Initial PSNR: 21.446293, 2024-12-23 08:38:31.271859\n",
      "Step: 100, MSE: 0.007650, PSNR: 21.060408, PSNR Diff: -0.385885, Changes: 6, Reward: -2.70, 08:38:33\n",
      "Step: 200, MSE: 0.008192, PSNR: 20.763132, PSNR Diff: -0.683161, Changes: 1, Reward: -4.78, 08:38:35\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 296        |\n",
      "|    ep_rew_mean          | -1.21e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 19         |\n",
      "|    iterations           | 53         |\n",
      "|    time_elapsed         | 689        |\n",
      "|    total_timesteps      | 13568      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 38753372.0 |\n",
      "|    clip_fraction        | 0.872      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -9.09e+04  |\n",
      "|    explained_variance   | 0.148      |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 221        |\n",
      "|    n_updates            | 520        |\n",
      "|    policy_gradient_loss | 7.03e+08   |\n",
      "|    value_loss           | 0.116      |\n",
      "----------------------------------------\n",
      "Step: 300, MSE: 0.008786, PSNR: 20.459290, PSNR Diff: -0.987003, Changes: 6, Reward: -6.91, 08:38:45\n",
      "Episode failed: PSNR Diff -1.003225 < -1 at step 304\n",
      "Initial MSE: 0.005877, Initial PSNR: 22.274117, 08:38:46\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.005877, Initial PSNR: 22.274117, 2024-12-23 08:38:46.027604\n",
      "Step: 100, MSE: 0.006489, PSNR: 21.844275, PSNR Diff: -0.429842, Changes: 7, Reward: -3.01, 08:38:47\n",
      "Step: 200, MSE: 0.007082, PSNR: 21.464592, PSNR Diff: -0.809525, Changes: 5, Reward: -5.67, 08:38:49\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 296          |\n",
      "|    ep_rew_mean          | -1.21e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 702          |\n",
      "|    total_timesteps      | 13824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5981744600.0 |\n",
      "|    clip_fraction        | 0.886        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.09e+04    |\n",
      "|    explained_variance   | 0.778        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 42.8         |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | 2.05e+08     |\n",
      "|    value_loss           | 0.0766       |\n",
      "------------------------------------------\n",
      "Episode failed: PSNR Diff -1.001858 < -1 at step 271\n",
      "Initial MSE: 0.011029, Initial PSNR: 19.574530, 08:38:59\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.011029, Initial PSNR: 19.574530, 2024-12-23 08:38:59.253036\n",
      "Step: 100, MSE: 0.011419, PSNR: 19.423656, PSNR Diff: -0.150873, Changes: 4, Reward: -1.06, 08:39:00\n",
      "---------------------------------------------\n",
      "| rollout/                |                 |\n",
      "|    ep_len_mean          | 296             |\n",
      "|    ep_rew_mean          | -1.21e+03       |\n",
      "| time/                   |                 |\n",
      "|    fps                  | 19              |\n",
      "|    iterations           | 55              |\n",
      "|    time_elapsed         | 715             |\n",
      "|    total_timesteps      | 14080           |\n",
      "| train/                  |                 |\n",
      "|    approx_kl            | 1052558000000.0 |\n",
      "|    clip_fraction        | 0.892           |\n",
      "|    clip_range           | 0.2             |\n",
      "|    entropy_loss         | -9.09e+04       |\n",
      "|    explained_variance   | 0.797           |\n",
      "|    learning_rate        | 1e-05           |\n",
      "|    loss                 | -0.0689         |\n",
      "|    n_updates            | 540             |\n",
      "|    policy_gradient_loss | 2.37e+14        |\n",
      "|    value_loss           | 0.0547          |\n",
      "---------------------------------------------\n",
      "Step: 200, MSE: 0.011709, PSNR: 19.314903, PSNR Diff: -0.259626, Changes: 7, Reward: -1.82, 08:39:11\n",
      "Step: 300, MSE: 0.012005, PSNR: 19.206339, PSNR Diff: -0.368191, Changes: 7, Reward: -2.58, 08:39:12\n",
      "Step: 400, MSE: 0.012400, PSNR: 19.065817, PSNR Diff: -0.508713, Changes: 6, Reward: -3.56, 08:39:14\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 296           |\n",
      "|    ep_rew_mean          | -1.21e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 56            |\n",
      "|    time_elapsed         | 728           |\n",
      "|    total_timesteps      | 14336         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 28409573000.0 |\n",
      "|    clip_fraction        | 0.893         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | -0.134        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | -0.0163       |\n",
      "|    n_updates            | 550           |\n",
      "|    policy_gradient_loss | 9.89e+12      |\n",
      "|    value_loss           | 0.0486        |\n",
      "-------------------------------------------\n",
      "Step: 500, MSE: 0.012738, PSNR: 18.948902, PSNR Diff: -0.625628, Changes: 4, Reward: -4.38, 08:39:25\n",
      "Step: 600, MSE: 0.013082, PSNR: 18.833105, PSNR Diff: -0.741425, Changes: 6, Reward: -5.19, 08:39:27\n",
      "Step: 700, MSE: 0.013439, PSNR: 18.716427, PSNR Diff: -0.858103, Changes: 4, Reward: -6.01, 08:39:29\n",
      "---------------------------------------------\n",
      "| rollout/                |                 |\n",
      "|    ep_len_mean          | 296             |\n",
      "|    ep_rew_mean          | -1.21e+03       |\n",
      "| time/                   |                 |\n",
      "|    fps                  | 19              |\n",
      "|    iterations           | 57              |\n",
      "|    time_elapsed         | 742             |\n",
      "|    total_timesteps      | 14592           |\n",
      "| train/                  |                 |\n",
      "|    approx_kl            | 1701778800000.0 |\n",
      "|    clip_fraction        | 0.898           |\n",
      "|    clip_range           | 0.2             |\n",
      "|    entropy_loss         | -9.09e+04       |\n",
      "|    explained_variance   | -0.155          |\n",
      "|    learning_rate        | 1e-05           |\n",
      "|    loss                 | -0.0809         |\n",
      "|    n_updates            | 560             |\n",
      "|    policy_gradient_loss | 1.77e+06        |\n",
      "|    value_loss           | 0.0179          |\n",
      "---------------------------------------------\n",
      "Step: 800, MSE: 0.013869, PSNR: 18.579670, PSNR Diff: -0.994860, Changes: 7, Reward: -6.96, 08:39:39\n",
      "Episode failed: PSNR Diff -1.000179 < -1 at step 810\n",
      "Initial MSE: 0.003075, Initial PSNR: 25.019129, 08:39:40\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.003075, Initial PSNR: 25.019129, 2024-12-23 08:39:40.028868\n",
      "Step: 100, MSE: 0.003368, PSNR: 24.622932, PSNR Diff: -0.396196, Changes: 7, Reward: -2.77, 08:39:41\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 306            |\n",
      "|    ep_rew_mean          | -1.25e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 19             |\n",
      "|    iterations           | 58             |\n",
      "|    time_elapsed         | 755            |\n",
      "|    total_timesteps      | 14848          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 199153290000.0 |\n",
      "|    clip_fraction        | 0.888          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -9.09e+04      |\n",
      "|    explained_variance   | -0.0788        |\n",
      "|    learning_rate        | 1e-05          |\n",
      "|    loss                 | 0.000653       |\n",
      "|    n_updates            | 570            |\n",
      "|    policy_gradient_loss | 3.37e+06       |\n",
      "|    value_loss           | 0.0389         |\n",
      "--------------------------------------------\n",
      "Step: 200, MSE: 0.003597, PSNR: 24.337366, PSNR Diff: -0.681763, Changes: 5, Reward: -4.77, 08:39:52\n",
      "Step: 300, MSE: 0.003811, PSNR: 24.086548, PSNR Diff: -0.932581, Changes: 5, Reward: -6.53, 08:39:53\n",
      "Episode failed: PSNR Diff -1.001680 < -1 at step 324\n",
      "Initial MSE: 0.001598, Initial PSNR: 21.840214, 08:39:54\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.001598, Initial PSNR: 21.840214, 2024-12-23 08:39:54.182691\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 307       |\n",
      "|    ep_rew_mean          | -1.25e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 19        |\n",
      "|    iterations           | 59        |\n",
      "|    time_elapsed         | 768       |\n",
      "|    total_timesteps      | 15104     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 37782.78  |\n",
      "|    clip_fraction        | 0.874     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -9.09e+04 |\n",
      "|    explained_variance   | 0.29      |\n",
      "|    learning_rate        | 1e-05     |\n",
      "|    loss                 | 0.253     |\n",
      "|    n_updates            | 580       |\n",
      "|    policy_gradient_loss | 9.62e+04  |\n",
      "|    value_loss           | 0.0622    |\n",
      "---------------------------------------\n",
      "Step: 100, MSE: 0.002012, PSNR: 20.840378, PSNR Diff: -0.999836, Changes: 4, Reward: -7.00, 08:40:04\n",
      "Episode failed: PSNR Diff -1.010525 < -1 at step 101\n",
      "Initial MSE: 0.006110, Initial PSNR: 21.967287, 08:40:04\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.006110, Initial PSNR: 21.967287, 2024-12-23 08:40:04.591144\n",
      "Step: 100, MSE: 0.006409, PSNR: 21.760176, PSNR Diff: -0.207111, Changes: 7, Reward: -1.45, 08:40:06\n",
      "Step: 200, MSE: 0.006714, PSNR: 21.558056, PSNR Diff: -0.409231, Changes: 5, Reward: -2.86, 08:40:07\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 303          |\n",
      "|    ep_rew_mean          | -1.24e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 781          |\n",
      "|    total_timesteps      | 15360        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.473119e+16 |\n",
      "|    clip_fraction        | 0.879        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.09e+04    |\n",
      "|    explained_variance   | -0.771       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.00435      |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | 5.17e+14     |\n",
      "|    value_loss           | 0.0671       |\n",
      "------------------------------------------\n",
      "Step: 300, MSE: 0.006966, PSNR: 21.398211, PSNR Diff: -0.569077, Changes: 5, Reward: -3.98, 08:40:18\n",
      "Step: 400, MSE: 0.007317, PSNR: 21.184422, PSNR Diff: -0.782866, Changes: 6, Reward: -5.48, 08:40:20\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 303           |\n",
      "|    ep_rew_mean          | -1.24e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 61            |\n",
      "|    time_elapsed         | 794           |\n",
      "|    total_timesteps      | 15616         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.3593107e+17 |\n",
      "|    clip_fraction        | 0.893         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.09e+04     |\n",
      "|    explained_variance   | 0.874         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 0.26          |\n",
      "|    n_updates            | 600           |\n",
      "|    policy_gradient_loss | 2.14e+15      |\n",
      "|    value_loss           | 0.0632        |\n",
      "-------------------------------------------\n",
      "Step: 500, MSE: 0.007615, PSNR: 21.011223, PSNR Diff: -0.956064, Changes: 3, Reward: -6.69, 08:40:31\n",
      "Episode failed: PSNR Diff -1.000893 < -1 at step 526\n",
      "Initial MSE: 0.002312, Initial PSNR: 26.359688, 08:40:32\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.002312, Initial PSNR: 26.359688, 2024-12-23 08:40:32.041792\n",
      "Step: 100, MSE: 0.002510, PSNR: 26.003155, PSNR Diff: -0.356533, Changes: 9, Reward: -2.50, 08:40:33\n",
      "Step: 200, MSE: 0.002723, PSNR: 25.649323, PSNR Diff: -0.710365, Changes: 7, Reward: -4.97, 08:40:35\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 307          |\n",
      "|    ep_rew_mean          | -1.25e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 808          |\n",
      "|    total_timesteps      | 15872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9594480000.0 |\n",
      "|    clip_fraction        | 0.887        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.09e+04    |\n",
      "|    explained_variance   | -0.247       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | -0.0678      |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | 4.69e+08     |\n",
      "|    value_loss           | 0.126        |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "from sb3_contrib import MaskablePPO\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import torchOptics.optics as tt\n",
    "import torch.nn as nn\n",
    "import torchOptics.metrics as tm\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torchvision\n",
    "import tqdm\n",
    "import time\n",
    "import pandas as pd\n",
    "from sb3_contrib.common.maskable.utils import get_action_masks\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "from stable_baselines3 import PPO\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 현재 날짜와 시간을 가져와 포맷 지정\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "class BinaryNet(nn.Module):\n",
    "    def __init__(self, num_hologram, final='Sigmoid', in_planes=3,\n",
    "                 channels=[32, 64, 128, 256, 512, 1024, 2048, 4096],\n",
    "                 convReLU=True, convBN=True, poolReLU=True, poolBN=True,\n",
    "                 deconvReLU=True, deconvBN=True):\n",
    "        super(BinaryNet, self).__init__()\n",
    "\n",
    "        def CRB2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True, relu=True, bn=True):\n",
    "            layers = []\n",
    "            layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                 kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                                 bias=bias)]\n",
    "            if relu:\n",
    "                layers += [nn.Tanh()]\n",
    "            if bn:\n",
    "                layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "\n",
    "            cbr = nn.Sequential(*layers)  # *으로 list unpacking\n",
    "\n",
    "            return cbr\n",
    "\n",
    "        def TRB2d(in_channels, out_channels, kernel_size=2, stride=2, bias=True, relu=True, bn=True):\n",
    "            layers = []\n",
    "            layers += [nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                          kernel_size=2, stride=2, padding=0,\n",
    "                                          bias=True)]\n",
    "            if bn:\n",
    "                layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "            if relu:\n",
    "                layers += [nn.ReLU()]\n",
    "\n",
    "            cbr = nn.Sequential(*layers)  # *으로 list unpacking\n",
    "\n",
    "            return cbr\n",
    "\n",
    "        self.enc1_1 = CRB2d(in_planes, channels[0], relu=convReLU, bn=convBN)\n",
    "        self.enc1_2 = CRB2d(channels[0], channels[0], relu=convReLU, bn=convBN)\n",
    "        self.pool1 = CRB2d(channels[0], channels[0], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc2_1 = CRB2d(channels[0], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.enc2_2 = CRB2d(channels[1], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.pool2 = CRB2d(channels[1], channels[1], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc3_1 = CRB2d(channels[1], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.enc3_2 = CRB2d(channels[2], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.pool3 = CRB2d(channels[2], channels[2], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc4_1 = CRB2d(channels[2], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.enc4_2 = CRB2d(channels[3], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.pool4 = CRB2d(channels[3], channels[3], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc5_1 = CRB2d(channels[3], channels[4], relu=convReLU, bn=convBN)\n",
    "        self.enc5_2 = CRB2d(channels[4], channels[4], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv4 = TRB2d(channels[4], channels[3], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec4_1 = CRB2d(channels[4], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.dec4_2 = CRB2d(channels[3], channels[3], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv3 = TRB2d(channels[3], channels[2], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec3_1 = CRB2d(channels[3], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.dec3_2 = CRB2d(channels[2], channels[2], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv2 = TRB2d(channels[2], channels[1], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec2_1 = CRB2d(channels[2], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.dec2_2 = CRB2d(channels[1], channels[1], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv1 = TRB2d(channels[1], channels[0], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec1_1 = CRB2d(channels[1], channels[0], relu=convReLU, bn=convBN)\n",
    "        self.dec1_2 = CRB2d(channels[0], channels[0], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.classifier = CRB2d(channels[0], num_hologram, relu=False, bn=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1_1 = self.enc1_1(x)\n",
    "        enc1_2 = self.enc1_2(enc1_1)\n",
    "        pool1 = self.pool1(enc1_2)\n",
    "\n",
    "        enc2_1 = self.enc2_1(pool1)\n",
    "        enc2_2 = self.enc2_2(enc2_1)\n",
    "        pool2 = self.pool2(enc2_2)\n",
    "\n",
    "        enc3_1 = self.enc3_1(pool2)\n",
    "        enc3_2 = self.enc3_2(enc3_1)\n",
    "        pool3 = self.pool3(enc3_2)\n",
    "\n",
    "        enc4_1 = self.enc4_1(pool3)\n",
    "        enc4_2 = self.enc4_2(enc4_1)\n",
    "        pool4 = self.pool4(enc4_2)\n",
    "\n",
    "        enc5_1 = self.enc5_1(pool4)\n",
    "        enc5_2 = self.enc5_2(enc5_1)\n",
    "\n",
    "        deconv4 = self.deconv4(enc5_2)\n",
    "        concat4 = torch.cat((deconv4, enc4_2), dim=1)\n",
    "        dec4_1 = self.dec4_1(concat4)\n",
    "        dec4_2 = self.dec4_2(dec4_1)\n",
    "\n",
    "        deconv3 = self.deconv3(dec4_2)\n",
    "        concat3 = torch.cat((deconv3, enc3_2), dim=1)\n",
    "        dec3_1 = self.dec3_1(concat3)\n",
    "        dec3_2 = self.dec3_2(dec3_1)\n",
    "\n",
    "        deconv2 = self.deconv2(dec3_2)\n",
    "        concat2 = torch.cat((deconv2, enc2_2), dim=1)\n",
    "        dec2_1 = self.dec2_1(concat2)\n",
    "        dec2_2 = self.dec2_2(dec2_1)\n",
    "\n",
    "        deconv1 = self.deconv1(dec2_2)\n",
    "        concat1 = torch.cat((deconv1, enc1_2), dim=1)\n",
    "        dec1_1 = self.dec1_1(concat1)\n",
    "        dec1_2 = self.dec1_2(dec1_1)\n",
    "\n",
    "        # Final classifier\n",
    "        out = self.classifier(dec1_2)\n",
    "        out = nn.Sigmoid()(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = BinaryNet(num_hologram=8, in_planes=1, convReLU=False,\n",
    "                  convBN=False, poolReLU=False, poolBN=False,\n",
    "                  deconvReLU=False, deconvBN=False).cuda()\n",
    "test = torch.randn(1, 1, 128, 128).cuda()\n",
    "out = model(test)\n",
    "print(out.shape)\n",
    "\n",
    "\n",
    "class Dataset512(Dataset):\n",
    "    def __init__(self, target_dir, meta, transform=None, isTrain=True, padding=0):\n",
    "        self.target_dir = target_dir\n",
    "        self.transform = transform\n",
    "        self.meta = meta\n",
    "        self.isTrain = isTrain\n",
    "        self.target_list = sorted(glob.glob(target_dir+'*.png'))\n",
    "        self.center_crop = torchvision.transforms.CenterCrop(128)\n",
    "        self.random_crop = torchvision.transforms.RandomCrop((128, 128))\n",
    "        self.padding = padding\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        target = tt.imread(self.target_list[idx], meta=meta, gray=True).unsqueeze(0)\n",
    "        if target.shape[-1] < 128 or target.shape[-2] < 128:\n",
    "            target = torchvision.transforms.Resize(128)(target)\n",
    "        if self.isTrain:\n",
    "            target = self.random_crop(target)\n",
    "            target = torchvision.transforms.functional.pad(target, (self.padding, self.padding, self.padding, self.padding))\n",
    "        else:\n",
    "            target = self.center_crop(target)\n",
    "            target = torchvision.transforms.functional.pad(target, (self.padding, self.padding, self.padding, self.padding))\n",
    "        return target\n",
    "\n",
    "\n",
    "# BinaryHologramEnv 클래스\n",
    "class BinaryHologramEnv(gym.Env):\n",
    "    def __init__(self, target_function, trainloader, max_steps=1000, T_PSNR=30, T_steps=10, max_allowed_changes=10):\n",
    "        \"\"\"\n",
    "        target_function: 타겟 이미지와의 손실(MSE 또는 PSNR) 계산 함수.\n",
    "        trainloader: 학습 데이터셋 로더.\n",
    "        max_steps: 최대 타임스텝 제한.\n",
    "        T_PSNR: 목표 PSNR 값.\n",
    "        T_steps: PSNR 목표를 유지해야 하는 최소 타임스텝.\n",
    "        max_allowed_changes: 한 번에 조작할 수 있는 최대 픽셀 수.\n",
    "        \"\"\"\n",
    "        super(BinaryHologramEnv, self).__init__()\n",
    "\n",
    "        # 관찰 공간 (1, 8, 128, 128)\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(1, 8, 128, 128), dtype=np.float32)\n",
    "\n",
    "        # 행동 공간: MultiBinary 데이터\n",
    "        self.action_space = spaces.MultiBinary(1 * 8 * 128 * 128)\n",
    "\n",
    "        # 모델 및 데이터 로더 설정\n",
    "        self.target_function = target_function  # BinaryNet 모델\n",
    "        self.trainloader = trainloader          # 학습 데이터 로더\n",
    "\n",
    "        # 에피소드 설정\n",
    "        self.max_steps = max_steps\n",
    "        self.T_PSNR = T_PSNR\n",
    "        self.T_steps = T_steps\n",
    "        self.max_allowed_changes = max_allowed_changes  # 한 번에 조작할 수 있는 최대 픽셀 수\n",
    "\n",
    "        # 학습 상태 초기화\n",
    "        self.state = None\n",
    "        self.observation = None\n",
    "        self.steps = 0\n",
    "        self.psnr_sustained_steps = 0\n",
    "\n",
    "        # 학습 데이터셋에서 첫 배치 추출\n",
    "        self.data_iter = iter(self.trainloader)\n",
    "        self.target_image = None\n",
    "\n",
    "    def reset(self, seed=None, options=None, lr=1e-4, z=2e-3):\n",
    "        \"\"\"\n",
    "        환경 초기화 함수.\n",
    "        데이터셋에서 새로운 이미지를 가져오고 초기 상태를 설정합니다.\n",
    "        - 데이터셋의 다음 이미지를 불러옵니다. \n",
    "        - BinaryNet을 사용해 초기 관찰값을 생성합니다.\n",
    "        - 초기 상태(state)는 관찰값을 이진화한 결과입니다.\n",
    "        - 초기 PSNR과 MSE를 계산하고 출력합니다.\n",
    "\n",
    "        Args:\n",
    "            seed (int, optional): 랜덤 시드 값. Default는 None.\n",
    "            options (dict, optional): 추가 옵션. Default는 None.\n",
    "            lr (float, optional): 학습률. Default는 1e-4.\n",
    "            z (float, optional): 시뮬레이션 거리. Default는 2e-3.\n",
    "\n",
    "        Returns:\n",
    "            observation (np.ndarray): 초기 관찰값.\n",
    "            dict: 초기 상태와 행동 마스크.\n",
    "        \"\"\"\n",
    "        torch.cuda.empty_cache()\n",
    "        try:\n",
    "            self.target_image = next(self.data_iter)\n",
    "        except StopIteration:\n",
    "            self.data_iter = iter(self.trainloader)\n",
    "            self.target_image = next(self.data_iter)\n",
    "\n",
    "        self.target_image = self.target_image.cuda()\n",
    "        with torch.no_grad():\n",
    "            model_output = self.target_function(self.target_image)\n",
    "        self.observation = model_output.cpu().numpy()  # (1, 8, 512, 512)\n",
    "\n",
    "        self.steps = 0\n",
    "        self.psnr_sustained_steps = 0\n",
    "        self.state = (self.observation >= 0.5).astype(np.int8)  # 이진화 상태\n",
    "\n",
    "        binary = torch.tensor(self.state, dtype=torch.float32).cuda()\n",
    "        binary = tt.Tensor(binary, meta={'dx': (7.56e-6, 7.56e-6), 'wl': 515e-9})  # meta 정보 포함\n",
    "\n",
    "        # 시뮬레이션\n",
    "        sim = tt.simulate(binary, z).abs()**2\n",
    "        result = torch.mean(sim, dim=1, keepdim=True)\n",
    "\n",
    "        # MSE 및 PSNR 계산\n",
    "        mse = tt.relativeLoss(result, self.target_image, F.mse_loss).detach().cpu().numpy()\n",
    "        self.initial_psnr = tt.relativeLoss(result, self.target_image, tm.get_PSNR)  # 초기 PSNR 저장\n",
    "\n",
    "        current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        print(f\"Initial MSE: {mse:.6f}, Initial PSNR: {self.initial_psnr:.6f}, {current_time}\")\n",
    "\n",
    "        mask = self.create_action_mask(self.observation)\n",
    "        return self.observation, {\"state\": self.state, \"mask\": mask}\n",
    "\n",
    "\n",
    "    def initialize_state(self, z=2e-3):\n",
    "        \"\"\"\n",
    "        초기 상태를 생성하고, 시뮬레이션 및 관련 값을 계산합니다.\n",
    "\n",
    "        Args:\n",
    "            z (float): 시뮬레이션 거리. Default는 2e-3.\n",
    "\n",
    "        Returns:\n",
    "            observation (np.ndarray): 초기 관찰값.\n",
    "            dict: 초기 상태와 행동 마스크.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            # 모델로 초기 관찰값 생성\n",
    "            model_output = self.target_function(self.target_image)\n",
    "        self.observation = model_output.cpu().numpy()  # 관찰값을 numpy 배열로 변환\n",
    "\n",
    "        self.state = (self.observation >= 0.5).astype(np.int8)  # 이진화 상태\n",
    "\n",
    "        binary = torch.tensor(self.state, dtype=torch.float32).cuda()  # 상태를 Torch 텐서로 변환\n",
    "        binary = tt.Tensor(binary, meta={'dx': (7.56e-6, 7.56e-6), 'wl': 515e-9})  # 메타 정보 추가\n",
    "\n",
    "        # 시뮬레이션 수행\n",
    "        sim = tt.simulate(binary, z).abs()**2\n",
    "        result = torch.mean(sim, dim=1, keepdim=True)\n",
    "\n",
    "        # 초기 MSE와 PSNR 계산\n",
    "        mse = tt.relativeLoss(result, self.target_image, F.mse_loss).detach().cpu().numpy()\n",
    "        psnr = tt.relativeLoss(result, self.target_image, tm.get_PSNR)\n",
    "\n",
    "        # 초기 값 출력\n",
    "        print(f\"Initial MSE: {mse:.6f}, Initial PSNR: {psnr:.6f}, {datetime.now()}\")\n",
    "\n",
    "        # 관찰값 업데이트\n",
    "        self.observation = result.detach().cpu().numpy()\n",
    "        mask = self.create_action_mask(self.observation)\n",
    "\n",
    "        return self.observation, {\"state\": self.state, \"mask\": mask}\n",
    "\n",
    "    def create_action_mask(self, observation):\n",
    "        \"\"\"\n",
    "        관찰값에 따라 행동 마스크 생성.\n",
    "        - 관찰값이 0~0.2인 경우 행동 0으로 고정.\n",
    "        - 관찰값이 0.8~1인 경우 행동 1로 고정.\n",
    "        - 최대 변경 가능 픽셀 수 제한.\n",
    "\n",
    "        Args:\n",
    "            observation (np.ndarray): 관찰값.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: 행동 마스크.\n",
    "        \"\"\"\n",
    "        mask = np.ones_like(observation, dtype=np.int8)  # 기본적으로 모든 행동 가능\n",
    "        mask[observation <= 0.2] = 0  # 관찰값이 0~0.2면 행동 0으로 고정\n",
    "        mask[observation >= 0.8] = 1  # 관찰값이 0.8~1이면 행동 1로 고정\n",
    "\n",
    "        # 허용된 변경 수를 강제 적용\n",
    "        allowed_indices = np.where(mask.flatten() == 1)[0]\n",
    "        if len(allowed_indices) > self.max_allowed_changes:\n",
    "            # 초과 변경을 방지하도록 고정된 수의 픽셀만 선택 가능\n",
    "            selected_indices = np.random.choice(allowed_indices, self.max_allowed_changes, replace=False)\n",
    "            mask = np.zeros_like(mask.flatten())\n",
    "            mask[selected_indices] = 1\n",
    "            mask = mask.reshape(observation.shape)\n",
    "\n",
    "        return mask\n",
    "\n",
    "    def step(self, action, lr=1e-4, z=2e-3):\n",
    "        \"\"\"\n",
    "        환경의 한 타임스텝을 진행합니다.\n",
    "        - 주어진 행동(action)을 적용하고, 새로운 상태를 계산합니다.\n",
    "        - MSE와 PSNR 계산 후 보상을 반환합니다.\n",
    "\n",
    "        Args:\n",
    "            action (np.ndarray): 에이전트가 수행한 행동.\n",
    "            lr (float, optional): 학습률. Default는 1e-4.\n",
    "            z (float, optional): 시뮬레이션 거리. Default는 2e-3.\n",
    "\n",
    "        Returns:\n",
    "            observation (np.ndarray): 새로운 관찰값.\n",
    "            float: 보상 값.\n",
    "            bool: 종료 여부.\n",
    "            bool: Truncated 여부.\n",
    "            dict: 추가 정보 (MSE, PSNR, 행동 마스크 등).\n",
    "        \"\"\"\n",
    "        if self.steps == 0:\n",
    "            print(\"Executing reset logic for the first step\")\n",
    "            self.steps += 1\n",
    "            observation, info = self.initialize_state(z)\n",
    "            return observation, 0.0, False, False, info\n",
    "\n",
    "        action = np.reshape(action, (1, 8, 128, 128)).astype(np.int8)\n",
    "\n",
    "        # 행동에 마스크 강제 적용\n",
    "        mask = self.create_action_mask(self.observation)\n",
    "        masked_action = action * mask\n",
    "\n",
    "        # 조작 픽셀 수 확인\n",
    "        num_changes = np.sum(masked_action)\n",
    "        reward = 0\n",
    "\n",
    "        if num_changes > self.max_allowed_changes:\n",
    "            reward -= 50\n",
    "\n",
    "        # 현재 상태에 행동을 적용하여 새로운 상태 생성\n",
    "        new_state = np.logical_xor(self.state, masked_action).astype(np.int8)\n",
    "\n",
    "        binary = torch.tensor(new_state, dtype=torch.float32).cuda()\n",
    "        binary = tt.Tensor(binary, meta={'dx': (7.56e-6, 7.56e-6), 'wl': 515e-9})\n",
    "\n",
    "        # 시뮬레이션 수행\n",
    "        sim = tt.simulate(binary, z).abs()**2\n",
    "        result = torch.mean(sim, dim=1, keepdim=True)\n",
    "\n",
    "        # MSE 및 PSNR 계산\n",
    "        mse = tt.relativeLoss(result, self.target_image, F.mse_loss).detach().cpu().numpy()\n",
    "        psnr = tt.relativeLoss(result, self.target_image, tm.get_PSNR)\n",
    "\n",
    "        # 초기 PSNR과의 차이 계산\n",
    "        psnr_diff = psnr - self.initial_psnr\n",
    "\n",
    "        # 실패 조건 확인\n",
    "        if psnr_diff < -1:\n",
    "            print(f\"Episode failed: PSNR Diff {psnr_diff:.6f} < -1 at step {self.steps}\")\n",
    "            return self.observation, -100.0, True, False, {\"mse\": mse, \"psnr\": psnr, \"psnr_diff\": psnr_diff, \"mask\": None}\n",
    "\n",
    "        # 보상 계산\n",
    "        reward += psnr_diff * 7\n",
    "        reward -= 0.1 * num_changes if num_changes > self.max_allowed_changes else 0\n",
    "\n",
    "        # 출력 추가 (100 스텝마다 출력)\n",
    "        if self.steps % 100 == 0:\n",
    "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "            print(f\"Step: {self.steps}, MSE: {mse:.6f}, PSNR: {psnr:.6f}, PSNR Diff: {psnr_diff:.6f}, \"\n",
    "                  f\"Changes: {num_changes}, Reward: {reward:.2f}, {current_time}\")\n",
    "\n",
    "        # 상태 업데이트\n",
    "        self.state = new_state\n",
    "        self.observation = self.state\n",
    "\n",
    "        terminated = self.steps >= self.max_steps or self.psnr_sustained_steps >= self.T_steps\n",
    "        truncated = self.steps >= self.max_steps\n",
    "\n",
    "        if psnr >= self.T_PSNR:\n",
    "            self.psnr_sustained_steps += 1\n",
    "        else:\n",
    "            self.psnr_sustained_steps = 0\n",
    "\n",
    "        mask = self.create_action_mask(self.observation)\n",
    "        info = {\"mse\": mse, \"psnr\": psnr, \"psnr_diff\": psnr_diff, \"mask\": mask}\n",
    "\n",
    "        del binary, sim, result\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        self.steps += 1\n",
    "        return self.observation, reward, terminated, truncated, info\n",
    "\n",
    "\n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_uniform_(m.weight.data, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight.data, 1)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight.data)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "batch_size = 1\n",
    "target_dir = '/nfs/dataset/DIV2K/DIV2K_train_HR/DIV2K_train_HR/'\n",
    "valid_dir = '/nfs/dataset/DIV2K/DIV2K_valid_HR/DIV2K_valid_HR/'\n",
    "meta = {'wl': (515e-9), 'dx': (7.56e-6, 7.56e-6)}  # 메타 정보\n",
    "padding = 0\n",
    "\n",
    "# Dataset512 클래스 사용\n",
    "train_dataset = Dataset512(target_dir=target_dir, meta=meta, isTrain=True, padding=padding)\n",
    "valid_dataset = Dataset512(target_dir=valid_dir, meta=meta, isTrain=False, padding=padding)\n",
    "\n",
    "# DataLoader 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# BinaryNet 모델 로드\n",
    "model = BinaryNet(num_hologram=8, in_planes=1, convReLU=False, convBN=False,\n",
    "                  poolReLU=False, poolBN=False, deconvReLU=False, deconvBN=False).cuda()\n",
    "model.load_state_dict(torch.load('result_v/2024-12-19 21:37:10.439713_pre_reinforce_8_0.002/2024-12-19 21:37:10.439713_pre_reinforce_8_0.002'))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# 마스크 함수 정의\n",
    "def mask_fn(env):\n",
    "    return env.create_action_mask(env.observation)\n",
    "\n",
    "# 환경 생성에 새로운 데이터 로더 적용\n",
    "env = BinaryHologramEnv(\n",
    "    target_function=model,\n",
    "    trainloader=train_loader,  # 업데이트된 train_loader 사용\n",
    "    max_steps=1000,\n",
    "    T_PSNR=30,\n",
    "    T_steps=10\n",
    ")\n",
    "\n",
    "# ActionMasker 래퍼 적용\n",
    "env = ActionMasker(env, mask_fn)\n",
    "\n",
    "# Vectorized 환경 생성\n",
    "venv = make_vec_env(lambda: env, n_envs=1)\n",
    "venv = VecNormalize(venv, norm_obs=True, norm_reward=True, clip_obs=10.0)\n",
    "\n",
    "# PPO 학습\n",
    "#ppo_model = PPO(\n",
    "#    \"MlpPolicy\",\n",
    "#    venv,\n",
    "#    verbose=2,\n",
    "#    n_steps=1024,\n",
    "#    batch_size=64,\n",
    "#    gamma=0.99,\n",
    "#    learning_rate=3e-4,\n",
    "#    tensorboard_log=\"./ppo_with_mask/\"\n",
    "#)\n",
    "\n",
    "#ppo_model.learn(total_timesteps=10000000)\n",
    "\n",
    "# 학습된 모델 저장\n",
    "#ppo_model.save(f\"ppo_with_mask_{current_date}\")\n",
    "\n",
    "from sb3_contrib import RecurrentPPO\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    net_arch=[dict(pi=[256, 256], vf=[256, 256])],  # 더 복잡한 네트워크 구조\n",
    "    lstm_hidden_size=128,  # LSTM 크기 유지\n",
    "    shared_lstm=False  # 별도 LSTM 사용\n",
    ")\n",
    "\n",
    "ppo_model = RecurrentPPO(\n",
    "    \"MlpLstmPolicy\",\n",
    "    venv,\n",
    "    verbose=2,\n",
    "    n_steps=256,\n",
    "    batch_size=64,\n",
    "    gamma=0.99,\n",
    "    gae_lambda=0.95,\n",
    "    learning_rate=1e-5,\n",
    "    clip_range=0.2,\n",
    "    vf_coef=0.5,\n",
    "    max_grad_norm=0.5,  # 그라디언트 클리핑 활성화\n",
    "    tensorboard_log=\"./ppo_with_mask/\",\n",
    "    policy_kwargs=policy_kwargs\n",
    ")\n",
    "\n",
    "\n",
    "# 학습\n",
    "ppo_model.learn(total_timesteps=10000000)\n",
    "\n",
    "# 모델 저장\n",
    "ppo_model.save(f\"ppo_with_mask_{current_date}\")\n",
    "\n",
    "\n",
    "# 평가용 환경 생성\n",
    "#eval_env = make_vec_env(lambda: env, n_envs=1)\n",
    "\n",
    "# EvalCallback 추가\n",
    "#eval_callback = EvalCallback(\n",
    "#    eval_env,\n",
    "#    best_model_save_path='./logs/',\n",
    "#    log_path='./logs/',\n",
    "#    eval_freq=10000,  # 평가 빈도 (타임스텝 기준)\n",
    "#    deterministic=True,\n",
    "#    render=False\n",
    "#)\n",
    "\n",
    "#ppo_model = PPO(\n",
    "#    \"MlpPolicy\",\n",
    "#    venv,\n",
    "#    verbose=2,\n",
    "#    n_steps=1024,\n",
    "#    batch_size=64,\n",
    "#    gamma=0.99,\n",
    "#    learning_rate=3e-4,\n",
    "#    tensorboard_log=\"./ppo_with_mask/\"\n",
    "#)\n",
    "\n",
    "# 학습 시작 (콜백 추가)\n",
    "#ppo_model.learn(total_timesteps=10000000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dd0c83-99b3-4f86-bc23-89c6b278e3ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e105c7a2-bd3a-440c-9ad3-3ec9a08af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
