{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e3bb6ba70918dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T07:50:49.917672Z",
     "start_time": "2024-12-17T07:50:49.704223Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/kornia/feature/lightglue.py:30: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 1024, 1024])\n",
      "Using cuda device\n",
      "Initial MSE: 0.003951, Initial PSNR: 22.867798, 12:56:35\n",
      "Logging to ./ppo_with_mask/PPO_51\n",
      "Executing reset logic for the first step\n",
      "Initial MSE: 0.003951, Initial PSNR: 22.867798, 2024-12-20_12-56-01\n",
      "Step: 1, MSE: 0.055931, PSNR: 11.358774, 12:56:36\n",
      "Step: 2, MSE: 0.055867, PSNR: 11.363712, 12:56:36\n",
      "Step: 3, MSE: 0.056043, PSNR: 11.350099, 12:56:37\n",
      "Step: 4, MSE: 0.055960, PSNR: 11.356546, 12:56:37\n",
      "Step: 5, MSE: 0.056055, PSNR: 11.349133, 12:56:37\n",
      "Step: 6, MSE: 0.055907, PSNR: 11.360646, 12:56:38\n",
      "Step: 7, MSE: 0.055957, PSNR: 11.356728, 12:56:38\n",
      "Step: 8, MSE: 0.056009, PSNR: 11.352707, 12:56:38\n",
      "Step: 9, MSE: 0.055984, PSNR: 11.354679, 12:56:39\n",
      "Step: 10, MSE: 0.055893, PSNR: 11.361737, 12:56:39\n",
      "Step: 11, MSE: 0.055871, PSNR: 11.363409, 12:56:39\n",
      "Step: 12, MSE: 0.055924, PSNR: 11.359320, 12:56:40\n",
      "Step: 13, MSE: 0.056008, PSNR: 11.352772, 12:56:40\n",
      "Step: 14, MSE: 0.055957, PSNR: 11.356782, 12:56:40\n",
      "Step: 15, MSE: 0.055871, PSNR: 11.363458, 12:56:40\n",
      "Step: 16, MSE: 0.055967, PSNR: 11.355944, 12:56:41\n",
      "Step: 17, MSE: 0.055996, PSNR: 11.353759, 12:56:41\n",
      "Step: 18, MSE: 0.055950, PSNR: 11.357306, 12:56:41\n",
      "Step: 19, MSE: 0.055891, PSNR: 11.361880, 12:56:42\n",
      "Step: 20, MSE: 0.055926, PSNR: 11.359166, 12:56:42\n",
      "Step: 21, MSE: 0.056003, PSNR: 11.353192, 12:56:42\n",
      "Step: 22, MSE: 0.055897, PSNR: 11.361431, 12:56:43\n",
      "Step: 23, MSE: 0.056018, PSNR: 11.352022, 12:56:43\n",
      "Step: 24, MSE: 0.056008, PSNR: 11.352819, 12:56:43\n",
      "Step: 25, MSE: 0.055870, PSNR: 11.363483, 12:56:44\n",
      "Step: 26, MSE: 0.056043, PSNR: 11.350116, 12:56:44\n",
      "Step: 27, MSE: 0.056074, PSNR: 11.347679, 12:56:44\n",
      "Step: 28, MSE: 0.055998, PSNR: 11.353589, 12:56:44\n",
      "Step: 29, MSE: 0.055898, PSNR: 11.361342, 12:56:45\n",
      "Step: 30, MSE: 0.055747, PSNR: 11.373060, 12:56:45\n",
      "Step: 31, MSE: 0.055963, PSNR: 11.356296, 12:56:45\n",
      "Step: 32, MSE: 0.055900, PSNR: 11.361164, 12:56:46\n",
      "Step: 33, MSE: 0.056032, PSNR: 11.350908, 12:56:46\n",
      "Step: 34, MSE: 0.055830, PSNR: 11.366586, 12:56:46\n",
      "Step: 35, MSE: 0.055879, PSNR: 11.362792, 12:56:47\n",
      "Step: 36, MSE: 0.055920, PSNR: 11.359586, 12:56:47\n",
      "Step: 37, MSE: 0.055902, PSNR: 11.361006, 12:56:47\n",
      "Step: 38, MSE: 0.055905, PSNR: 11.360822, 12:56:48\n",
      "Step: 39, MSE: 0.056008, PSNR: 11.352802, 12:56:48\n",
      "Step: 40, MSE: 0.055959, PSNR: 11.356569, 12:56:48\n",
      "Step: 41, MSE: 0.056018, PSNR: 11.352041, 12:56:48\n",
      "Step: 42, MSE: 0.055924, PSNR: 11.359344, 12:56:49\n",
      "Step: 43, MSE: 0.055999, PSNR: 11.353458, 12:56:49\n",
      "Step: 44, MSE: 0.055948, PSNR: 11.357456, 12:56:49\n",
      "Step: 45, MSE: 0.055962, PSNR: 11.356350, 12:56:50\n",
      "Step: 46, MSE: 0.055979, PSNR: 11.355040, 12:56:50\n",
      "Step: 47, MSE: 0.056008, PSNR: 11.352786, 12:56:50\n",
      "Step: 48, MSE: 0.055975, PSNR: 11.355334, 12:56:51\n",
      "Step: 49, MSE: 0.056059, PSNR: 11.348806, 12:56:51\n",
      "Step: 50, MSE: 0.055928, PSNR: 11.358999, 12:56:51\n",
      "Step: 51, MSE: 0.055996, PSNR: 11.353735, 12:56:52\n",
      "Step: 52, MSE: 0.056056, PSNR: 11.349081, 12:56:52\n",
      "Step: 53, MSE: 0.056033, PSNR: 11.350850, 12:56:52\n",
      "Step: 54, MSE: 0.055918, PSNR: 11.359751, 12:56:52\n",
      "Step: 55, MSE: 0.055949, PSNR: 11.357345, 12:56:53\n",
      "Step: 56, MSE: 0.055984, PSNR: 11.354648, 12:56:53\n",
      "Step: 57, MSE: 0.055954, PSNR: 11.356953, 12:56:53\n",
      "Step: 58, MSE: 0.055834, PSNR: 11.366302, 12:56:54\n",
      "Step: 59, MSE: 0.055953, PSNR: 11.357086, 12:56:54\n",
      "Step: 60, MSE: 0.055944, PSNR: 11.357761, 12:56:54\n",
      "Step: 61, MSE: 0.055994, PSNR: 11.353873, 12:56:55\n",
      "Step: 62, MSE: 0.055954, PSNR: 11.356997, 12:56:55\n",
      "Step: 63, MSE: 0.056003, PSNR: 11.353153, 12:56:55\n",
      "Step: 64, MSE: 0.055891, PSNR: 11.361861, 12:56:55\n",
      "Step: 65, MSE: 0.055894, PSNR: 11.361624, 12:56:56\n",
      "Step: 66, MSE: 0.055953, PSNR: 11.357080, 12:56:56\n",
      "Step: 67, MSE: 0.055857, PSNR: 11.364541, 12:56:56\n",
      "Step: 68, MSE: 0.055950, PSNR: 11.357269, 12:56:57\n",
      "Step: 69, MSE: 0.055921, PSNR: 11.359526, 12:56:57\n",
      "Step: 70, MSE: 0.056009, PSNR: 11.352696, 12:56:57\n",
      "Step: 71, MSE: 0.055861, PSNR: 11.364204, 12:56:58\n",
      "Step: 72, MSE: 0.056004, PSNR: 11.353067, 12:56:58\n",
      "Step: 73, MSE: 0.056020, PSNR: 11.351873, 12:56:58\n",
      "Step: 74, MSE: 0.055984, PSNR: 11.354661, 12:56:59\n",
      "Step: 75, MSE: 0.055945, PSNR: 11.357694, 12:56:59\n",
      "Step: 76, MSE: 0.055807, PSNR: 11.368423, 12:56:59\n",
      "Step: 77, MSE: 0.055914, PSNR: 11.360053, 12:57:00\n",
      "Step: 78, MSE: 0.055996, PSNR: 11.353697, 12:57:00\n",
      "Step: 79, MSE: 0.055989, PSNR: 11.354280, 12:57:00\n",
      "Step: 80, MSE: 0.055938, PSNR: 11.358200, 12:57:00\n",
      "Step: 81, MSE: 0.055987, PSNR: 11.354412, 12:57:01\n",
      "Step: 82, MSE: 0.055894, PSNR: 11.361668, 12:57:01\n",
      "Step: 83, MSE: 0.055975, PSNR: 11.355314, 12:57:01\n",
      "Step: 84, MSE: 0.055906, PSNR: 11.360730, 12:57:02\n",
      "Step: 85, MSE: 0.056003, PSNR: 11.353192, 12:57:02\n",
      "Step: 86, MSE: 0.055980, PSNR: 11.354937, 12:57:02\n",
      "Step: 87, MSE: 0.055921, PSNR: 11.359525, 12:57:03\n",
      "Step: 88, MSE: 0.055907, PSNR: 11.360660, 12:57:03\n",
      "Step: 89, MSE: 0.055944, PSNR: 11.357748, 12:57:03\n",
      "Step: 90, MSE: 0.055923, PSNR: 11.359368, 12:57:04\n",
      "Step: 91, MSE: 0.055933, PSNR: 11.358624, 12:57:04\n",
      "Step: 92, MSE: 0.055925, PSNR: 11.359233, 12:57:04\n",
      "Step: 93, MSE: 0.056019, PSNR: 11.351937, 12:57:05\n",
      "Step: 94, MSE: 0.055872, PSNR: 11.363367, 12:57:05\n",
      "Step: 95, MSE: 0.055933, PSNR: 11.358633, 12:57:05\n",
      "Step: 96, MSE: 0.055791, PSNR: 11.369616, 12:57:06\n",
      "Step: 97, MSE: 0.055854, PSNR: 11.364755, 12:57:06\n",
      "Step: 98, MSE: 0.055969, PSNR: 11.355853, 12:57:06\n",
      "Step: 99, MSE: 0.055969, PSNR: 11.355818, 12:57:06\n",
      "Model saved at step 100 to ./ppo_checkpoints_2024-12-20_12-56-01/model_step_100.zip\n",
      "Step: 100, MSE: 0.055897, PSNR: 11.361432, 12:58:21\n",
      "Step: 101, MSE: 0.055989, PSNR: 11.354252, 12:58:21\n",
      "Step: 102, MSE: 0.055965, PSNR: 11.356159, 12:58:21\n",
      "Step: 103, MSE: 0.055969, PSNR: 11.355827, 12:58:22\n",
      "Step: 104, MSE: 0.055932, PSNR: 11.358673, 12:58:22\n",
      "Step: 105, MSE: 0.055850, PSNR: 11.365041, 12:58:22\n",
      "Step: 106, MSE: 0.055950, PSNR: 11.357306, 12:58:23\n",
      "Step: 107, MSE: 0.055867, PSNR: 11.363766, 12:58:23\n",
      "Step: 108, MSE: 0.055939, PSNR: 11.358173, 12:58:23\n",
      "Step: 109, MSE: 0.056017, PSNR: 11.352095, 12:58:24\n",
      "Step: 110, MSE: 0.055984, PSNR: 11.354638, 12:58:24\n",
      "Step: 111, MSE: 0.056040, PSNR: 11.350328, 12:58:24\n",
      "Step: 112, MSE: 0.055982, PSNR: 11.354826, 12:58:24\n",
      "Step: 113, MSE: 0.055906, PSNR: 11.360727, 12:58:25\n",
      "Step: 114, MSE: 0.056111, PSNR: 11.344780, 12:58:25\n",
      "Step: 115, MSE: 0.055897, PSNR: 11.361372, 12:58:25\n",
      "Step: 116, MSE: 0.056060, PSNR: 11.348782, 12:58:26\n",
      "Step: 117, MSE: 0.055948, PSNR: 11.357413, 12:58:26\n",
      "Step: 118, MSE: 0.055998, PSNR: 11.353599, 12:58:26\n",
      "Step: 119, MSE: 0.056015, PSNR: 11.352261, 12:58:27\n",
      "Step: 120, MSE: 0.055844, PSNR: 11.365503, 12:58:27\n",
      "Step: 121, MSE: 0.055937, PSNR: 11.358318, 12:58:27\n",
      "Step: 122, MSE: 0.055980, PSNR: 11.354998, 12:58:28\n",
      "Step: 123, MSE: 0.055967, PSNR: 11.356011, 12:58:28\n",
      "Step: 124, MSE: 0.056000, PSNR: 11.353447, 12:58:28\n",
      "Step: 125, MSE: 0.055917, PSNR: 11.359850, 12:58:28\n",
      "Step: 126, MSE: 0.056023, PSNR: 11.351666, 12:58:29\n",
      "Step: 127, MSE: 0.055987, PSNR: 11.354457, 12:58:29\n",
      "Step: 128, MSE: 0.055976, PSNR: 11.355274, 12:58:29\n",
      "Step: 129, MSE: 0.056023, PSNR: 11.351599, 12:58:30\n",
      "Step: 130, MSE: 0.055978, PSNR: 11.355133, 12:58:30\n",
      "Step: 131, MSE: 0.055885, PSNR: 11.362363, 12:58:30\n",
      "Step: 132, MSE: 0.055854, PSNR: 11.364779, 12:58:31\n",
      "Step: 133, MSE: 0.055924, PSNR: 11.359335, 12:58:31\n",
      "Step: 134, MSE: 0.055929, PSNR: 11.358901, 12:58:31\n",
      "Step: 135, MSE: 0.055949, PSNR: 11.357382, 12:58:32\n",
      "Step: 136, MSE: 0.055963, PSNR: 11.356310, 12:58:32\n",
      "Step: 137, MSE: 0.055983, PSNR: 11.354759, 12:58:32\n",
      "Step: 138, MSE: 0.055907, PSNR: 11.360647, 12:58:32\n",
      "Step: 139, MSE: 0.055975, PSNR: 11.355353, 12:58:33\n",
      "Step: 140, MSE: 0.055936, PSNR: 11.358393, 12:58:33\n",
      "Step: 141, MSE: 0.056007, PSNR: 11.352849, 12:58:33\n",
      "Step: 142, MSE: 0.056080, PSNR: 11.347195, 12:58:34\n",
      "Step: 143, MSE: 0.055965, PSNR: 11.356155, 12:58:34\n",
      "Step: 144, MSE: 0.056047, PSNR: 11.349781, 12:58:34\n",
      "Step: 145, MSE: 0.055873, PSNR: 11.363251, 12:58:35\n",
      "Step: 146, MSE: 0.055953, PSNR: 11.357096, 12:58:35\n",
      "Step: 147, MSE: 0.055897, PSNR: 11.361389, 12:58:35\n",
      "Step: 148, MSE: 0.055884, PSNR: 11.362402, 12:58:36\n",
      "Step: 149, MSE: 0.055987, PSNR: 11.354412, 12:58:36\n",
      "Step: 150, MSE: 0.055917, PSNR: 11.359863, 12:58:36\n",
      "Step: 151, MSE: 0.055991, PSNR: 11.354147, 12:58:36\n",
      "Step: 152, MSE: 0.055972, PSNR: 11.355614, 12:58:37\n",
      "Step: 153, MSE: 0.055970, PSNR: 11.355774, 12:58:37\n",
      "Step: 154, MSE: 0.056058, PSNR: 11.348896, 12:58:37\n",
      "Step: 155, MSE: 0.056016, PSNR: 11.352207, 12:58:38\n",
      "Step: 156, MSE: 0.055947, PSNR: 11.357523, 12:58:38\n",
      "Step: 157, MSE: 0.055949, PSNR: 11.357402, 12:58:38\n",
      "Step: 158, MSE: 0.055916, PSNR: 11.359970, 12:58:39\n",
      "Step: 159, MSE: 0.055864, PSNR: 11.363945, 12:58:39\n",
      "Step: 160, MSE: 0.055864, PSNR: 11.363945, 12:58:39\n",
      "Step: 161, MSE: 0.055925, PSNR: 11.359249, 12:58:39\n",
      "Step: 162, MSE: 0.055960, PSNR: 11.356550, 12:58:40\n",
      "Step: 163, MSE: 0.055923, PSNR: 11.359424, 12:58:40\n",
      "Step: 164, MSE: 0.055980, PSNR: 11.355003, 12:58:40\n",
      "Step: 165, MSE: 0.055933, PSNR: 11.358595, 12:58:41\n",
      "Step: 166, MSE: 0.056041, PSNR: 11.350202, 12:58:41\n",
      "Step: 167, MSE: 0.055881, PSNR: 11.362665, 12:58:41\n",
      "Step: 168, MSE: 0.055923, PSNR: 11.359401, 12:58:42\n",
      "Step: 169, MSE: 0.055950, PSNR: 11.357279, 12:58:42\n",
      "Step: 170, MSE: 0.056009, PSNR: 11.352705, 12:58:42\n",
      "Step: 171, MSE: 0.055931, PSNR: 11.358803, 12:58:43\n",
      "Step: 172, MSE: 0.055957, PSNR: 11.356731, 12:58:43\n",
      "Step: 173, MSE: 0.055972, PSNR: 11.355597, 12:58:43\n",
      "Step: 174, MSE: 0.056032, PSNR: 11.350970, 12:58:43\n",
      "Step: 175, MSE: 0.056026, PSNR: 11.351410, 12:58:44\n",
      "Step: 176, MSE: 0.055886, PSNR: 11.362303, 12:58:44\n",
      "Step: 177, MSE: 0.056007, PSNR: 11.352878, 12:58:44\n",
      "Step: 178, MSE: 0.055974, PSNR: 11.355469, 12:58:45\n",
      "Step: 179, MSE: 0.055971, PSNR: 11.355628, 12:58:45\n",
      "Step: 180, MSE: 0.055971, PSNR: 11.355658, 12:58:45\n",
      "Step: 181, MSE: 0.055996, PSNR: 11.353708, 12:58:46\n",
      "Step: 182, MSE: 0.055907, PSNR: 11.360660, 12:58:46\n",
      "Step: 183, MSE: 0.055945, PSNR: 11.357653, 12:58:46\n",
      "Step: 184, MSE: 0.055993, PSNR: 11.353960, 12:58:46\n",
      "Step: 185, MSE: 0.055843, PSNR: 11.365615, 12:58:47\n",
      "Step: 186, MSE: 0.055954, PSNR: 11.356982, 12:58:47\n",
      "Step: 187, MSE: 0.055871, PSNR: 11.363410, 12:58:47\n",
      "Step: 188, MSE: 0.055998, PSNR: 11.353554, 12:58:48\n",
      "Step: 189, MSE: 0.055805, PSNR: 11.368556, 12:58:48\n",
      "Step: 190, MSE: 0.056032, PSNR: 11.350945, 12:58:48\n",
      "Step: 191, MSE: 0.056025, PSNR: 11.351439, 12:58:49\n",
      "Step: 192, MSE: 0.055938, PSNR: 11.358247, 12:58:49\n",
      "Step: 193, MSE: 0.055931, PSNR: 11.358801, 12:58:49\n",
      "Step: 194, MSE: 0.055845, PSNR: 11.365442, 12:58:49\n",
      "Step: 195, MSE: 0.056051, PSNR: 11.349489, 12:58:50\n",
      "Step: 196, MSE: 0.055980, PSNR: 11.354937, 12:58:50\n",
      "Step: 197, MSE: 0.055935, PSNR: 11.358457, 12:58:50\n",
      "Step: 198, MSE: 0.055951, PSNR: 11.357201, 12:58:51\n",
      "Step: 199, MSE: 0.055959, PSNR: 11.356602, 12:58:51\n",
      "Model saved at step 200 to ./ppo_checkpoints_2024-12-20_12-56-01/model_step_200.zip\n",
      "Step: 200, MSE: 0.055889, PSNR: 11.362008, 13:00:01\n",
      "Step: 201, MSE: 0.055993, PSNR: 11.353928, 13:00:02\n",
      "Step: 202, MSE: 0.055895, PSNR: 11.361574, 13:00:02\n",
      "Step: 203, MSE: 0.055878, PSNR: 11.362920, 13:00:02\n",
      "Step: 204, MSE: 0.055903, PSNR: 11.360959, 13:00:03\n",
      "Step: 205, MSE: 0.055882, PSNR: 11.362592, 13:00:03\n",
      "Step: 206, MSE: 0.056043, PSNR: 11.350051, 13:00:03\n",
      "Step: 207, MSE: 0.055926, PSNR: 11.359158, 13:00:03\n",
      "Step: 208, MSE: 0.055945, PSNR: 11.357702, 13:00:04\n",
      "Step: 209, MSE: 0.056003, PSNR: 11.353192, 13:00:04\n",
      "Step: 210, MSE: 0.055990, PSNR: 11.354181, 13:00:04\n",
      "Step: 211, MSE: 0.055975, PSNR: 11.355322, 13:00:05\n",
      "Step: 212, MSE: 0.056030, PSNR: 11.351112, 13:00:05\n",
      "Step: 213, MSE: 0.055992, PSNR: 11.354051, 13:00:05\n",
      "Step: 214, MSE: 0.055997, PSNR: 11.353656, 13:00:06\n",
      "Step: 215, MSE: 0.055990, PSNR: 11.354165, 13:00:06\n",
      "Step: 216, MSE: 0.055942, PSNR: 11.357918, 13:00:06\n",
      "Step: 217, MSE: 0.056002, PSNR: 11.353253, 13:00:07\n",
      "Step: 218, MSE: 0.055904, PSNR: 11.360853, 13:00:07\n",
      "Step: 219, MSE: 0.056043, PSNR: 11.350075, 13:00:07\n",
      "Step: 220, MSE: 0.055986, PSNR: 11.354466, 13:00:07\n",
      "Step: 221, MSE: 0.055892, PSNR: 11.361814, 13:00:08\n",
      "Step: 222, MSE: 0.055837, PSNR: 11.366071, 13:00:08\n",
      "Step: 223, MSE: 0.055922, PSNR: 11.359451, 13:00:08\n",
      "Step: 224, MSE: 0.055992, PSNR: 11.354073, 13:00:09\n",
      "Step: 225, MSE: 0.055975, PSNR: 11.355357, 13:00:09\n",
      "Step: 226, MSE: 0.055964, PSNR: 11.356226, 13:00:09\n",
      "Step: 227, MSE: 0.055943, PSNR: 11.357861, 13:00:10\n",
      "Step: 228, MSE: 0.055925, PSNR: 11.359200, 13:00:10\n",
      "Step: 229, MSE: 0.055904, PSNR: 11.360875, 13:00:10\n",
      "Step: 230, MSE: 0.056148, PSNR: 11.341938, 13:00:11\n",
      "Step: 231, MSE: 0.055970, PSNR: 11.355715, 13:00:11\n",
      "Step: 232, MSE: 0.055902, PSNR: 11.361051, 13:00:11\n",
      "Step: 233, MSE: 0.055962, PSNR: 11.356327, 13:00:12\n",
      "Step: 234, MSE: 0.055786, PSNR: 11.370010, 13:00:12\n",
      "Step: 235, MSE: 0.056022, PSNR: 11.351679, 13:00:12\n",
      "Step: 236, MSE: 0.055930, PSNR: 11.358833, 13:00:13\n",
      "Step: 237, MSE: 0.055861, PSNR: 11.364240, 13:00:13\n",
      "Step: 238, MSE: 0.055942, PSNR: 11.357913, 13:00:13\n",
      "Step: 239, MSE: 0.056081, PSNR: 11.347103, 13:00:13\n",
      "Step: 240, MSE: 0.055912, PSNR: 11.360218, 13:00:14\n",
      "Step: 241, MSE: 0.055892, PSNR: 11.361810, 13:00:14\n",
      "Step: 242, MSE: 0.055995, PSNR: 11.353785, 13:00:14\n",
      "Step: 243, MSE: 0.055886, PSNR: 11.362262, 13:00:15\n",
      "Step: 244, MSE: 0.056052, PSNR: 11.349360, 13:00:15\n",
      "Step: 245, MSE: 0.055997, PSNR: 11.353665, 13:00:15\n",
      "Step: 246, MSE: 0.055828, PSNR: 11.366774, 13:00:16\n",
      "Step: 247, MSE: 0.055955, PSNR: 11.356941, 13:00:16\n",
      "Step: 248, MSE: 0.055923, PSNR: 11.359350, 13:00:16\n",
      "Step: 249, MSE: 0.056012, PSNR: 11.352468, 13:00:16\n",
      "Step: 250, MSE: 0.055935, PSNR: 11.358485, 13:00:17\n",
      "Step: 251, MSE: 0.055906, PSNR: 11.360695, 13:00:17\n",
      "Step: 252, MSE: 0.055966, PSNR: 11.356068, 13:00:17\n",
      "Step: 253, MSE: 0.056052, PSNR: 11.349379, 13:00:18\n",
      "Step: 254, MSE: 0.055882, PSNR: 11.362593, 13:00:18\n",
      "Step: 255, MSE: 0.056011, PSNR: 11.352576, 13:00:18\n",
      "Step: 256, MSE: 0.055990, PSNR: 11.354222, 13:00:19\n",
      "Step: 257, MSE: 0.055889, PSNR: 11.362009, 13:00:19\n",
      "Step: 258, MSE: 0.056002, PSNR: 11.353272, 13:00:19\n",
      "Step: 259, MSE: 0.055985, PSNR: 11.354538, 13:00:20\n",
      "Step: 260, MSE: 0.055893, PSNR: 11.361700, 13:00:20\n",
      "Step: 261, MSE: 0.056031, PSNR: 11.351000, 13:00:20\n",
      "Step: 262, MSE: 0.055938, PSNR: 11.358253, 13:00:20\n",
      "Step: 263, MSE: 0.055943, PSNR: 11.357812, 13:00:21\n",
      "Step: 264, MSE: 0.055946, PSNR: 11.357621, 13:00:21\n",
      "Step: 265, MSE: 0.055985, PSNR: 11.354591, 13:00:21\n",
      "Step: 266, MSE: 0.055932, PSNR: 11.358673, 13:00:22\n",
      "Step: 267, MSE: 0.055955, PSNR: 11.356936, 13:00:22\n",
      "Step: 268, MSE: 0.056043, PSNR: 11.350098, 13:00:22\n",
      "Step: 269, MSE: 0.055841, PSNR: 11.365755, 13:00:23\n",
      "Step: 270, MSE: 0.055940, PSNR: 11.358067, 13:00:23\n",
      "Step: 271, MSE: 0.056044, PSNR: 11.349991, 13:00:23\n",
      "Step: 272, MSE: 0.056074, PSNR: 11.347704, 13:00:24\n",
      "Step: 273, MSE: 0.056012, PSNR: 11.352462, 13:00:24\n",
      "Step: 274, MSE: 0.055924, PSNR: 11.359277, 13:00:24\n",
      "Step: 275, MSE: 0.055963, PSNR: 11.356248, 13:00:25\n",
      "Step: 276, MSE: 0.056001, PSNR: 11.353329, 13:00:25\n",
      "Step: 277, MSE: 0.055972, PSNR: 11.355618, 13:00:25\n",
      "Step: 278, MSE: 0.055973, PSNR: 11.355497, 13:00:25\n",
      "Step: 279, MSE: 0.055951, PSNR: 11.357184, 13:00:26\n",
      "Step: 280, MSE: 0.055921, PSNR: 11.359563, 13:00:26\n",
      "Step: 281, MSE: 0.055884, PSNR: 11.362432, 13:00:26\n",
      "Step: 282, MSE: 0.056091, PSNR: 11.346368, 13:00:27\n",
      "Step: 283, MSE: 0.056048, PSNR: 11.349702, 13:00:27\n",
      "Step: 284, MSE: 0.055932, PSNR: 11.358691, 13:00:27\n",
      "Step: 285, MSE: 0.055950, PSNR: 11.357264, 13:00:28\n",
      "Step: 286, MSE: 0.055937, PSNR: 11.358305, 13:00:28\n",
      "Step: 287, MSE: 0.056049, PSNR: 11.349609, 13:00:28\n",
      "Step: 288, MSE: 0.055866, PSNR: 11.363806, 13:00:29\n",
      "Step: 289, MSE: 0.056014, PSNR: 11.352319, 13:00:29\n",
      "Step: 290, MSE: 0.055865, PSNR: 11.363874, 13:00:29\n",
      "Step: 291, MSE: 0.056001, PSNR: 11.353323, 13:00:30\n",
      "Step: 292, MSE: 0.055874, PSNR: 11.363174, 13:00:30\n",
      "Step: 293, MSE: 0.055906, PSNR: 11.360723, 13:00:30\n",
      "Step: 294, MSE: 0.055816, PSNR: 11.367703, 13:00:30\n",
      "Step: 295, MSE: 0.055905, PSNR: 11.360771, 13:00:31\n",
      "Step: 296, MSE: 0.055895, PSNR: 11.361565, 13:00:31\n",
      "Step: 297, MSE: 0.055998, PSNR: 11.353545, 13:00:31\n",
      "Step: 298, MSE: 0.055852, PSNR: 11.364890, 13:00:32\n",
      "Step: 299, MSE: 0.055962, PSNR: 11.356387, 13:00:32\n",
      "Model saved at step 300 to ./ppo_checkpoints_2024-12-20_12-56-01/model_step_300.zip\n",
      "Step: 300, MSE: 0.056033, PSNR: 11.350859, 13:01:45\n",
      "Step: 301, MSE: 0.055904, PSNR: 11.360894, 13:01:46\n",
      "Step: 302, MSE: 0.055981, PSNR: 11.354884, 13:01:46\n",
      "Step: 303, MSE: 0.055940, PSNR: 11.358094, 13:01:46\n",
      "Step: 304, MSE: 0.056038, PSNR: 11.350489, 13:01:47\n",
      "Step: 305, MSE: 0.055886, PSNR: 11.362240, 13:01:47\n",
      "Step: 306, MSE: 0.056000, PSNR: 11.353431, 13:01:47\n",
      "Step: 307, MSE: 0.055886, PSNR: 11.362278, 13:01:48\n",
      "Step: 308, MSE: 0.056053, PSNR: 11.349289, 13:01:48\n",
      "Step: 309, MSE: 0.055944, PSNR: 11.357744, 13:01:48\n",
      "Step: 310, MSE: 0.055860, PSNR: 11.364323, 13:01:49\n",
      "Step: 311, MSE: 0.055961, PSNR: 11.356473, 13:01:49\n",
      "Step: 312, MSE: 0.055950, PSNR: 11.357274, 13:01:49\n",
      "Step: 313, MSE: 0.055997, PSNR: 11.353656, 13:01:49\n",
      "Step: 314, MSE: 0.055972, PSNR: 11.355558, 13:01:50\n",
      "Step: 315, MSE: 0.056007, PSNR: 11.352863, 13:01:50\n",
      "Step: 316, MSE: 0.055911, PSNR: 11.360329, 13:01:50\n",
      "Step: 317, MSE: 0.055925, PSNR: 11.359257, 13:01:51\n",
      "Step: 318, MSE: 0.056025, PSNR: 11.351496, 13:01:51\n",
      "Step: 319, MSE: 0.055958, PSNR: 11.356650, 13:01:51\n",
      "Step: 320, MSE: 0.055985, PSNR: 11.354555, 13:01:52\n",
      "Step: 321, MSE: 0.056030, PSNR: 11.351126, 13:01:52\n",
      "Step: 322, MSE: 0.055980, PSNR: 11.354953, 13:01:52\n",
      "Step: 323, MSE: 0.056019, PSNR: 11.351905, 13:01:52\n",
      "Step: 324, MSE: 0.055976, PSNR: 11.355314, 13:01:53\n",
      "Step: 325, MSE: 0.055870, PSNR: 11.363473, 13:01:53\n",
      "Step: 326, MSE: 0.056036, PSNR: 11.350632, 13:01:53\n",
      "Step: 327, MSE: 0.055923, PSNR: 11.359354, 13:01:54\n",
      "Step: 328, MSE: 0.055986, PSNR: 11.354507, 13:01:54\n",
      "Step: 329, MSE: 0.055892, PSNR: 11.361767, 13:01:54\n",
      "Step: 330, MSE: 0.055967, PSNR: 11.355992, 13:01:55\n",
      "Step: 331, MSE: 0.055998, PSNR: 11.353588, 13:01:55\n",
      "Step: 332, MSE: 0.056068, PSNR: 11.348158, 13:01:55\n",
      "Step: 333, MSE: 0.055926, PSNR: 11.359188, 13:01:56\n",
      "Step: 334, MSE: 0.055976, PSNR: 11.355277, 13:01:56\n",
      "Step: 335, MSE: 0.055930, PSNR: 11.358815, 13:01:56\n",
      "Step: 336, MSE: 0.055938, PSNR: 11.358187, 13:01:57\n",
      "Step: 337, MSE: 0.056013, PSNR: 11.352413, 13:01:57\n",
      "Step: 338, MSE: 0.056091, PSNR: 11.346379, 13:01:57\n",
      "Step: 339, MSE: 0.056001, PSNR: 11.353355, 13:01:57\n",
      "Step: 340, MSE: 0.055954, PSNR: 11.356982, 13:01:58\n",
      "Step: 341, MSE: 0.055864, PSNR: 11.363977, 13:01:58\n",
      "Step: 342, MSE: 0.055953, PSNR: 11.357037, 13:01:58\n",
      "Step: 343, MSE: 0.055923, PSNR: 11.359359, 13:01:59\n",
      "Step: 344, MSE: 0.055859, PSNR: 11.364370, 13:01:59\n",
      "Step: 345, MSE: 0.055957, PSNR: 11.356787, 13:01:59\n",
      "Step: 346, MSE: 0.056009, PSNR: 11.352753, 13:02:00\n",
      "Step: 347, MSE: 0.056033, PSNR: 11.350821, 13:02:00\n",
      "Step: 348, MSE: 0.055922, PSNR: 11.359461, 13:02:00\n",
      "Step: 349, MSE: 0.055874, PSNR: 11.363231, 13:02:00\n",
      "Step: 350, MSE: 0.056125, PSNR: 11.343708, 13:02:01\n",
      "Step: 351, MSE: 0.055945, PSNR: 11.357710, 13:02:01\n",
      "Step: 352, MSE: 0.055881, PSNR: 11.362659, 13:02:01\n",
      "Step: 353, MSE: 0.055879, PSNR: 11.362771, 13:02:02\n",
      "Step: 354, MSE: 0.055975, PSNR: 11.355319, 13:02:02\n",
      "Step: 355, MSE: 0.055996, PSNR: 11.353740, 13:02:02\n",
      "Step: 356, MSE: 0.056028, PSNR: 11.351273, 13:02:03\n",
      "Step: 357, MSE: 0.055984, PSNR: 11.354671, 13:02:03\n",
      "Step: 358, MSE: 0.055843, PSNR: 11.365570, 13:02:03\n",
      "Step: 359, MSE: 0.055864, PSNR: 11.363936, 13:02:04\n",
      "Step: 360, MSE: 0.055967, PSNR: 11.355984, 13:02:04\n",
      "Step: 361, MSE: 0.055850, PSNR: 11.365095, 13:02:04\n",
      "Step: 362, MSE: 0.055810, PSNR: 11.368194, 13:02:04\n",
      "Step: 363, MSE: 0.055999, PSNR: 11.353498, 13:02:05\n",
      "Step: 364, MSE: 0.056025, PSNR: 11.351503, 13:02:05\n",
      "Step: 365, MSE: 0.055933, PSNR: 11.358624, 13:02:05\n",
      "Step: 366, MSE: 0.055974, PSNR: 11.355414, 13:02:06\n",
      "Step: 367, MSE: 0.055978, PSNR: 11.355160, 13:02:06\n",
      "Step: 368, MSE: 0.055993, PSNR: 11.353989, 13:02:06\n",
      "Step: 369, MSE: 0.055954, PSNR: 11.357007, 13:02:07\n",
      "Step: 370, MSE: 0.056009, PSNR: 11.352709, 13:02:07\n",
      "Step: 371, MSE: 0.055961, PSNR: 11.356459, 13:02:07\n",
      "Step: 372, MSE: 0.055925, PSNR: 11.359268, 13:02:08\n",
      "Step: 373, MSE: 0.056065, PSNR: 11.348356, 13:02:08\n",
      "Step: 374, MSE: 0.055901, PSNR: 11.361066, 13:02:08\n",
      "Step: 375, MSE: 0.056040, PSNR: 11.350335, 13:02:09\n",
      "Step: 376, MSE: 0.055937, PSNR: 11.358289, 13:02:09\n",
      "Step: 377, MSE: 0.055998, PSNR: 11.353567, 13:02:09\n",
      "Step: 378, MSE: 0.055953, PSNR: 11.357033, 13:02:09\n",
      "Step: 379, MSE: 0.055967, PSNR: 11.355991, 13:02:10\n",
      "Step: 380, MSE: 0.055998, PSNR: 11.353570, 13:02:10\n",
      "Step: 381, MSE: 0.055939, PSNR: 11.358112, 13:02:10\n",
      "Step: 382, MSE: 0.055930, PSNR: 11.358833, 13:02:11\n",
      "Step: 383, MSE: 0.055979, PSNR: 11.355065, 13:02:11\n",
      "Step: 384, MSE: 0.055953, PSNR: 11.357064, 13:02:11\n",
      "Step: 385, MSE: 0.055932, PSNR: 11.358658, 13:02:12\n",
      "Step: 386, MSE: 0.055995, PSNR: 11.353832, 13:02:12\n",
      "Step: 387, MSE: 0.055947, PSNR: 11.357563, 13:02:12\n",
      "Step: 388, MSE: 0.056077, PSNR: 11.347461, 13:02:13\n",
      "Step: 389, MSE: 0.055991, PSNR: 11.354140, 13:02:13\n",
      "Step: 390, MSE: 0.055897, PSNR: 11.361401, 13:02:13\n",
      "Step: 391, MSE: 0.055849, PSNR: 11.365150, 13:02:14\n",
      "Step: 392, MSE: 0.055970, PSNR: 11.355743, 13:02:14\n",
      "Step: 393, MSE: 0.055996, PSNR: 11.353693, 13:02:14\n",
      "Step: 394, MSE: 0.055953, PSNR: 11.357075, 13:02:14\n",
      "Step: 395, MSE: 0.055914, PSNR: 11.360084, 13:02:15\n",
      "Step: 396, MSE: 0.056039, PSNR: 11.350375, 13:02:15\n",
      "Step: 397, MSE: 0.055999, PSNR: 11.353453, 13:02:15\n",
      "Step: 398, MSE: 0.055965, PSNR: 11.356121, 13:02:16\n",
      "Step: 399, MSE: 0.056094, PSNR: 11.346125, 13:02:16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "from sb3_contrib import MaskablePPO\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import torchOptics.optics as tt\n",
    "import torch.nn as nn\n",
    "import torchOptics.metrics as tm\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torchvision\n",
    "import tqdm\n",
    "import time\n",
    "import pandas as pd\n",
    "from sb3_contrib.common.maskable.utils import get_action_masks\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "from stable_baselines3 import PPO\n",
    "import warnings\n",
    "\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import os\n",
    "\n",
    "class SaveOnStepCallback(BaseCallback):\n",
    "    def __init__(self, save_freq, save_path, verbose=0):\n",
    "        super(SaveOnStepCallback, self).__init__(verbose)\n",
    "        self.save_freq = save_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        # 저장 경로가 없으면 생성\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # 지정된 주기마다 모델 저장\n",
    "        if self.n_calls % self.save_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, f\"model_step_{self.n_calls}.zip\")\n",
    "            self.model.save(model_path)\n",
    "            if self.verbose > 0:\n",
    "                print(f\"Model saved at step {self.n_calls} to {model_path}\")\n",
    "        return True\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 현재 날짜와 시간을 가져와 포맷 지정\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "class BinaryNet(nn.Module):\n",
    "    def __init__(self, num_hologram, final='Sigmoid', in_planes=3,\n",
    "                 channels=[32, 64, 128, 256, 512, 1024, 2048, 4096],\n",
    "                 convReLU=True, convBN=True, poolReLU=True, poolBN=True,\n",
    "                 deconvReLU=True, deconvBN=True):\n",
    "        super(BinaryNet, self).__init__()\n",
    "\n",
    "        def CRB2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True, relu=True, bn=True):\n",
    "            layers = []\n",
    "            layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                 kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                                 bias=bias)]\n",
    "            if relu:\n",
    "                layers += [nn.Tanh()]\n",
    "            if bn:\n",
    "                layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "\n",
    "            cbr = nn.Sequential(*layers)  # *으로 list unpacking\n",
    "\n",
    "            return cbr\n",
    "\n",
    "        def TRB2d(in_channels, out_channels, kernel_size=2, stride=2, bias=True, relu=True, bn=True):\n",
    "            layers = []\n",
    "            layers += [nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                          kernel_size=2, stride=2, padding=0,\n",
    "                                          bias=True)]\n",
    "            if bn:\n",
    "                layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "            if relu:\n",
    "                layers += [nn.ReLU()]\n",
    "\n",
    "            cbr = nn.Sequential(*layers)  # *으로 list unpacking\n",
    "\n",
    "            return cbr\n",
    "\n",
    "        self.enc1_1 = CRB2d(in_planes, channels[0], relu=convReLU, bn=convBN)\n",
    "        self.enc1_2 = CRB2d(channels[0], channels[0], relu=convReLU, bn=convBN)\n",
    "        self.pool1 = CRB2d(channels[0], channels[0], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc2_1 = CRB2d(channels[0], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.enc2_2 = CRB2d(channels[1], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.pool2 = CRB2d(channels[1], channels[1], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc3_1 = CRB2d(channels[1], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.enc3_2 = CRB2d(channels[2], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.pool3 = CRB2d(channels[2], channels[2], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc4_1 = CRB2d(channels[2], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.enc4_2 = CRB2d(channels[3], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.pool4 = CRB2d(channels[3], channels[3], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc5_1 = CRB2d(channels[3], channels[4], relu=convReLU, bn=convBN)\n",
    "        self.enc5_2 = CRB2d(channels[4], channels[4], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv4 = TRB2d(channels[4], channels[3], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec4_1 = CRB2d(channels[4], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.dec4_2 = CRB2d(channels[3], channels[3], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv3 = TRB2d(channels[3], channels[2], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec3_1 = CRB2d(channels[3], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.dec3_2 = CRB2d(channels[2], channels[2], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv2 = TRB2d(channels[2], channels[1], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec2_1 = CRB2d(channels[2], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.dec2_2 = CRB2d(channels[1], channels[1], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv1 = TRB2d(channels[1], channels[0], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec1_1 = CRB2d(channels[1], channels[0], relu=convReLU, bn=convBN)\n",
    "        self.dec1_2 = CRB2d(channels[0], channels[0], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.classifier = CRB2d(channels[0], num_hologram, relu=False, bn=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1_1 = self.enc1_1(x)\n",
    "        enc1_2 = self.enc1_2(enc1_1)\n",
    "        pool1 = self.pool1(enc1_2)\n",
    "\n",
    "        enc2_1 = self.enc2_1(pool1)\n",
    "        enc2_2 = self.enc2_2(enc2_1)\n",
    "        pool2 = self.pool2(enc2_2)\n",
    "\n",
    "        enc3_1 = self.enc3_1(pool2)\n",
    "        enc3_2 = self.enc3_2(enc3_1)\n",
    "        pool3 = self.pool3(enc3_2)\n",
    "\n",
    "        enc4_1 = self.enc4_1(pool3)\n",
    "        enc4_2 = self.enc4_2(enc4_1)\n",
    "        pool4 = self.pool4(enc4_2)\n",
    "\n",
    "        enc5_1 = self.enc5_1(pool4)\n",
    "        enc5_2 = self.enc5_2(enc5_1)\n",
    "\n",
    "        deconv4 = self.deconv4(enc5_2)\n",
    "        concat4 = torch.cat((deconv4, enc4_2), dim=1)\n",
    "        dec4_1 = self.dec4_1(concat4)\n",
    "        dec4_2 = self.dec4_2(dec4_1)\n",
    "\n",
    "        deconv3 = self.deconv3(dec4_2)\n",
    "        concat3 = torch.cat((deconv3, enc3_2), dim=1)\n",
    "        dec3_1 = self.dec3_1(concat3)\n",
    "        dec3_2 = self.dec3_2(dec3_1)\n",
    "\n",
    "        deconv2 = self.deconv2(dec3_2)\n",
    "        concat2 = torch.cat((deconv2, enc2_2), dim=1)\n",
    "        dec2_1 = self.dec2_1(concat2)\n",
    "        dec2_2 = self.dec2_2(dec2_1)\n",
    "\n",
    "        deconv1 = self.deconv1(dec2_2)\n",
    "        concat1 = torch.cat((deconv1, enc1_2), dim=1)\n",
    "        dec1_1 = self.dec1_1(concat1)\n",
    "        dec1_2 = self.dec1_2(dec1_1)\n",
    "\n",
    "        # Final classifier\n",
    "        out = self.classifier(dec1_2)\n",
    "        out = nn.Sigmoid()(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = BinaryNet(num_hologram=8, in_planes=1, convReLU=False,\n",
    "                  convBN=False, poolReLU=False, poolBN=False,\n",
    "                  deconvReLU=False, deconvBN=False).cuda()\n",
    "test = torch.randn(1, 1, 1024, 1024).cuda()\n",
    "out = model(test)\n",
    "print(out.shape)\n",
    "\n",
    "\n",
    "class Dataset512(Dataset):\n",
    "    def __init__(self, target_dir, meta, transform=None, isTrain=True, padding=0):\n",
    "        self.target_dir = target_dir\n",
    "        self.transform = transform\n",
    "        self.meta = meta\n",
    "        self.isTrain = isTrain\n",
    "        self.target_list = sorted(glob.glob(target_dir+'*.png'))\n",
    "        self.center_crop = torchvision.transforms.CenterCrop(1024)\n",
    "        self.random_crop = torchvision.transforms.RandomCrop((1024, 1024))\n",
    "        self.padding = padding\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        target = tt.imread(self.target_list[idx], meta=meta, gray=True).unsqueeze(0)\n",
    "        if target.shape[-1] < 1024 or target.shape[-2] < 1024:\n",
    "            target = torchvision.transforms.Resize(1024)(target)\n",
    "        if self.isTrain:\n",
    "            target = self.random_crop(target)\n",
    "            target = torchvision.transforms.functional.pad(target, (self.padding, self.padding, self.padding, self.padding))\n",
    "        else:\n",
    "            target = self.center_crop(target)\n",
    "            target = torchvision.transforms.functional.pad(target, (self.padding, self.padding, self.padding, self.padding))\n",
    "        return target\n",
    "\n",
    "\n",
    "#BinaryHologramEnv 클래스\n",
    "class BinaryHologramEnv(gym.Env):\n",
    "    def __init__(self, target_function, trainloader, max_steps=100000, T_PSNR=30, T_steps=1000):\n",
    "        \"\"\"\n",
    "        target_function: 타겟 이미지와의 손실(MSE 또는 PSNR) 계산 함수.\n",
    "        trainloader: 학습 데이터셋 로더.\n",
    "        max_steps: 최대 타임스텝 제한.\n",
    "        T_PSNR: 목표 PSNR 값.\n",
    "        T_steps: PSNR 목표를 유지해야 하는 최소 타임스텝.\n",
    "        \"\"\"\n",
    "        super(BinaryHologramEnv, self).__init__()\n",
    "\n",
    "        # 관찰 공간 (1, 8, 1024, 1024)\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(1, 8, 1024, 1024), dtype=np.float32)\n",
    "\n",
    "        # 행동 공간: (1, 8, 1024, 1024) 형태의 이진 데이터\n",
    "        self.action_space = spaces.Box(low=0, high=1, shape=(1, 8, 1024, 1024), dtype=np.int8)\n",
    "\n",
    "        # 모델 및 데이터 로더 설정\n",
    "        self.target_function = target_function  # BinaryNet 모델\n",
    "        self.trainloader = trainloader          # 학습 데이터 로더\n",
    "\n",
    "        # 에피소드 설정\n",
    "        self.max_steps = max_steps\n",
    "        self.T_PSNR = T_PSNR\n",
    "        self.T_steps = T_steps\n",
    "\n",
    "        # 학습 상태\n",
    "        self.state = None\n",
    "        self.observation = None\n",
    "        self.steps = 0\n",
    "        self.psnr_sustained_steps = 0\n",
    "\n",
    "        # 학습 데이터셋에서 첫 배치 추출\n",
    "        self.data_iter = iter(self.trainloader)\n",
    "        self.target_image = None\n",
    "\n",
    "    def reset(self, seed=None, options=None, lr=1e-4, z=2e-3):\n",
    "        torch.cuda.empty_cache()\n",
    "        try:\n",
    "            self.target_image = next(self.data_iter)\n",
    "        except StopIteration:\n",
    "            self.data_iter = iter(self.trainloader)\n",
    "            self.target_image = next(self.data_iter)\n",
    "\n",
    "        self.target_image = self.target_image.cuda()\n",
    "        with torch.no_grad():\n",
    "            model_output = self.target_function(self.target_image)\n",
    "        self.observation = model_output.cpu().numpy()  # (1, 8, 1024, 1024)\n",
    "\n",
    "        self.steps = 0\n",
    "        self.psnr_sustained_steps = 0\n",
    "        self.state = (self.observation >= 0.5).astype(np.int8)  # 이진화 상태\n",
    "\n",
    "        binary = torch.tensor(self.state, dtype=torch.float32).cuda()\n",
    "        binary = tt.Tensor(binary, meta={'dx': (7.56e-6, 7.56e-6), 'wl': 515e-9})  # meta 정보 포함\n",
    "\n",
    "        # 시뮬레이션\n",
    "        sim = tt.simulate(binary, z).abs()**2\n",
    "        result = torch.mean(sim, dim=1, keepdim=True)\n",
    "\n",
    "        # MSE 및 PSNR 계산\n",
    "        mse = tt.relativeLoss(result, self.target_image, F.mse_loss).detach().cpu().numpy()\n",
    "        psnr = tt.relativeLoss(result, self.target_image, tm.get_PSNR)\n",
    "\n",
    "        current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        print(f\"Initial MSE: {mse:.6f}, Initial PSNR: {psnr:.6f}, {current_time}\")\n",
    "\n",
    "        mask = self.create_action_mask(self.observation)\n",
    "        return self.observation, {\"state\": self.state, \"mask\": mask}\n",
    "\n",
    "\n",
    "    def initialize_state(self, z=2e-3):\n",
    "        \"\"\"\n",
    "        초기 상태를 생성하고, 시뮬레이션 및 관련 값을 계산합니다.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            model_output = self.target_function(self.target_image)\n",
    "        self.observation = model_output.cpu().numpy()  # (1, 8, 1024, 1024)\n",
    "\n",
    "        self.state = (self.observation >= 0.5).astype(np.int8)  # 이진화 상태\n",
    "\n",
    "        binary = torch.tensor(self.state, dtype=torch.float32).cuda()\n",
    "        binary = tt.Tensor(binary, meta={'dx': (7.56e-6, 7.56e-6), 'wl': 515e-9})  # meta 정보 포함\n",
    "\n",
    "        # 시뮬레이션\n",
    "        sim = tt.simulate(binary, z).abs()**2\n",
    "        result = torch.mean(sim, dim=1, keepdim=True)\n",
    "\n",
    "        # MSE 및 PSNR 계산\n",
    "        mse = tt.relativeLoss(result, self.target_image, F.mse_loss).detach().cpu().numpy()\n",
    "        psnr = tt.relativeLoss(result, self.target_image, tm.get_PSNR)\n",
    "\n",
    "        print(f\"Initial MSE: {mse:.6f}, Initial PSNR: {psnr:.6f}, {current_date}\")\n",
    "\n",
    "        # 관찰값 업데이트\n",
    "        self.observation = result.detach().cpu().numpy()\n",
    "        mask = self.create_action_mask(self.observation)\n",
    "\n",
    "        return self.observation, {\"state\": self.state, \"mask\": mask}\n",
    "\n",
    "    def step(self, action, lr=1e-4, z=2e-3):\n",
    "        # 첫 스텝에서 초기 상태와 동일한 행동 적용\n",
    "        if self.steps == 0:\n",
    "            print(\"Executing reset logic for the first step\")\n",
    "            self.steps += 1  # 스텝 증가\n",
    "            # reset과 동일한 로직을 호출해 초기 상태 생성\n",
    "            observation, info = self.initialize_state(z)\n",
    "            return observation, 0.0, False, False, info\n",
    "\n",
    "        # 현재 상태에 행동을 적용하여 새로운 상태 생성\n",
    "        new_state = np.logical_xor(self.state, action).astype(np.int8)\n",
    "\n",
    "        # 이진화된 새로운 상태를 torch 텐서로 변환\n",
    "        binary = torch.tensor(new_state, dtype=torch.float32).cuda()\n",
    "        binary = tt.Tensor(binary, meta={'dx': (7.56e-6, 7.56e-6), 'wl': 515e-9})  # meta 정보 포함\n",
    "\n",
    "        # 시뮬레이션 수행\n",
    "        sim = tt.simulate(binary, z).abs()**2\n",
    "        result = torch.mean(sim, dim=1, keepdim=True)\n",
    "\n",
    "        # MSE 및 PSNR 계산\n",
    "        mse = tt.relativeLoss(result, self.target_image, F.mse_loss).detach().cpu().numpy()\n",
    "        psnr = tt.relativeLoss(result, self.target_image, tm.get_PSNR)\n",
    "        reward = -mse\n",
    "\n",
    "        # 출력 추가\n",
    "        current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        print(f\"Step: {self.steps}, MSE: {mse:.6f}, PSNR: {psnr:.6f}, {current_time}\")\n",
    "\n",
    "        # 상태 업데이트\n",
    "        self.state = new_state\n",
    "        self.observation = self.state  # 관찰값은 항상 상태와 동일\n",
    "\n",
    "        # 종료 조건\n",
    "        terminated = self.steps >= self.max_steps or self.psnr_sustained_steps >= self.T_steps\n",
    "        truncated = self.steps >= self.max_steps\n",
    "\n",
    "        if psnr >= self.T_PSNR:\n",
    "            self.psnr_sustained_steps += 1\n",
    "        else:\n",
    "            self.psnr_sustained_steps = 0\n",
    "\n",
    "        # 행동 마스크 생성\n",
    "        mask = self.create_action_mask(self.observation)\n",
    "        info = {\"mse\": mse, \"psnr\": psnr, \"mask\": mask}\n",
    "\n",
    "        del binary, sim, result\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        self.steps += 1\n",
    "        return self.observation, reward, terminated, truncated, info\n",
    "\n",
    "    def create_action_mask(self, observation):\n",
    "        \"\"\"\n",
    "        관찰값에 따라 행동 마스크 생성.\n",
    "        관찰값이 0~0.2인 경우 -> 행동 0으로 고정.\n",
    "        관찰값이 0.8~1인 경우 -> 행동 1로 고정.\n",
    "        \"\"\"\n",
    "        mask = np.ones_like(observation, dtype=np.int8)  # 기본적으로 모든 행동 가능\n",
    "        mask[observation <= 0.2] = 0  # 관찰값이 0~0.2면 행동 0으로 고정\n",
    "        mask[observation >= 0.8] = 1  # 관찰값이 0.8~1이면 행동 1로 고정\n",
    "        return mask\n",
    "\n",
    "\n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_uniform_(m.weight.data, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight.data, 1)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight.data)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "batch_size = 1\n",
    "target_dir = '/nfs/dataset/DIV2K/DIV2K_train_HR/DIV2K_train_HR/'\n",
    "valid_dir = '/nfs/dataset/DIV2K/DIV2K_valid_HR/DIV2K_valid_HR/'\n",
    "meta = {'wl': (515e-9), 'dx': (7.56e-6, 7.56e-6)}  # 메타 정보\n",
    "padding = 0\n",
    "\n",
    "# Dataset512 클래스 사용\n",
    "train_dataset = Dataset512(target_dir=target_dir, meta=meta, isTrain=True, padding=padding)\n",
    "valid_dataset = Dataset512(target_dir=valid_dir, meta=meta, isTrain=False, padding=padding)\n",
    "\n",
    "# DataLoader 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# BinaryNet 모델 로드\n",
    "model = BinaryNet(num_hologram=8, in_planes=1, convReLU=False, convBN=False,\n",
    "                  poolReLU=False, poolBN=False, deconvReLU=False, deconvBN=False).cuda()\n",
    "model.load_state_dict(torch.load('result_v/2024-12-15 14:02:27.770108_pre_reinforce_8_0.002/2024-12-15 14:02:27.770108_pre_reinforce_8_0.002'))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# 마스크 함수 정의\n",
    "def mask_fn(env):\n",
    "    return env.create_action_mask(env.observation)\n",
    "\n",
    "# 환경 생성에 새로운 데이터 로더 적용\n",
    "env = BinaryHologramEnv(\n",
    "    target_function=model,\n",
    "    trainloader=train_loader,  # 업데이트된 train_loader 사용\n",
    "    max_steps=100000,\n",
    "    T_PSNR=30,\n",
    "    T_steps=1000\n",
    ")\n",
    "\n",
    "# ActionMasker 래퍼 적용\n",
    "env = ActionMasker(env, mask_fn)\n",
    "\n",
    "# Vectorized 환경 생성\n",
    "venv = make_vec_env(lambda: env, n_envs=1)\n",
    "venv = VecNormalize(venv, norm_obs=True, norm_reward=True, clip_obs=10.0)\n",
    "\n",
    "# PPO 학습\n",
    "ppo_model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    venv,\n",
    "    verbose=2,\n",
    "    n_steps=1024,\n",
    "    batch_size=64,\n",
    "    gamma=0.99,\n",
    "    learning_rate=3e-4,\n",
    "    tensorboard_log=\"./ppo_with_mask/\"\n",
    ")\n",
    "\n",
    "# 모델 저장 경로와 주기 설정\n",
    "save_path = f\"./ppo_checkpoints_{current_date}\"\n",
    "save_freq = 100  # 예: 매 100 스텝마다 저장\n",
    "\n",
    "# 콜백 인스턴스 생성\n",
    "save_callback = SaveOnStepCallback(save_freq=save_freq, save_path=save_path, verbose=1)\n",
    "\n",
    "# PPO 모델 학습 시작\n",
    "ppo_model.learn(total_timesteps=10000000, callback=save_callback)\n",
    "\n",
    "\n",
    "# 모델 저장\n",
    "ppo_model.save(f\"ppo_with_mask_{current_date}\")\n",
    "\n",
    "# VecNormalize 저장\n",
    "\n",
    "# VecNormalize 저장\n",
    "venv.save(f\"ppo_with_mask_{current_date}_vecnormalize.pkl\")\n",
    "\n",
    "\n",
    "# 평가용 환경 생성\n",
    "#eval_env = make_vec_env(lambda: env, n_envs=1)\n",
    "\n",
    "# EvalCallback 추가\n",
    "#eval_callback = EvalCallback(\n",
    "#    eval_env,\n",
    "#    best_model_save_path='./logs/',\n",
    "#    log_path='./logs/',\n",
    "#    eval_freq=10000,  # 평가 빈도 (타임스텝 기준)\n",
    "#    deterministic=True,\n",
    "#    render=False\n",
    "#)\n",
    "\n",
    "#ppo_model = PPO(\n",
    "#    \"MlpPolicy\",\n",
    "#    venv,\n",
    "#    verbose=2,\n",
    "#    n_steps=1024,\n",
    "#    batch_size=64,\n",
    "#    gamma=0.99,\n",
    "#    learning_rate=3e-4,\n",
    "#    tensorboard_log=\"./ppo_with_mask/\"\n",
    "#)\n",
    "\n",
    "# 학습 시작 (콜백 추가)\n",
    "#ppo_model.learn(total_timesteps=10000000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dd0c83-99b3-4f86-bc23-89c6b278e3ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e105c7a2-bd3a-440c-9ad3-3ec9a08af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
