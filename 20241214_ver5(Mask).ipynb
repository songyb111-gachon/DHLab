{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d7d6156-1a3c-4d16-8a80-26491908ed6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/kornia/feature/lightglue.py:30: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import torchOptics.optics as tt\n",
    "import warnings\n",
    "import torch.nn as nn\n",
    "import torchOptics.metrics as tm\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torchvision\n",
    "import datetime\n",
    "import tqdm\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class SignFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        t = torch.Tensor([0.5]).to(input.device)  # threshold\n",
    "        output = (input > t).float() * 1\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output * torch.ones_like(input)  # Replace with your custom gradient computation\n",
    "        return grad_input\n",
    "\n",
    "class RealSign(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        output = torch.sign(input)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output * torch.ones_like(input)  # Replace with your custom gradient computation\n",
    "        return grad_input\n",
    "\n",
    "\n",
    "class Dataset512(Dataset):\n",
    "    def __init__(self, target_dir, meta, transform=None, isTrain=True, padding=0):\n",
    "        self.target_dir = target_dir\n",
    "        self.transform = transform\n",
    "        self.meta = meta\n",
    "        self.isTrain = isTrain\n",
    "        self.target_list = sorted(glob.glob(target_dir+'*.png'))\n",
    "        self.center_crop = torchvision.transforms.CenterCrop(1024)\n",
    "        self.random_crop = torchvision.transforms.RandomCrop((1024, 1024))\n",
    "        self.padding = padding\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        target = tt.imread(self.target_list[idx], meta=meta, gray=True).unsqueeze(0)\n",
    "        if target.shape[-1] < 1024 or target.shape[-2] < 1024:\n",
    "            target = torchvision.transforms.Resize(1024)(target)\n",
    "        if self.isTrain:\n",
    "            target = self.random_crop(target)\n",
    "            target = torchvision.transforms.functional.pad(target, (self.padding, self.padding, self.padding, self.padding))\n",
    "        else:\n",
    "            target = self.center_crop(target)\n",
    "            target = torchvision.transforms.functional.pad(target, (self.padding, self.padding, self.padding, self.padding))\n",
    "        return target\n",
    "\n",
    "\n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_uniform_(m.weight.data, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight.data, 1)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight.data)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "# load data\n",
    "batch_size = 1\n",
    "# target_dir = 'dataset/DIV2K/DIV2K_train_HR/'\n",
    "# valid_dir = 'dataset/DIV2K/DIV2K_valid_HR/'\n",
    "target_dir = '/nfs/dataset/DIV2K/DIV2K_train_HR/DIV2K_train_HR/'\n",
    "valid_dir = '/nfs/dataset/DIV2K/DIV2K_valid_HR/DIV2K_valid_HR/'\n",
    "# sim_dir = 'binary_dataset/simulated/'\n",
    "meta = {'wl' : (515e-9), 'dx':(7.56e-6, 7.56e-6)}\n",
    "padding = 0\n",
    "train_dataset = Dataset512(target_dir=target_dir, meta=meta, isTrain=True, padding=padding)\n",
    "valid_dataset = Dataset512(target_dir=valid_dir, meta=meta, isTrain=False, padding=padding)\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "validloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_uniform_(m.weight.data, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight.data, 1)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight.data)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "\n",
    "def train(model, num_hologram=10, custom_name='fcn', epochs=100, lr=1e-4, z=2e-3):\n",
    "    date = datetime.datetime.now() - datetime.timedelta(hours=15)\n",
    "    mean_psnr_list = []\n",
    "    mean_mse_list = []\n",
    "    max_epoch = 0\n",
    "    max_psnr = 0\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    sign_function = SignFunction.apply\n",
    "    # path = 'models/'\n",
    "    model_name = f'{date}_{custom_name}_{num_hologram}_{z}'\n",
    "    # make result folder\n",
    "    result_folder = 'result/'+model_name\n",
    "    os.mkdir(result_folder)\n",
    "    model_path = os.path.join(result_folder, model_name)\n",
    "    psnr_result_path = os.path.join(result_folder, 'meanPSNR.npy')\n",
    "    mse_result_path = os.path.join(result_folder, 'meanMSE.npy')\n",
    "    result = {'model_path': model_path, 'psnr_result_path': psnr_result_path,\n",
    "          'mse_result_path': mse_result_path, 'z': z,\n",
    "          'num_hologram': num_hologram, 'lr': lr, 'epochs': epochs}\n",
    "    # save result dict\n",
    "    with open(os.path.join(result_folder, 'result_dict.pickle'), 'wb') as fw:\n",
    "        pickle.dump(result, fw)\n",
    "    for epoch in range(epochs):\n",
    "        pbar = tqdm.tqdm(trainloader)\n",
    "        model.train()\n",
    "        for target in pbar:\n",
    "            out = model(target)\n",
    "            binary = sign_function(out)\n",
    "            sim = tt.simulate(binary, z).abs()**2\n",
    "            result = torch.mean(sim, dim=1, keepdim=True)\n",
    "            loss = tt.relativeLoss(result, target, F.mse_loss)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            psnrList = []\n",
    "            mseList = []\n",
    "            for valid in validloader:\n",
    "                out = model(valid)\n",
    "                binary = sign_function(out)\n",
    "                sim = tt.simulate(binary, z).abs()**2\n",
    "                result = torch.mean(sim, dim=1, keepdim=True)\n",
    "                psnr = tt.relativeLoss(result, valid, tm.get_PSNR)\n",
    "                psnrList.append(psnr)\n",
    "                mse = tt.relativeLoss(result, valid, F.mse_loss).detach().cpu().numpy()\n",
    "                mseList.append(mse)\n",
    "            mean_psnr = sum(psnrList)/len(psnrList)\n",
    "            mean_mse = sum(mseList)/len(mseList)\n",
    "            mean_psnr_list.append(mean_psnr)\n",
    "            mean_mse_list.append(mean_mse)\n",
    "            # save psnr and mse\n",
    "            np.save(psnr_result_path, mean_psnr_list)\n",
    "            np.save(mse_result_path, mean_mse_list)\n",
    "            plt.plot(np.arange(len(mean_psnr_list)), mean_psnr_list,\n",
    "                     label=f'max psnr: {max(mean_psnr_list)}')\n",
    "            plt.title(model_name+'_psnr')\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(result_folder, 'meanPSNR.png'))\n",
    "            plt.clf()\n",
    "            plt.plot(np.arange(len(mean_mse_list)), mean_mse_list,\n",
    "                     label=f'max psnr: {min(mean_mse_list)}')\n",
    "            plt.title(model_name+'_mse')\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(result_folder, 'meanMSE.png'))\n",
    "            plt.clf()\n",
    "            print(f'mean PSNR : {mean_psnr} {epoch}/{epochs}')\n",
    "            print(f'mean MSE : {mean_mse} {epoch}/{epochs}')\n",
    "\n",
    "        if mean_psnr > max_psnr:\n",
    "            max_psnr = mean_psnr\n",
    "            max_epoch = epoch\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        print(f'max_psnr: {max_psnr}, epoch: {max_epoch}')\n",
    "\n",
    "\n",
    "def binary_sim(out, z=2e-3):\n",
    "    binary = SignFunction.apply(out)\n",
    "    sim = tt.simulate(binary, z).abs()**2\n",
    "    res = torch.mean(sim, dim=1, keepdim=True)\n",
    "    return binary, res\n",
    "\n",
    "\n",
    "def valid(model):\n",
    "    with torch.no_grad():\n",
    "        psnr_list = []\n",
    "        for target in validloader:\n",
    "            out = model(target)\n",
    "            binary, res = binary_sim(out)\n",
    "            psnr = tt.relativeLoss(res, target, tm.get_PSNR)\n",
    "            psnr_list.append(psnr)\n",
    "    print(sum(psnr_list)/len(psnr_list))\n",
    "\n",
    "\n",
    "def check_order(bmodel, classifier, target):\n",
    "    if len(target.shape) == 3:\n",
    "        target = target.unsqueeze(0)\n",
    "    result = []\n",
    "    with torch.no_grad():\n",
    "        out = bmodel(target)\n",
    "        binary, res = binary_sim(out)\n",
    "        for i in range(10):\n",
    "            binary_input = binary[0][i].unsqueeze(0).unsqueeze(0)\n",
    "            prop_order = classifier(binary_input)\n",
    "            result.append(torch.argmax(prop_order))\n",
    "    print(result)\n",
    "\n",
    "\n",
    "def check_order_without_model(binary, classifier):\n",
    "    with torch.no_grad():\n",
    "        result = []\n",
    "        for i in range(10):\n",
    "            binary_input = binary[0][i].unsqueeze(0).unsqueeze(0)\n",
    "            prop_order = classifier(binary_input)\n",
    "            result.append(torch.argmax(prop_order))\n",
    "    print(result)\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc = nn.Linear(64 * 64 * 64, 10)  # 최종 분류를 위한 FC 레이어\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(torch.relu(self.conv1(x)))\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))\n",
    "        x = self.pool3(torch.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 64 * 64)  # flatten\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def rgb_binary_sim(out, z, th):\n",
    "    pixel_pitch = 7.56e-6\n",
    "    meta = {'wl' : (638e-9, 515e-9, 450e-9), 'dx':(pixel_pitch, pixel_pitch)}\n",
    "    rmeta = {'wl': (638e-9), 'dx': (pixel_pitch, pixel_pitch)}\n",
    "    gmeta = {'wl': (515e-9), 'dx': (pixel_pitch, pixel_pitch)}\n",
    "    bmeta = {'wl': (450e-9), 'dx': (pixel_pitch, pixel_pitch)}\n",
    "    sign = SignFunction.apply\n",
    "    binary = sign(out, th)\n",
    "    channel = out.shape[1]\n",
    "    rchannel = int(channel/3)\n",
    "    gchannel = int(channel*2/3)\n",
    "    red = binary[:, :rchannel, :, :]\n",
    "    green = binary[:, rchannel:gchannel, :, :]\n",
    "    blue = binary[:, gchannel:, :, :]\n",
    "    red = tt.Tensor(red, meta=rmeta)\n",
    "    green = tt.Tensor(green, meta=gmeta)\n",
    "    blue = tt.Tensor(blue, meta=bmeta)\n",
    "    rsim = tt.simulate(red, z).abs()**2\n",
    "    gsim = tt.simulate(green, z).abs()**2\n",
    "    bsim = tt.simulate(blue, z).abs()**2\n",
    "    rmean = torch.mean(rsim, dim=1, keepdim=True)\n",
    "    gmean = torch.mean(gsim, dim=1, keepdim=True)\n",
    "    bmean = torch.mean(bsim, dim=1, keepdim=True)\n",
    "    rgb = torch.cat([rmean, gmean, bmean], dim=1)\n",
    "    rgb = tt.Tensor(rgb, meta=meta)\n",
    "    binary = tt.Tensor(binary, meta=meta)\n",
    "    return binary, rgb\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1eeb963-4afb-4fa4-b6ed-d79b9f080c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "class BinaryNet(nn.Module):\n",
    "    def __init__(self, num_hologram, final='Sigmoid', in_planes=3,\n",
    "                 channels=[32, 64, 128, 256, 512, 1024, 2048, 4096],\n",
    "                 convReLU=True, convBN=True, poolReLU=True, poolBN=True,\n",
    "                 deconvReLU=True, deconvBN=True):\n",
    "        super(BinaryNet, self).__init__()\n",
    "\n",
    "        def CRB2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True, relu=True, bn=True):\n",
    "            layers = []\n",
    "            layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                 kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                                 bias=bias)]\n",
    "            if relu:\n",
    "                layers += [nn.Tanh()]\n",
    "            if bn:\n",
    "                layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "\n",
    "            cbr = nn.Sequential(*layers) # *으로 list unpacking \n",
    "\n",
    "            return cbr\n",
    "\n",
    "        def TRB2d(in_channels, out_channels, kernel_size=2, stride=2, bias=True, relu=True, bn=True):\n",
    "            layers = []\n",
    "            layers += [nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                          kernel_size=2, stride=2, padding=0,\n",
    "                                          bias=True)]\n",
    "            if bn:\n",
    "                layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "            if relu:\n",
    "                layers += [nn.ReLU()]\n",
    "\n",
    "            cbr = nn.Sequential(*layers) # *으로 list unpacking \n",
    "\n",
    "            return cbr\n",
    "\n",
    "        self.enc1_1 = CRB2d(in_planes, channels[0], relu=convReLU, bn=convBN)\n",
    "        self.enc1_2 = CRB2d(channels[0], channels[0], relu=convReLU, bn=convBN)\n",
    "        self.pool1 = CRB2d(channels[0], channels[0], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc2_1 = CRB2d(channels[0], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.enc2_2 = CRB2d(channels[1], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.pool2 = CRB2d(channels[1], channels[1], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc3_1 = CRB2d(channels[1], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.enc3_2 = CRB2d(channels[2], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.pool3 = CRB2d(channels[2], channels[2], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc4_1 = CRB2d(channels[2], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.enc4_2 = CRB2d(channels[3], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.pool4 = CRB2d(channels[3], channels[3], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc5_1 = CRB2d(channels[3], channels[4], relu=convReLU, bn=convBN)\n",
    "        self.enc5_2 = CRB2d(channels[4], channels[4], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv4 = TRB2d(channels[4], channels[3], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec4_1 = CRB2d(channels[4], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.dec4_2 = CRB2d(channels[3], channels[3], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv3 = TRB2d(channels[3], channels[2], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec3_1 = CRB2d(channels[3], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.dec3_2 = CRB2d(channels[2], channels[2], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv2 = TRB2d(channels[2], channels[1], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec2_1 = CRB2d(channels[2], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.dec2_2 = CRB2d(channels[1], channels[1], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv1 = TRB2d(channels[1], channels[0], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec1_1 = CRB2d(channels[1], channels[0], relu=convReLU, bn=convBN)\n",
    "        self.dec1_2 = CRB2d(channels[0], channels[0], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.classifier = CRB2d(channels[0], num_hologram, relu=False, bn=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1_1 = self.enc1_1(x)\n",
    "        enc1_2 = self.enc1_2(enc1_1)\n",
    "        pool1 = self.pool1(enc1_2)\n",
    "\n",
    "        enc2_1 = self.enc2_1(pool1)\n",
    "        enc2_2 = self.enc2_2(enc2_1)\n",
    "        pool2 = self.pool2(enc2_2)\n",
    "\n",
    "        enc3_1 = self.enc3_1(pool2)\n",
    "        enc3_2 = self.enc3_2(enc3_1)\n",
    "        pool3 = self.pool3(enc3_2)\n",
    "\n",
    "        enc4_1 = self.enc4_1(pool3)\n",
    "        enc4_2 = self.enc4_2(enc4_1)\n",
    "        pool4 = self.pool4(enc4_2)\n",
    "\n",
    "        enc5_1 = self.enc5_1(pool4)\n",
    "        enc5_2 = self.enc5_2(enc5_1)\n",
    "\n",
    "        deconv4 = self.deconv4(enc5_2)\n",
    "        concat4 = torch.cat((deconv4, enc4_2), dim=1)\n",
    "        dec4_1 = self.dec4_1(concat4)\n",
    "        dec4_2 = self.dec4_2(dec4_1)\n",
    "\n",
    "        deconv3 = self.deconv3(dec4_2)\n",
    "        concat3 = torch.cat((deconv3, enc3_2), dim=1)\n",
    "        dec3_1 = self.dec3_1(concat3)\n",
    "        dec3_2 = self.dec3_2(dec3_1)\n",
    "\n",
    "        deconv2 = self.deconv2(dec3_2)\n",
    "        concat2 = torch.cat((deconv2, enc2_2), dim=1)\n",
    "        dec2_1 = self.dec2_1(concat2)\n",
    "        dec2_2 = self.dec2_2(dec2_1)\n",
    "\n",
    "        deconv1 = self.deconv1(dec2_2)\n",
    "        concat1 = torch.cat((deconv1, enc1_2), dim=1)\n",
    "        dec1_1 = self.dec1_1(concat1)\n",
    "        dec1_2 = self.dec1_2(dec1_1)\n",
    "\n",
    "        # Final classifier\n",
    "        out = self.classifier(dec1_2)\n",
    "        out = nn.Sigmoid()(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = BinaryNet(num_hologram=8, in_planes=1, convReLU=False,\n",
    "                  convBN=False, poolReLU=False, poolBN=False,\n",
    "                  deconvReLU=False, deconvBN=False).cuda()\n",
    "test = torch.randn(1, 1, 1024, 1024).cuda()\n",
    "out = model(test)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cce810b8-6c1f-4f2f-a856-6b77320f9de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_binary_train_padding(model, num_hologram=24, custom_name='0703Unet', epochs=500, lr=1e-4, z=2e-3):\n",
    "    date = datetime.datetime.now() - datetime.timedelta(hours=15)\n",
    "    model.apply(initialize_weights)\n",
    "    mean_psnr_list = []\n",
    "    mean_mse_list = []\n",
    "    max_epoch = 0\n",
    "    max_psnr = 0\n",
    "    crop = torchvision.transforms.CenterCrop(896)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    sign = SignFunction.apply\n",
    "    # path = 'models/'\n",
    "    model_name = f'{date}_{custom_name}_{num_hologram}_{z}'\n",
    "    # make result folder\n",
    "    result_folder = 'result/'+model_name\n",
    "    os.mkdir(result_folder)\n",
    "    num_parameters = count_parameters(model)\n",
    "    model_path = os.path.join(result_folder, model_name)\n",
    "    psnr_result_path = os.path.join(result_folder, 'meanPSNR.npy')\n",
    "    mse_result_path = os.path.join(result_folder, 'meanMSE.npy')\n",
    "    result = {'model_path': model_path, 'psnr_result_path': psnr_result_path,\n",
    "          'mse_result_path': mse_result_path, 'z': z,\n",
    "          'num_hologram': num_hologram, 'lr': lr, 'epochs': epochs,\n",
    "            'num_parameters': num_parameters}\n",
    "    # save result dict\n",
    "    with open(os.path.join(result_folder, 'result_dict.pickle'), 'wb') as fw:\n",
    "        pickle.dump(result, fw)\n",
    "    for epoch in range(epochs):\n",
    "        pbar = tqdm.tqdm(trainloader)\n",
    "        model.train()\n",
    "        for target in pbar:\n",
    "            target = target\n",
    "            out = model(target)\n",
    "            binary = sign(out)\n",
    "            sim = tt.simulate(binary, 2e-3).abs()**2\n",
    "            mean_sim = torch.mean(sim, dim=1, keepdim=True)\n",
    "            rgb = crop(mean_sim)\n",
    "            croped_target = crop(target)\n",
    "            loss = tt.relativeLoss(rgb, croped_target, F.mse_loss)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            psnrList = []\n",
    "            mseList = []\n",
    "            for idx, valid in enumerate(validloader):\n",
    "                valid = valid\n",
    "                out = model(valid)\n",
    "                binary = sign(out)\n",
    "                sim = tt.simulate(binary, 2e-3).abs()**2\n",
    "                mean_sim = torch.mean(sim, dim=1, keepdim=True)\n",
    "                rgb = crop(mean_sim)\n",
    "                croped_target = crop(valid)\n",
    "                psnr = tt.relativeLoss(rgb, croped_target, tm.get_PSNR)\n",
    "                psnrList.append(psnr)\n",
    "                mse = tt.relativeLoss(rgb, croped_target, F.mse_loss).detach().cpu().numpy()\n",
    "                mseList.append(mse)\n",
    "                if idx == 0:\n",
    "                    pl = tt.show_with_insets(rgb, croped_target, correct_colorwise=True)\n",
    "                    pl.save(os.path.join(result_folder, 'penguin.png'))\n",
    "            mean_psnr = sum(psnrList)/len(psnrList)\n",
    "            mean_mse = sum(mseList)/len(mseList)\n",
    "            mean_psnr_list.append(mean_psnr)\n",
    "            mean_mse_list.append(mean_mse)\n",
    "            # save psnr and mse\n",
    "            if epoch % 10 == 0:\n",
    "                np.save(psnr_result_path, mean_psnr_list)\n",
    "                np.save(mse_result_path, mean_mse_list)\n",
    "                plt.plot(np.arange(len(mean_psnr_list)), mean_psnr_list,\n",
    "                         label=f'max psnr: {max(mean_psnr_list)}')\n",
    "                plt.title(model_name+'_psnr')\n",
    "                plt.legend()\n",
    "                plt.savefig(os.path.join(result_folder, 'meanPSNR.png'))\n",
    "                plt.clf()\n",
    "                plt.plot(np.arange(len(mean_mse_list)), mean_mse_list,\n",
    "                         label=f'max psnr: {min(mean_mse_list)}')\n",
    "                plt.title(model_name+'_mse')\n",
    "                plt.legend()\n",
    "                plt.savefig(os.path.join(result_folder, 'meanMSE.png'))\n",
    "                plt.clf()\n",
    "            print(f'mean PSNR : {mean_psnr} {epoch}/{epochs}')\n",
    "            print(f'mean MSE : {mean_mse} {epoch}/{epochs}')\n",
    "\n",
    "        if mean_psnr > max_psnr:\n",
    "            max_psnr = mean_psnr\n",
    "            max_epoch = epoch\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        print(f'max_psnr: {max_psnr}, epoch: {max_epoch}')\n",
    "        print(f'Model saved at: {model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ed95b01-acaa-4898-82bb-05d549d2de85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 1024])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e26a3c0d-cb1f-4516-ac08-56afa736ecb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [1, 1, 1, 1024, 1024]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m sign \u001b[38;5;241m=\u001b[39m SignFunction\u001b[38;5;241m.\u001b[39mapply\n\u001b[0;32m----> 2\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m binary \u001b[38;5;241m=\u001b[39m sign(out, \u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m      4\u001b[0m sim \u001b[38;5;241m=\u001b[39m tt\u001b[38;5;241m.\u001b[39msimulate(binary, \u001b[38;5;241m2e-3\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 75\u001b[0m, in \u001b[0;36mBinaryNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m# Encoder\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m     enc1_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menc1_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     enc1_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc1_2(enc1_1)\n\u001b[1;32m     77\u001b[0m     pool1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool1(enc1_2)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/songyb111/torchOptics/optics.py:92\u001b[0m, in \u001b[0;36m_complex_not_implemented.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexToEnd(r)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/home/songyb111/torchOptics/optics.py:77\u001b[0m, in \u001b[0;36m_complex_not_implemented.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 77\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot implemented\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m/home/songyb111/torchOptics/optics.py:162\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;129m@_complex_not_implemented\u001b[39m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__torch_function__\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, types, args\u001b[38;5;241m=\u001b[39m(), kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 162\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(r, Tensor) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta:\n\u001b[1;32m    164\u001b[0m         r\u001b[38;5;241m.\u001b[39mmeta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py:1437\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1434\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1436\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m-> 1437\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1438\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1439\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [1, 1, 1, 1024, 1024]"
     ]
    }
   ],
   "source": [
    "sign = SignFunction.apply\n",
    "out = model(valid_dataset[0].unsqueeze(0).unsqueeze(0))\n",
    "binary = sign(out, 0.5)\n",
    "sim = tt.simulate(binary, 2e-3)\n",
    "mean_sim = torch.mean(sim, dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7e4818-79c2-459d-8a18-d17564f613f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in trainloader:\n",
    "    print(target.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea4334c4-82e6-43c1-b516-e68cd3992175",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtarget\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'target' is not defined"
     ]
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84c5ec99-e9aa-43db-8cd8-51cb219fb07b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_sim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmean_sim\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean_sim' is not defined"
     ]
    }
   ],
   "source": [
    "mean_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b907fbe1-9557-4bb4-a3c8-41410564205a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/overrides.py:1641: DeprecationWarning: Defining your `__torch_function__ as a plain method is deprecated and will be an error in future, please define it as a classmethod.\n",
      "  warnings.warn(\"Defining your `__torch_function__ as a plain method is deprecated and \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Logging to ./ppo_maskable_mlp/PPO_2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Environment does not support action masking. Consider using ActionMasker wrapper",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 162\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# MaskablePPO 모델 설정 및 학습\u001b[39;00m\n\u001b[1;32m    152\u001b[0m maskable_ppo_model \u001b[38;5;241m=\u001b[39m MaskablePPO(\n\u001b[1;32m    153\u001b[0m     policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# 기본 MLP 정책\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     env\u001b[38;5;241m=\u001b[39mvenv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m     tensorboard_log\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./ppo_maskable_mlp/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    161\u001b[0m )\n\u001b[0;32m--> 162\u001b[0m \u001b[43mmaskable_ppo_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# 학습된 모델 저장\u001b[39;00m\n\u001b[1;32m    165\u001b[0m maskable_ppo_model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaskable_ppo_binary_hologram_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sb3_contrib/ppo_mask/ppo_mask.py:454\u001b[0m, in \u001b[0;36mMaskablePPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, use_masking, progress_bar)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 454\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_masking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[1;32m    457\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sb3_contrib/ppo_mask/ppo_mask.py:217\u001b[0m, in \u001b[0;36mMaskablePPO.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps, use_masking)\u001b[0m\n\u001b[1;32m    214\u001b[0m rollout_buffer\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_masking \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_masking_supported(env):\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnvironment does not support action masking. Consider using ActionMasker wrapper\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    219\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_rollout_start()\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n_steps \u001b[38;5;241m<\u001b[39m n_rollout_steps:\n",
      "\u001b[0;31mValueError\u001b[0m: Environment does not support action masking. Consider using ActionMasker wrapper"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "from sb3_contrib import MaskablePPO\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import torchOptics.optics as tt\n",
    "import torch.nn as nn\n",
    "import torchOptics.metrics as tm\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CuDNN 비활성화\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "# 현재 날짜와 시간을 가져와 포맷 지정\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# 간단한 데이터셋 클래스\n",
    "class SimpleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, target_dir, meta, transform=None, isTrain=True, padding=0):\n",
    "        self.target_list = sorted(glob.glob(target_dir + '*.png'))\n",
    "        self.meta = meta\n",
    "        self.transform = transform\n",
    "        self.isTrain = isTrain\n",
    "        self.padding = padding\n",
    "        self.random_crop = transforms.RandomCrop((1024, 1024))\n",
    "        self.center_crop = transforms.CenterCrop(1024)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = tt.imread(self.target_list[idx], meta=self.meta, gray=True).unsqueeze(0)\n",
    "        if img.shape[-2] < 1024 or img.shape[-1] < 1024:\n",
    "            img = transforms.Resize((1024, 1024))(img)\n",
    "        img = self.random_crop(img) if self.isTrain else self.center_crop(img)\n",
    "        img = transforms.functional.pad(img, (self.padding,) * 4)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "# 사용자 정의 ActionMasker\n",
    "class ActionMasker(gym.Wrapper):\n",
    "    def __init__(self, env, mask_func):\n",
    "        super().__init__(env)\n",
    "        self.mask_func = mask_func\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        obs = self.env.reset(**kwargs)\n",
    "        self.current_mask = self.mask_func(self.env)\n",
    "        return obs, {\"mask\": self.current_mask}\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, truncated, info = self.env.step(action)\n",
    "        self.current_mask = self.mask_func(self.env)\n",
    "        info[\"mask\"] = self.current_mask\n",
    "        return obs, reward, done, truncated, info\n",
    "\n",
    "# BinaryHologramEnv 클래스\n",
    "class BinaryHologramEnv(gym.Env):\n",
    "    def __init__(self, target_function, trainloader, max_steps=1000000, T_PSNR=30, T_steps=100):\n",
    "        super(BinaryHologramEnv, self).__init__()\n",
    "        # 관찰 공간: (1, 8, 1024, 1024)\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(1, 8, 1024, 1024), dtype=np.float32)\n",
    "        # 행동 공간: MultiBinary 데이터\n",
    "        self.action_space = spaces.MultiBinary(1 * 8 * 1024 * 1024)\n",
    "        self.target_function = target_function\n",
    "        self.trainloader = trainloader\n",
    "        self.max_steps = max_steps\n",
    "        self.T_PSNR = T_PSNR\n",
    "        self.T_steps = T_steps\n",
    "        self.data_iter = iter(self.trainloader)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        try:\n",
    "            self.target_image = next(self.data_iter)\n",
    "        except StopIteration:\n",
    "            self.data_iter = iter(self.trainloader)\n",
    "            self.target_image = next(self.data_iter)\n",
    "\n",
    "        self.target_image = self.target_image.cuda()\n",
    "        with torch.no_grad():\n",
    "            self.observation = self.target_function(self.target_image).cpu().numpy().reshape(1, 8, 1024, 1024)\n",
    "\n",
    "        self.steps = 0\n",
    "        self.psnr_sustained_steps = 0\n",
    "        return self.observation\n",
    "\n",
    "    def step(self, action, lr=1e-4, z=2e-3):\n",
    "        action = np.reshape(action, (1, 8, 1024, 1024)).astype(np.int8)\n",
    "        binary = action\n",
    "        sim = tt.simulate(binary, z).abs()**2\n",
    "        result = torch.mean(sim, dim=1, keepdim=True)\n",
    "        mse = tt.relativeLoss(result, self.target_image, F.mse_loss).detach().cpu().numpy()\n",
    "        psnr = tt.relativeLoss(result, self.target_image, tm.get_PSNR)\n",
    "        reward = -mse\n",
    "        terminated = False\n",
    "        truncated = self.steps >= self.max_steps\n",
    "        self.steps += 1\n",
    "        if psnr >= self.T_PSNR:\n",
    "            self.psnr_sustained_steps += 1\n",
    "        else:\n",
    "            self.psnr_sustained_steps = 0\n",
    "        if self.psnr_sustained_steps >= self.T_steps:\n",
    "            terminated = True\n",
    "        info = {\"mse\": mse, \"psnr\": psnr, \"psnr_sustained_steps\": self.psnr_sustained_steps}\n",
    "        return self.observation, reward, terminated, truncated, info\n",
    "\n",
    "# ActionMasker를 위한 함수\n",
    "def get_action_mask(env):\n",
    "    # 관찰값에 따라 행동 마스크 생성\n",
    "    observation = env.observation.squeeze()  # (1, 8, 1024, 1024) -> (8, 1024, 1024)\n",
    "    mask = np.ones_like(observation, dtype=np.int8)  # 동일한 모양의 마스크 생성\n",
    "    mask[observation <= 0.2] = 0\n",
    "    mask[observation >= 0.8] = 1\n",
    "    return mask.reshape(-1)  # 행동 공간과 일치하도록 1차원으로 변환\n",
    "\n",
    "# 데이터 로더 생성\n",
    "target_dir = '/nfs/dataset/DIV2K/DIV2K_train_HR/DIV2K_train_HR/'\n",
    "valid_dir = '/nfs/dataset/DIV2K/DIV2K_valid_HR/DIV2K_valid_HR/'\n",
    "meta = {'wl': 515e-9, 'dx': (7.56e-6, 7.56e-6)}\n",
    "padding = 0\n",
    "train_dataset = SimpleDataset(target_dir=target_dir, meta=meta, isTrain=True, padding=padding)\n",
    "valid_dataset = SimpleDataset(target_dir=valid_dir, meta=meta, isTrain=False, padding=padding)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# BinaryNet 모델 로드\n",
    "model = BinaryNet(num_hologram=8, in_planes=1, convReLU=False, convBN=False,\n",
    "                  poolReLU=False, poolBN=False, deconvReLU=False, deconvBN=False).cuda()\n",
    "model.load_state_dict(torch.load('result/2024-12-07 19:38:09.105795_pre_reinforce_8_0.002/2024-12-07 19:38:09.105795_pre_reinforce_8_0.002'))\n",
    "model.eval()\n",
    "\n",
    "# Gym 환경 생성\n",
    "env = BinaryHologramEnv(target_function=model, trainloader=train_loader, max_steps=1000, T_PSNR=30, T_steps=100)\n",
    "env = ActionMasker(env, get_action_mask)\n",
    "\n",
    "# Vectorized 환경 생성\n",
    "venv = make_vec_env(lambda: env, n_envs=1)\n",
    "venv = VecNormalize(venv, norm_obs=True, norm_reward=True, clip_obs=10.0)\n",
    "\n",
    "# MaskablePPO 모델 설정 및 학습\n",
    "maskable_ppo_model = MaskablePPO(\n",
    "    policy=\"MlpPolicy\",  # 기본 MLP 정책\n",
    "    env=venv,\n",
    "    verbose=1,\n",
    "    n_steps=128,\n",
    "    batch_size=64,\n",
    "    gamma=0.99,\n",
    "    learning_rate=3e-4,\n",
    "    tensorboard_log=\"./ppo_maskable_mlp/\",\n",
    ")\n",
    "maskable_ppo_model.learn(total_timesteps=100000)\n",
    "\n",
    "# 학습된 모델 저장\n",
    "maskable_ppo_model.save(f\"maskable_ppo_binary_hologram_{current_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8c9d82-7dbd-4b8d-9110-826a88c50f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "def target_function(state, action):\n",
    "    \"\"\"\n",
    "    타겟 함수: 상태와 행동 간의 MSE를 계산합니다.\n",
    "    \"\"\"\n",
    "    target = state.mean(axis=-1, keepdims=True)\n",
    "    return np.mean((action.mean(axis=-1) - target.squeeze()) ** 2)\n",
    "\n",
    "# 환경 인스턴스 생성\n",
    "env = BinaryHologramEnv(\n",
    "    target_function=target_function,\n",
    "    max_steps=1000000,\n",
    "    T_PSNR=30,\n",
    "    T_steps=100,\n",
    ")\n",
    "\n",
    "# 환경 유효성 확인\n",
    "check_env(env, warn=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc19a437-4845-451b-97f2-d2a25f6b8640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
