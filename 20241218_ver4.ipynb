{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e3bb6ba70918dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T07:50:49.917672Z",
     "start_time": "2024-12-17T07:50:49.704223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 1024, 1024])\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_675050/2791955175.py:320: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('result_v/2024-12-15 14:02:27.770108_pre_reinforce_8_0.002/2024-12-15 14:02:27.770108_pre_reinforce_8_0.002'))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "from sb3_contrib import MaskablePPO\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import torchOptics.optics as tt\n",
    "import torch.nn as nn\n",
    "import torchOptics.metrics as tm\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torchvision\n",
    "import tqdm\n",
    "import time\n",
    "import pandas as pd\n",
    "from sb3_contrib.common.maskable.utils import get_action_masks\n",
    "from sb3_contrib.common.wrappers import ActionMasker  # 수정된 import 경로\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "# 현재 날짜와 시간을 가져와 포맷 지정\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "class BinaryNet(nn.Module):\n",
    "    def __init__(self, num_hologram, final='Sigmoid', in_planes=3,\n",
    "                 channels=[32, 64, 128, 256, 512, 1024, 2048, 4096],\n",
    "                 convReLU=True, convBN=True, poolReLU=True, poolBN=True,\n",
    "                 deconvReLU=True, deconvBN=True):\n",
    "        super(BinaryNet, self).__init__()\n",
    "\n",
    "        def CRB2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True, relu=True, bn=True):\n",
    "            layers = []\n",
    "            layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                 kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                                 bias=bias)]\n",
    "            if relu:\n",
    "                layers += [nn.Tanh()]\n",
    "            if bn:\n",
    "                layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "\n",
    "            cbr = nn.Sequential(*layers)  # *으로 list unpacking\n",
    "\n",
    "            return cbr\n",
    "\n",
    "        def TRB2d(in_channels, out_channels, kernel_size=2, stride=2, bias=True, relu=True, bn=True):\n",
    "            layers = []\n",
    "            layers += [nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                          kernel_size=2, stride=2, padding=0,\n",
    "                                          bias=True)]\n",
    "            if bn:\n",
    "                layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "            if relu:\n",
    "                layers += [nn.ReLU()]\n",
    "\n",
    "            cbr = nn.Sequential(*layers)  # *으로 list unpacking\n",
    "\n",
    "            return cbr\n",
    "\n",
    "        self.enc1_1 = CRB2d(in_planes, channels[0], relu=convReLU, bn=convBN)\n",
    "        self.enc1_2 = CRB2d(channels[0], channels[0], relu=convReLU, bn=convBN)\n",
    "        self.pool1 = CRB2d(channels[0], channels[0], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc2_1 = CRB2d(channels[0], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.enc2_2 = CRB2d(channels[1], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.pool2 = CRB2d(channels[1], channels[1], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc3_1 = CRB2d(channels[1], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.enc3_2 = CRB2d(channels[2], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.pool3 = CRB2d(channels[2], channels[2], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc4_1 = CRB2d(channels[2], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.enc4_2 = CRB2d(channels[3], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.pool4 = CRB2d(channels[3], channels[3], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc5_1 = CRB2d(channels[3], channels[4], relu=convReLU, bn=convBN)\n",
    "        self.enc5_2 = CRB2d(channels[4], channels[4], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv4 = TRB2d(channels[4], channels[3], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec4_1 = CRB2d(channels[4], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.dec4_2 = CRB2d(channels[3], channels[3], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv3 = TRB2d(channels[3], channels[2], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec3_1 = CRB2d(channels[3], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.dec3_2 = CRB2d(channels[2], channels[2], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv2 = TRB2d(channels[2], channels[1], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec2_1 = CRB2d(channels[2], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.dec2_2 = CRB2d(channels[1], channels[1], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv1 = TRB2d(channels[1], channels[0], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec1_1 = CRB2d(channels[1], channels[0], relu=convReLU, bn=convBN)\n",
    "        self.dec1_2 = CRB2d(channels[0], channels[0], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.classifier = CRB2d(channels[0], num_hologram, relu=False, bn=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1_1 = self.enc1_1(x)\n",
    "        enc1_2 = self.enc1_2(enc1_1)\n",
    "        pool1 = self.pool1(enc1_2)\n",
    "\n",
    "        enc2_1 = self.enc2_1(pool1)\n",
    "        enc2_2 = self.enc2_2(enc2_1)\n",
    "        pool2 = self.pool2(enc2_2)\n",
    "\n",
    "        enc3_1 = self.enc3_1(pool2)\n",
    "        enc3_2 = self.enc3_2(enc3_1)\n",
    "        pool3 = self.pool3(enc3_2)\n",
    "\n",
    "        enc4_1 = self.enc4_1(pool3)\n",
    "        enc4_2 = self.enc4_2(enc4_1)\n",
    "        pool4 = self.pool4(enc4_2)\n",
    "\n",
    "        enc5_1 = self.enc5_1(pool4)\n",
    "        enc5_2 = self.enc5_2(enc5_1)\n",
    "\n",
    "        deconv4 = self.deconv4(enc5_2)\n",
    "        concat4 = torch.cat((deconv4, enc4_2), dim=1)\n",
    "        dec4_1 = self.dec4_1(concat4)\n",
    "        dec4_2 = self.dec4_2(dec4_1)\n",
    "\n",
    "        deconv3 = self.deconv3(dec4_2)\n",
    "        concat3 = torch.cat((deconv3, enc3_2), dim=1)\n",
    "        dec3_1 = self.dec3_1(concat3)\n",
    "        dec3_2 = self.dec3_2(dec3_1)\n",
    "\n",
    "        deconv2 = self.deconv2(dec3_2)\n",
    "        concat2 = torch.cat((deconv2, enc2_2), dim=1)\n",
    "        dec2_1 = self.dec2_1(concat2)\n",
    "        dec2_2 = self.dec2_2(dec2_1)\n",
    "\n",
    "        deconv1 = self.deconv1(dec2_2)\n",
    "        concat1 = torch.cat((deconv1, enc1_2), dim=1)\n",
    "        dec1_1 = self.dec1_1(concat1)\n",
    "        dec1_2 = self.dec1_2(dec1_1)\n",
    "\n",
    "        # Final classifier\n",
    "        out = self.classifier(dec1_2)\n",
    "        out = nn.Sigmoid()(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = BinaryNet(num_hologram=8, in_planes=1, convReLU=False,\n",
    "                  convBN=False, poolReLU=False, poolBN=False,\n",
    "                  deconvReLU=False, deconvBN=False).cuda()\n",
    "test = torch.randn(1, 1, 1024, 1024).cuda()\n",
    "out = model(test)\n",
    "print(out.shape)\n",
    "\n",
    "\n",
    "# 간단한 데이터셋 클래스\n",
    "class SimpleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, target_dir, meta, transform=None, isTrain=True, padding=0):\n",
    "        \"\"\"\n",
    "        target_dir: 데이터가 저장된 디렉토리 경로\n",
    "        meta: 이미지 메타 정보\n",
    "        transform: 이미지 전처리\n",
    "        isTrain: 학습용(True) 또는 검증용(False) 데이터셋 여부\n",
    "        padding: 이미지 패딩\n",
    "        \"\"\"\n",
    "        self.target_list = sorted(glob.glob(target_dir + '*.png'))\n",
    "        self.meta = meta\n",
    "        self.transform = transform\n",
    "        self.isTrain = isTrain\n",
    "        self.padding = padding\n",
    "        self.random_crop = transforms.RandomCrop((1024, 1024))\n",
    "        self.center_crop = transforms.CenterCrop(1024)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 이미지 로드\n",
    "        img = tt.imread(self.target_list[idx], meta=self.meta, gray=True).unsqueeze(0)\n",
    "\n",
    "        # 크기 조정\n",
    "        if img.shape[-2] < 1024 or img.shape[-1] < 1024:\n",
    "            img = transforms.Resize((1024, 1024))(img)\n",
    "\n",
    "        # 학습용 랜덤 크롭 또는 검증용 센터 크롭\n",
    "        if self.isTrain:\n",
    "            img = self.random_crop(img)\n",
    "        else:\n",
    "            img = self.center_crop(img)\n",
    "\n",
    "        # 패딩 추가\n",
    "        img = transforms.functional.pad(\n",
    "            img, (self.padding, self.padding, self.padding, self.padding)\n",
    "        )\n",
    "\n",
    "        # 변환 적용 (optional)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img\n",
    "\n",
    "\n",
    "# BinaryHologramEnv 클래스 수정\n",
    "class BinaryHologramEnv(gym.Env):\n",
    "    def __init__(self, target_function, trainloader, meta, max_steps=1000000, T_PSNR=30, T_steps=100):\n",
    "        super(BinaryHologramEnv, self).__init__()\n",
    "\n",
    "        # 관찰 공간 및 행동 공간 설정\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(1, 8, 1024, 1024), dtype=np.float32)\n",
    "        self.action_space = spaces.MultiBinary(1 * 8 * 1024 * 1024)\n",
    "\n",
    "        # 메타 정보 및 시뮬레이션 파라미터\n",
    "        self.meta = meta\n",
    "        self.target_function = target_function  # BinaryNet 모델\n",
    "        self.trainloader = trainloader  # 학습 데이터 로더\n",
    "\n",
    "        # 에피소드 설정\n",
    "        self.max_steps = max_steps\n",
    "        self.T_PSNR = T_PSNR\n",
    "        self.T_steps = T_steps\n",
    "\n",
    "        # 상태 초기화\n",
    "        self.state = None\n",
    "        self.observation = None\n",
    "        self.steps = 0\n",
    "        self.psnr_sustained_steps = 0\n",
    "\n",
    "        # 데이터 로더 초기화\n",
    "        self.data_iter = iter(self.trainloader)\n",
    "        self.target_image = None\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        try:\n",
    "            self.target_image = next(self.data_iter)\n",
    "        except StopIteration:\n",
    "            self.data_iter = iter(self.trainloader)\n",
    "            self.target_image = next(self.data_iter)\n",
    "\n",
    "        self.target_image = self.target_image.cuda()\n",
    "        with torch.no_grad():\n",
    "            self.observation = self.target_function(self.target_image).cpu().numpy()\n",
    "\n",
    "        self.steps = 0\n",
    "        self.psnr_sustained_steps = 0\n",
    "\n",
    "        mask = self.create_action_mask(self.observation)\n",
    "        return self.observation, {\"mask\": mask}\n",
    "\n",
    "    def step(self, action, lr=1e-4, z=2e-3):\n",
    "        with torch.no_grad():\n",
    "            # 행동을 변환\n",
    "            action = np.reshape(action, (1, 8, 1024, 1024)).astype(np.int8)\n",
    "            binary = torch.tensor(action, device=\"cuda\", dtype=torch.float32)\n",
    "    \n",
    "            # simulate 함수 호출에 메타 정보 전달\n",
    "            sim = tt.simulate(binary, z, psize=self.meta['dx'], wl=self.meta['wl']).abs()**2\n",
    "            result = torch.mean(sim, dim=1, keepdim=True)\n",
    "    \n",
    "            # 손실 및 보상 계산\n",
    "            mse = tt.relativeLoss(result, self.target_image, F.mse_loss).detach().cpu().item()\n",
    "            psnr = tt.relativeLoss(result, self.target_image, tm.get_PSNR).cpu().item()\n",
    "            reward = -mse\n",
    "    \n",
    "            # 상태 업데이트\n",
    "            if self.state is None:\n",
    "                self.state = np.zeros_like(action, dtype=np.float32)\n",
    "            self.state = np.logical_xor(self.state, action).astype(np.float32)\n",
    "    \n",
    "        # GPU 메모리 해제\n",
    "        del binary, sim, result\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "        # 종료 조건\n",
    "        terminated = psnr >= self.T_PSNR\n",
    "        truncated = self.steps >= self.max_steps\n",
    "        self.steps += 1\n",
    "    \n",
    "        # 다음 상태의 마스크 생성\n",
    "        mask = self.create_action_mask(self.observation)\n",
    "        info = {\"mse\": mse, \"psnr\": psnr, \"mask\": mask}\n",
    "    \n",
    "        # 관찰값과 상태 결합\n",
    "        combined_observation = np.stack([self.observation, self.state], axis=0).astype(np.float32)\n",
    "        return combined_observation, reward, terminated, truncated, info\n",
    "\n",
    "\n",
    "    def create_action_mask(self, observation):\n",
    "        # 관찰값에 따른 행동 마스크 생성\n",
    "        mask = np.ones_like(observation, dtype=np.int8)\n",
    "        mask[observation <= 0.2] = 0\n",
    "        mask[observation >= 0.8] = 1\n",
    "        return mask\n",
    "\n",
    "\n",
    "# 데이터 로더 생성\n",
    "target_dir = '/nfs/dataset/DIV2K/DIV2K_train_HR/DIV2K_train_HR/'\n",
    "valid_dir = '/nfs/dataset/DIV2K/DIV2K_valid_HR/DIV2K_valid_HR/'\n",
    "meta = {'wl': 515e-9, 'dx': (7.56e-6, 7.56e-6)}  # 메타 정보\n",
    "padding = 0\n",
    "\n",
    "train_dataset = SimpleDataset(target_dir=target_dir, meta=meta, isTrain=True, padding=padding)\n",
    "valid_dataset = SimpleDataset(target_dir=valid_dir, meta=meta, isTrain=False, padding=padding)\n",
    "\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# BinaryNet 모델 로드\n",
    "model = BinaryNet(num_hologram=8, in_planes=1, convReLU=False, convBN=False,\n",
    "                  poolReLU=False, poolBN=False, deconvReLU=False, deconvBN=False).cuda()\n",
    "model.load_state_dict(torch.load('result_v/2024-12-15 14:02:27.770108_pre_reinforce_8_0.002/2024-12-15 14:02:27.770108_pre_reinforce_8_0.002'))\n",
    "model.eval()\n",
    "\n",
    "# 마스크 함수 정의\n",
    "def mask_fn(env):\n",
    "    return env.create_action_mask(env.observation)\n",
    "\n",
    "eta = {'wl': 515e-9, 'dx': (7.56e-6, 7.56e-6)}  # 메타 정보\n",
    "\n",
    "# 환경 생성\n",
    "env = BinaryHologramEnv(\n",
    "    target_function=model,\n",
    "    trainloader=train_loader,\n",
    "    meta=meta,  # 메타 정보 전달\n",
    "    max_steps=1000,\n",
    "    T_PSNR=30,\n",
    "    T_steps=100\n",
    ")\n",
    "\n",
    "# ActionMasker 래퍼 적용\n",
    "env = ActionMasker(env, mask_fn)\n",
    "\n",
    "# Vectorized 환경 생성\n",
    "venv = make_vec_env(lambda: env, n_envs=1)\n",
    "venv = VecNormalize(venv, norm_obs=True, norm_reward=True, clip_obs=10.0)\n",
    "\n",
    "# PPO 모델 설정\n",
    "ppo_model = PPO(\n",
    "    \"MlpPolicy\",  # MLP 정책 사용\n",
    "    venv,\n",
    "    verbose=1,\n",
    "    n_steps=1024,\n",
    "    batch_size=8,\n",
    "    gamma=0.99,\n",
    "    learning_rate=3e-4,\n",
    "    tensorboard_log=\"./ppo_mlp/\"\n",
    ")\n",
    "\n",
    "# 학습 실행\n",
    "ppo_model.learn(total_timesteps=100000)\n",
    "\n",
    "# 모델 저장\n",
    "ppo_model.save(f\"ppo_binary_hologram_{current_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce4522d6afc03b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
