{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c64e8d35-cc9c-4587-b235-2f77939938fd",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/kornia/feature/lightglue.py:30: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /usr/local/lib/python3.8/dist-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torchOptics.optics as tt\n",
    "import warnings\n",
    "import torch.nn as nn\n",
    "import torchOptics.metrics as tm\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torchvision\n",
    "import datetime\n",
    "import tqdm\n",
    "import time\n",
    "import pandas as pd\n",
    "# import HHS.model\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class SignFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        t = torch.Tensor([0.5]).to(input.device)  # threshold\n",
    "        output = (input > t).float() * 1\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output * torch.ones_like(input)  # Replace with your custom gradient computation\n",
    "        return grad_input\n",
    "\n",
    "class RealSign(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        output = torch.sign(input)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output * torch.ones_like(input)  # Replace with your custom gradient computation\n",
    "        return grad_input\n",
    "\n",
    "\n",
    "class Dataset512(Dataset):\n",
    "    def __init__(self, target_dir, meta, transform=None, isTrain=True, padding=0):\n",
    "        self.target_dir = target_dir\n",
    "        self.transform = transform\n",
    "        self.meta = meta\n",
    "        self.isTrain = isTrain\n",
    "        self.target_list = sorted(glob.glob(target_dir+'*.png'))\n",
    "        self.center_crop = torchvision.transforms.CenterCrop(1024)\n",
    "        self.random_crop = torchvision.transforms.RandomCrop((1024, 1024))\n",
    "        self.padding = padding\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        target = tt.imread(self.target_list[idx], meta=meta, gray=True).unsqueeze(0)\n",
    "        if target.shape[-1] < 1024 or target.shape[-2] < 1024:\n",
    "            target = torchvision.transforms.Resize(1024)(target)\n",
    "        if self.isTrain:\n",
    "            target = self.random_crop(target)\n",
    "            target = torchvision.transforms.functional.pad(target, (self.padding, self.padding, self.padding, self.padding))\n",
    "        else:\n",
    "            target = self.center_crop(target)\n",
    "            target = torchvision.transforms.functional.pad(target, (self.padding, self.padding, self.padding, self.padding))\n",
    "        return target\n",
    "\n",
    "\n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_uniform_(m.weight.data, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight.data, 1)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight.data)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "# load data\n",
    "batch_size = 1\n",
    "# target_dir = 'dataset/DIV2K/DIV2K_train_HR/'\n",
    "# valid_dir = 'dataset/DIV2K/DIV2K_valid_HR/'\n",
    "target_dir = '/nfs/dataset/DIV2K/DIV2K_train_HR/DIV2K_train_HR/'\n",
    "valid_dir = '/nfs/dataset/DIV2K/DIV2K_valid_HR/DIV2K_valid_HR/'\n",
    "# sim_dir = 'binary_dataset/simulated/'\n",
    "meta = {'wl' : (515e-9), 'dx':(7.56e-6, 7.56e-6)}\n",
    "padding = 0\n",
    "train_dataset = Dataset512(target_dir=target_dir, meta=meta, isTrain=True, padding=padding)\n",
    "valid_dataset = Dataset512(target_dir=valid_dir, meta=meta, isTrain=False, padding=padding)\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "validloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_uniform_(m.weight.data, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight.data, 1)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight.data)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "\n",
    "def train(model, num_hologram=10, custom_name='fcn', epochs=100, lr=1e-4, z=2e-3):\n",
    "    date = datetime.datetime.now() - datetime.timedelta(hours=15)\n",
    "    mean_psnr_list = []\n",
    "    mean_mse_list = []\n",
    "    max_epoch = 0\n",
    "    max_psnr = 0\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    sign_function = SignFunction.apply\n",
    "    # path = 'models/'\n",
    "    model_name = f'{date}_{custom_name}_{num_hologram}_{z}'\n",
    "    # make result folder\n",
    "    result_folder = 'result/'+model_name\n",
    "    os.mkdir(result_folder)\n",
    "    model_path = os.path.join(result_folder, model_name)\n",
    "    psnr_result_path = os.path.join(result_folder, 'meanPSNR.npy')\n",
    "    mse_result_path = os.path.join(result_folder, 'meanMSE.npy')\n",
    "    result = {'model_path': model_path, 'psnr_result_path': psnr_result_path,\n",
    "          'mse_result_path': mse_result_path, 'z': z,\n",
    "          'num_hologram': num_hologram, 'lr': lr, 'epochs': epochs}\n",
    "    # save result dict\n",
    "    with open(os.path.join(result_folder, 'result_dict.pickle'), 'wb') as fw:\n",
    "        pickle.dump(result, fw)\n",
    "    for epoch in range(epochs):\n",
    "        pbar = tqdm.tqdm(trainloader)\n",
    "        model.train()\n",
    "        for target in pbar:\n",
    "            out = model(target)\n",
    "            binary = sign_function(out)\n",
    "            sim = tt.simulate(binary, z).abs()**2\n",
    "            result = torch.mean(sim, dim=1, keepdim=True)\n",
    "            loss = tt.relativeLoss(result, target, F.mse_loss)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            psnrList = []\n",
    "            mseList = []\n",
    "            for valid in validloader:\n",
    "                out = model(valid)\n",
    "                binary = sign_function(out)\n",
    "                sim = tt.simulate(binary, z).abs()**2\n",
    "                result = torch.mean(sim, dim=1, keepdim=True)\n",
    "                psnr = tt.relativeLoss(result, valid, tm.get_PSNR)\n",
    "                psnrList.append(psnr)\n",
    "                mse = tt.relativeLoss(result, valid, F.mse_loss).detach().cpu().numpy()\n",
    "                mseList.append(mse)\n",
    "            mean_psnr = sum(psnrList)/len(psnrList)\n",
    "            mean_mse = sum(mseList)/len(mseList)\n",
    "            mean_psnr_list.append(mean_psnr)\n",
    "            mean_mse_list.append(mean_mse)\n",
    "            # save psnr and mse\n",
    "            np.save(psnr_result_path, mean_psnr_list)\n",
    "            np.save(mse_result_path, mean_mse_list)\n",
    "            plt.plot(np.arange(len(mean_psnr_list)), mean_psnr_list,\n",
    "                     label=f'max psnr: {max(mean_psnr_list)}')\n",
    "            plt.title(model_name+'_psnr')\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(result_folder, 'meanPSNR.png'))\n",
    "            plt.clf()\n",
    "            plt.plot(np.arange(len(mean_mse_list)), mean_mse_list,\n",
    "                     label=f'max psnr: {min(mean_mse_list)}')\n",
    "            plt.title(model_name+'_mse')\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(result_folder, 'meanMSE.png'))\n",
    "            plt.clf()\n",
    "            print(f'mean PSNR : {mean_psnr} {epoch}/{epochs}')\n",
    "            print(f'mean MSE : {mean_mse} {epoch}/{epochs}')\n",
    "\n",
    "        if mean_psnr > max_psnr:\n",
    "            max_psnr = mean_psnr\n",
    "            max_epoch = epoch\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        print(f'max_psnr: {max_psnr}, epoch: {max_epoch}')\n",
    "\n",
    "\n",
    "def binary_sim(out, z=2e-3):\n",
    "    binary = SignFunction.apply(out)\n",
    "    sim = tt.simulate(binary, z).abs()**2\n",
    "    res = torch.mean(sim, dim=1, keepdim=True)\n",
    "    return binary, res\n",
    "\n",
    "\n",
    "def valid(model):\n",
    "    with torch.no_grad():\n",
    "        psnr_list = []\n",
    "        for target in validloader:\n",
    "            out = model(target)\n",
    "            binary, res = binary_sim(out)\n",
    "            psnr = tt.relativeLoss(res, target, tm.get_PSNR)\n",
    "            psnr_list.append(psnr)\n",
    "    print(sum(psnr_list)/len(psnr_list))\n",
    "\n",
    "\n",
    "def check_order(bmodel, classifier, target):\n",
    "    if len(target.shape) == 3:\n",
    "        target = target.unsqueeze(0)\n",
    "    result = []\n",
    "    with torch.no_grad():\n",
    "        out = bmodel(target)\n",
    "        binary, res = binary_sim(out)\n",
    "        for i in range(10):\n",
    "            binary_input = binary[0][i].unsqueeze(0).unsqueeze(0)\n",
    "            prop_order = classifier(binary_input)\n",
    "            result.append(torch.argmax(prop_order))\n",
    "    print(result)\n",
    "\n",
    "\n",
    "def check_order_without_model(binary, classifier):\n",
    "    with torch.no_grad():\n",
    "        result = []\n",
    "        for i in range(10):\n",
    "            binary_input = binary[0][i].unsqueeze(0).unsqueeze(0)\n",
    "            prop_order = classifier(binary_input)\n",
    "            result.append(torch.argmax(prop_order))\n",
    "    print(result)\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc = nn.Linear(64 * 64 * 64, 10)  # 최종 분류를 위한 FC 레이어\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(torch.relu(self.conv1(x)))\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))\n",
    "        x = self.pool3(torch.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 64 * 64)  # flatten\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def rgb_binary_sim(out, z, th):\n",
    "    pixel_pitch = 7.56e-6\n",
    "    meta = {'wl' : (638e-9, 515e-9, 450e-9), 'dx':(pixel_pitch, pixel_pitch)}\n",
    "    rmeta = {'wl': (638e-9), 'dx': (pixel_pitch, pixel_pitch)}\n",
    "    gmeta = {'wl': (515e-9), 'dx': (pixel_pitch, pixel_pitch)}\n",
    "    bmeta = {'wl': (450e-9), 'dx': (pixel_pitch, pixel_pitch)}\n",
    "    sign = SignFunction.apply\n",
    "    binary = sign(out, th)\n",
    "    channel = out.shape[1]\n",
    "    rchannel = int(channel/3)\n",
    "    gchannel = int(channel*2/3)\n",
    "    red = binary[:, :rchannel, :, :]\n",
    "    green = binary[:, rchannel:gchannel, :, :]\n",
    "    blue = binary[:, gchannel:, :, :]\n",
    "    red = tt.Tensor(red, meta=rmeta)\n",
    "    green = tt.Tensor(green, meta=gmeta)\n",
    "    blue = tt.Tensor(blue, meta=bmeta)\n",
    "    rsim = tt.simulate(red, z).abs()**2\n",
    "    gsim = tt.simulate(green, z).abs()**2\n",
    "    bsim = tt.simulate(blue, z).abs()**2\n",
    "    rmean = torch.mean(rsim, dim=1, keepdim=True)\n",
    "    gmean = torch.mean(gsim, dim=1, keepdim=True)\n",
    "    bmean = torch.mean(bsim, dim=1, keepdim=True)\n",
    "    rgb = torch.cat([rmean, gmean, bmean], dim=1)\n",
    "    rgb = tt.Tensor(rgb, meta=meta)\n",
    "    binary = tt.Tensor(binary, meta=meta)\n",
    "    return binary, rgb\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4366c7c-ce09-486c-8f92-893a53b7df47",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "class BinaryNet(nn.Module):\n",
    "    def __init__(self, num_hologram, final='Sigmoid', in_planes=3,\n",
    "                 channels=[32, 64, 128, 256, 512, 1024, 2048, 4096],\n",
    "                 convReLU=True, convBN=True, poolReLU=True, poolBN=True,\n",
    "                 deconvReLU=True, deconvBN=True):\n",
    "        super(BinaryNet, self).__init__()\n",
    "\n",
    "        def CRB2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True, relu=True, bn=True):\n",
    "            layers = []\n",
    "            layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                 kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                                 bias=bias)]\n",
    "            if relu:\n",
    "                layers += [nn.Tanh()]\n",
    "            if bn:\n",
    "                layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "\n",
    "            cbr = nn.Sequential(*layers) # *으로 list unpacking \n",
    "\n",
    "            return cbr\n",
    "\n",
    "        def TRB2d(in_channels, out_channels, kernel_size=2, stride=2, bias=True, relu=True, bn=True):\n",
    "            layers = []\n",
    "            layers += [nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                          kernel_size=2, stride=2, padding=0,\n",
    "                                          bias=True)]\n",
    "            if bn:\n",
    "                layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "            if relu:\n",
    "                layers += [nn.ReLU()]\n",
    "\n",
    "            cbr = nn.Sequential(*layers) # *으로 list unpacking \n",
    "\n",
    "            return cbr\n",
    "\n",
    "        self.enc1_1 = CRB2d(in_planes, channels[0], relu=convReLU, bn=convBN)\n",
    "        self.enc1_2 = CRB2d(channels[0], channels[0], relu=convReLU, bn=convBN)\n",
    "        self.pool1 = CRB2d(channels[0], channels[0], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc2_1 = CRB2d(channels[0], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.enc2_2 = CRB2d(channels[1], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.pool2 = CRB2d(channels[1], channels[1], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc3_1 = CRB2d(channels[1], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.enc3_2 = CRB2d(channels[2], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.pool3 = CRB2d(channels[2], channels[2], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc4_1 = CRB2d(channels[2], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.enc4_2 = CRB2d(channels[3], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.pool4 = CRB2d(channels[3], channels[3], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc5_1 = CRB2d(channels[3], channels[4], relu=convReLU, bn=convBN)\n",
    "        self.enc5_2 = CRB2d(channels[4], channels[4], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv4 = TRB2d(channels[4], channels[3], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec4_1 = CRB2d(channels[4], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.dec4_2 = CRB2d(channels[3], channels[3], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv3 = TRB2d(channels[3], channels[2], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec3_1 = CRB2d(channels[3], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.dec3_2 = CRB2d(channels[2], channels[2], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv2 = TRB2d(channels[2], channels[1], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec2_1 = CRB2d(channels[2], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.dec2_2 = CRB2d(channels[1], channels[1], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv1 = TRB2d(channels[1], channels[0], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec1_1 = CRB2d(channels[1], channels[0], relu=convReLU, bn=convBN)\n",
    "        self.dec1_2 = CRB2d(channels[0], channels[0], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.classifier = CRB2d(channels[0], num_hologram, relu=False, bn=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1_1 = self.enc1_1(x)\n",
    "        enc1_2 = self.enc1_2(enc1_1)\n",
    "        pool1 = self.pool1(enc1_2)\n",
    "\n",
    "        enc2_1 = self.enc2_1(pool1)\n",
    "        enc2_2 = self.enc2_2(enc2_1)\n",
    "        pool2 = self.pool2(enc2_2)\n",
    "\n",
    "        enc3_1 = self.enc3_1(pool2)\n",
    "        enc3_2 = self.enc3_2(enc3_1)\n",
    "        pool3 = self.pool3(enc3_2)\n",
    "\n",
    "        enc4_1 = self.enc4_1(pool3)\n",
    "        enc4_2 = self.enc4_2(enc4_1)\n",
    "        pool4 = self.pool4(enc4_2)\n",
    "\n",
    "        enc5_1 = self.enc5_1(pool4)\n",
    "        enc5_2 = self.enc5_2(enc5_1)\n",
    "\n",
    "        deconv4 = self.deconv4(enc5_2)\n",
    "        concat4 = torch.cat((deconv4, enc4_2), dim=1)\n",
    "        dec4_1 = self.dec4_1(concat4)\n",
    "        dec4_2 = self.dec4_2(dec4_1)\n",
    "\n",
    "        deconv3 = self.deconv3(dec4_2)\n",
    "        concat3 = torch.cat((deconv3, enc3_2), dim=1)\n",
    "        dec3_1 = self.dec3_1(concat3)\n",
    "        dec3_2 = self.dec3_2(dec3_1)\n",
    "\n",
    "        deconv2 = self.deconv2(dec3_2)\n",
    "        concat2 = torch.cat((deconv2, enc2_2), dim=1)\n",
    "        dec2_1 = self.dec2_1(concat2)\n",
    "        dec2_2 = self.dec2_2(dec2_1)\n",
    "\n",
    "        deconv1 = self.deconv1(dec2_2)\n",
    "        concat1 = torch.cat((deconv1, enc1_2), dim=1)\n",
    "        dec1_1 = self.dec1_1(concat1)\n",
    "        dec1_2 = self.dec1_2(dec1_1)\n",
    "\n",
    "        # Final classifier\n",
    "        out = self.classifier(dec1_2)\n",
    "        out = nn.Sigmoid()(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = BinaryNet(num_hologram=8, in_planes=1, convReLU=False,\n",
    "                  convBN=False, poolReLU=False, poolBN=False,\n",
    "                  deconvReLU=False, deconvBN=False).cuda()\n",
    "test = torch.randn(1, 1, 1024, 1024).cuda()\n",
    "out = model(test)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47a89488-4a8c-463f-9ded-a5ade7b611bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T09:06:03.212048700Z",
     "start_time": "2024-12-06T09:04:47.392583Z"
    }
   },
   "outputs": [],
   "source": [
    "def rgb_binary_train_padding(model, num_hologram=24, custom_name='0703Unet', epochs=500, lr=1e-4, z=2e-3):\n",
    "    date = datetime.datetime.now() - datetime.timedelta(hours=15)\n",
    "    model.apply(initialize_weights)\n",
    "    mean_psnr_list = []\n",
    "    mean_mse_list = []\n",
    "    max_epoch = 0\n",
    "    max_psnr = 0\n",
    "    crop = torchvision.transforms.CenterCrop(896)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    sign = SignFunction.apply\n",
    "    # path = 'models/'\n",
    "    model_name = f'{date}_{custom_name}_{num_hologram}_{z}'\n",
    "    # make result folder\n",
    "    result_folder = 'result/'+model_name\n",
    "    os.mkdir(result_folder)\n",
    "    num_parameters = count_parameters(model)\n",
    "    model_path = os.path.join(result_folder, model_name)\n",
    "    psnr_result_path = os.path.join(result_folder, 'meanPSNR.npy')\n",
    "    mse_result_path = os.path.join(result_folder, 'meanMSE.npy')\n",
    "    result = {'model_path': model_path, 'psnr_result_path': psnr_result_path,\n",
    "          'mse_result_path': mse_result_path, 'z': z,\n",
    "          'num_hologram': num_hologram, 'lr': lr, 'epochs': epochs,\n",
    "            'num_parameters': num_parameters}\n",
    "    # save result dict\n",
    "    with open(os.path.join(result_folder, 'result_dict.pickle'), 'wb') as fw:\n",
    "        pickle.dump(result, fw)\n",
    "    for epoch in range(epochs):\n",
    "        pbar = tqdm.tqdm(trainloader)\n",
    "        model.train()\n",
    "        for target in pbar:\n",
    "            target = target\n",
    "            out = model(target)\n",
    "            binary = sign(out)\n",
    "            sim = tt.simulate(binary, 2e-3).abs()**2\n",
    "            mean_sim = torch.mean(sim, dim=1, keepdim=True)\n",
    "            rgb = crop(mean_sim)\n",
    "            croped_target = crop(target)\n",
    "            loss = tt.relativeLoss(rgb, croped_target, F.mse_loss)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            psnrList = []\n",
    "            mseList = []\n",
    "            for idx, valid in enumerate(validloader):\n",
    "                valid = valid\n",
    "                out = model(valid)\n",
    "                binary = sign(out)\n",
    "                sim = tt.simulate(binary, 2e-3).abs()**2\n",
    "                mean_sim = torch.mean(sim, dim=1, keepdim=True)\n",
    "                rgb = crop(mean_sim)\n",
    "                croped_target = crop(valid)\n",
    "                psnr = tt.relativeLoss(rgb, croped_target, tm.get_PSNR)\n",
    "                psnrList.append(psnr)\n",
    "                mse = tt.relativeLoss(rgb, croped_target, F.mse_loss).detach().cpu().numpy()\n",
    "                mseList.append(mse)\n",
    "                if idx == 0:\n",
    "                    pl = tt.show_with_insets(rgb, croped_target, correct_colorwise=True)\n",
    "                    pl.save(os.path.join(result_folder, 'penguin.png'))\n",
    "            mean_psnr = sum(psnrList)/len(psnrList)\n",
    "            mean_mse = sum(mseList)/len(mseList)\n",
    "            mean_psnr_list.append(mean_psnr)\n",
    "            mean_mse_list.append(mean_mse)\n",
    "            # save psnr and mse\n",
    "            if epoch % 10 == 0:\n",
    "                np.save(psnr_result_path, mean_psnr_list)\n",
    "                np.save(mse_result_path, mean_mse_list)\n",
    "                plt.plot(np.arange(len(mean_psnr_list)), mean_psnr_list,\n",
    "                         label=f'max psnr: {max(mean_psnr_list)}')\n",
    "                plt.title(model_name+'_psnr')\n",
    "                plt.legend()\n",
    "                plt.savefig(os.path.join(result_folder, 'meanPSNR.png'))\n",
    "                plt.clf()\n",
    "                plt.plot(np.arange(len(mean_mse_list)), mean_mse_list,\n",
    "                         label=f'max psnr: {min(mean_mse_list)}')\n",
    "                plt.title(model_name+'_mse')\n",
    "                plt.legend()\n",
    "                plt.savefig(os.path.join(result_folder, 'meanMSE.png'))\n",
    "                plt.clf()\n",
    "            print(f'mean PSNR : {mean_psnr} {epoch}/{epochs}')\n",
    "            print(f'mean MSE : {mean_mse} {epoch}/{epochs}')\n",
    "\n",
    "        if mean_psnr > max_psnr:\n",
    "            max_psnr = mean_psnr\n",
    "            max_epoch = epoch\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        print(f'max_psnr: {max_psnr}, epoch: {max_epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccd6d2b4-75ce-4139-9a0e-b2f622770f42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T09:06:03.214470900Z",
     "start_time": "2024-12-06T09:04:47.542936Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 376/800 [00:34<00:38, 10.96it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rgb_binary_train_padding(model, num_hologram=8, custom_name='pre_reinforce', epochs=500, lr=1e-4, z=2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b5e545-d079-427d-b45f-54f036986ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5171e0-5cd1-4f6f-9366-d6f84590e6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sign = SignFunction.apply\n",
    "out = model(valid_dataset[0].unsqueeze(0).unsqueeze(0))\n",
    "binary = sign(out, 0.5)\n",
    "sim = tt.simulate(binary, 2e-3)\n",
    "mean_sim = torch.mean(sim, dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efb9d87-35cc-40ee-b130-2442d28d64e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in trainloader:\n",
    "    print(target.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfe047d-0265-4d80-b53a-d168d993aac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8367302d-9f37-4a40-81fe-5b5b2d448ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8a29eb-181b-4785-9c8b-e72601a553cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
