{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9edb12d4-2114-40ca-bb64-b1ffebe207af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T10:35:57.693105Z",
     "start_time": "2025-01-06T10:35:55.232001Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 메시지는 콘솔과 파일에 동시에 기록됩니다.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/__init__.py:966\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m library\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m--> 966\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations\n\u001b[1;32m    968\u001b[0m \u001b[38;5;66;03m# Enable CUDA Sanitizer\u001b[39;00m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTORCH_CUDA_SANITIZER\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_meta_registrations.py:857\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlong\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    855\u001b[0m \u001b[38;5;129;43m@register_meta\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43maten\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnansum\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maten\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnansum\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;129;43m@out_wrapper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m--> 857\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mmeta_nansum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_get_reduction_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpromote_int_to_long\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdims\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdims\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_prims_common/wrappers.py:200\u001b[0m, in \u001b[0;36mout_wrapper.<locals>._out_wrapper\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m    187\u001b[0m out_type \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    188\u001b[0m     TensorLikeType\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_tensor\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m Tuple[\u001b[38;5;28mtuple\u001b[39m(TensorLikeType \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(out_names)))]\n\u001b[1;32m    191\u001b[0m )\n\u001b[1;32m    192\u001b[0m return_type \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    193\u001b[0m     TensorLikeType\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_tensor\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    197\u001b[0m     )\n\u001b[1;32m    198\u001b[0m )\n\u001b[0;32m--> 200\u001b[0m sig \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m factory_kwargs \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    202\u001b[0m is_factory_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m(p \u001b[38;5;129;01min\u001b[39;00m sig\u001b[38;5;241m.\u001b[39mparameters \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m factory_kwargs)\n",
      "File \u001b[0;32m/usr/lib/python3.8/inspect.py:3105\u001b[0m, in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   3103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msignature\u001b[39m(obj, \u001b[38;5;241m*\u001b[39m, follow_wrapped\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   3104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_wrapped\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/inspect.py:2854\u001b[0m, in \u001b[0;36mSignature.from_callable\u001b[0;34m(cls, obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   2851\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   2852\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_callable\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, \u001b[38;5;241m*\u001b[39m, follow_wrapped\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   2853\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2854\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_from_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigcls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2855\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mfollow_wrapper_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/inspect.py:2304\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[1;32m   2299\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m sig\u001b[38;5;241m.\u001b[39mreplace(parameters\u001b[38;5;241m=\u001b[39mnew_params)\n\u001b[1;32m   2301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isfunction(obj) \u001b[38;5;129;01mor\u001b[39;00m _signature_is_functionlike(obj):\n\u001b[1;32m   2302\u001b[0m     \u001b[38;5;66;03m# If it's a pure Python function, or an object that is duck type\u001b[39;00m\n\u001b[1;32m   2303\u001b[0m     \u001b[38;5;66;03m# of a Python function (Cython functions, for instance), then:\u001b[39;00m\n\u001b[0;32m-> 2304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_from_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigcls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2305\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mskip_bound_arg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_bound_arg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _signature_is_builtin(obj):\n\u001b[1;32m   2308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _signature_from_builtin(sigcls, obj,\n\u001b[1;32m   2309\u001b[0m                                    skip_bound_arg\u001b[38;5;241m=\u001b[39mskip_bound_arg)\n",
      "File \u001b[0;32m/usr/lib/python3.8/inspect.py:2168\u001b[0m, in \u001b[0;36m_signature_from_function\u001b[0;34m(cls, func, skip_bound_arg)\u001b[0m\n\u001b[1;32m   2166\u001b[0m kind \u001b[38;5;241m=\u001b[39m _POSITIONAL_ONLY \u001b[38;5;28;01mif\u001b[39;00m posonly_left \u001b[38;5;28;01melse\u001b[39;00m _POSITIONAL_OR_KEYWORD\n\u001b[1;32m   2167\u001b[0m annotation \u001b[38;5;241m=\u001b[39m annotations\u001b[38;5;241m.\u001b[39mget(name, _empty)\n\u001b[0;32m-> 2168\u001b[0m parameters\u001b[38;5;241m.\u001b[39mappend(\u001b[43mParameter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mannotation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2169\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m posonly_left:\n\u001b[1;32m   2171\u001b[0m     posonly_left \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.8/inspect.py:2491\u001b[0m, in \u001b[0;36mParameter.__init__\u001b[0;34m(self, name, kind, default, annotation)\u001b[0m\n\u001b[1;32m   2489\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, kind, \u001b[38;5;241m*\u001b[39m, default\u001b[38;5;241m=\u001b[39m_empty, annotation\u001b[38;5;241m=\u001b[39m_empty):\n\u001b[1;32m   2490\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2491\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kind \u001b[38;5;241m=\u001b[39m \u001b[43m_ParameterKind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2492\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m   2493\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkind\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m is not a valid Parameter.kind\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.8/enum.py:313\u001b[0m, in \u001b[0;36mEnumMeta.__call__\u001b[0;34m(cls, value, names, module, qualname, type, start)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    classes/types should always be True.\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, value, names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, module\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, qualname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    314\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m    Either returns an existing member, or creates a new enum class.\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    `type`, if set, will be mixed in as the first base class.\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# simple value lookup\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# 로그를 저장할 디렉토리 설정\n",
    "log_dir = \"log\"\n",
    "os.makedirs(log_dir, exist_ok=True)  # 디렉토리가 없으면 생성\n",
    "\n",
    "# 현재 파일 이름과 실행 시간 가져오기\n",
    "if '__file__' in globals():\n",
    "    current_file = os.path.splitext(os.path.basename(__file__))[0]  # 현재 파일 이름(확장자 제거)\n",
    "else:\n",
    "    current_file = \"interactive\"  # 인터프리터나 노트북 환경에서 기본 파일 이름 사용\n",
    "\n",
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")  # 현재 시간\n",
    "log_filename = os.path.join(log_dir, f\"{current_file}_{current_datetime}.log\")  # log 폴더에 파일 저장\n",
    "\n",
    "# 로그 설정\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filename),  # 동적으로 생성된 파일 이름 사용\n",
    "        logging.StreamHandler()  # 콘솔 출력\n",
    "    ]\n",
    ")\n",
    "\n",
    "class Tee:\n",
    "    def __init__(self, *files):\n",
    "        self.files = files\n",
    "\n",
    "    def write(self, data):\n",
    "        for file in self.files:\n",
    "            file.write(data)\n",
    "            file.flush()  # 실시간 저장\n",
    "\n",
    "    def flush(self):\n",
    "        for file in self.files:\n",
    "            file.flush()\n",
    "\n",
    "\n",
    "# stdout을 파일과 콘솔로 동시에 출력\n",
    "log_file = open(log_filename, \"a\")\n",
    "sys.stdout = Tee(sys.stdout, log_file)\n",
    "\n",
    "# 테스트 출력\n",
    "print(\"이 메시지는 콘솔과 파일에 동시에 기록됩니다.\")\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import BaseCallback, CallbackList\n",
    "\n",
    "import torchOptics.optics as tt\n",
    "import torchOptics.metrics as tm\n",
    "\n",
    "\n",
    "IPS = 256 #이미지 픽셀 사이즈\n",
    "CH = 8 #채널\n",
    "rw = 800 #보상\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 현재 날짜와 시간을 가져와 포맷 지정\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "class BinaryNet(nn.Module):\n",
    "    def __init__(self, num_hologram, final='Sigmoid', in_planes=3,\n",
    "                 channels=[32, 64, 128, 256, 512, 1024, 2048, 4096],\n",
    "                 convReLU=True, convBN=True, poolReLU=True, poolBN=True,\n",
    "                 deconvReLU=True, deconvBN=True):\n",
    "        super(BinaryNet, self).__init__()\n",
    "\n",
    "        def CRB2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True, relu=True, bn=True):\n",
    "            layers = []\n",
    "            layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                 kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                                 bias=bias)]\n",
    "            if relu:\n",
    "                layers += [nn.Tanh()]\n",
    "            if bn:\n",
    "                layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "\n",
    "            cbr = nn.Sequential(*layers)  # *으로 list unpacking\n",
    "\n",
    "            return cbr\n",
    "\n",
    "        def TRB2d(in_channels, out_channels, kernel_size=2, stride=2, bias=True, relu=True, bn=True):\n",
    "            layers = []\n",
    "            layers += [nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                          kernel_size=2, stride=2, padding=0,\n",
    "                                          bias=True)]\n",
    "            if bn:\n",
    "                layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "            if relu:\n",
    "                layers += [nn.ReLU()]\n",
    "\n",
    "            cbr = nn.Sequential(*layers)  # *으로 list unpacking\n",
    "\n",
    "            return cbr\n",
    "\n",
    "        self.enc1_1 = CRB2d(in_planes, channels[0], relu=convReLU, bn=convBN)\n",
    "        self.enc1_2 = CRB2d(channels[0], channels[0], relu=convReLU, bn=convBN)\n",
    "        self.pool1 = CRB2d(channels[0], channels[0], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc2_1 = CRB2d(channels[0], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.enc2_2 = CRB2d(channels[1], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.pool2 = CRB2d(channels[1], channels[1], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc3_1 = CRB2d(channels[1], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.enc3_2 = CRB2d(channels[2], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.pool3 = CRB2d(channels[2], channels[2], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc4_1 = CRB2d(channels[2], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.enc4_2 = CRB2d(channels[3], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.pool4 = CRB2d(channels[3], channels[3], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc5_1 = CRB2d(channels[3], channels[4], relu=convReLU, bn=convBN)\n",
    "        self.enc5_2 = CRB2d(channels[4], channels[4], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv4 = TRB2d(channels[4], channels[3], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec4_1 = CRB2d(channels[4], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.dec4_2 = CRB2d(channels[3], channels[3], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv3 = TRB2d(channels[3], channels[2], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec3_1 = CRB2d(channels[3], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.dec3_2 = CRB2d(channels[2], channels[2], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv2 = TRB2d(channels[2], channels[1], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec2_1 = CRB2d(channels[2], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.dec2_2 = CRB2d(channels[1], channels[1], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv1 = TRB2d(channels[1], channels[0], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec1_1 = CRB2d(channels[1], channels[0], relu=convReLU, bn=convBN)\n",
    "        self.dec1_2 = CRB2d(channels[0], channels[0], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.classifier = CRB2d(channels[0], num_hologram, relu=False, bn=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1_1 = self.enc1_1(x)\n",
    "        enc1_2 = self.enc1_2(enc1_1)\n",
    "        pool1 = self.pool1(enc1_2)\n",
    "\n",
    "        enc2_1 = self.enc2_1(pool1)\n",
    "        enc2_2 = self.enc2_2(enc2_1)\n",
    "        pool2 = self.pool2(enc2_2)\n",
    "\n",
    "        enc3_1 = self.enc3_1(pool2)\n",
    "        enc3_2 = self.enc3_2(enc3_1)\n",
    "        pool3 = self.pool3(enc3_2)\n",
    "\n",
    "        enc4_1 = self.enc4_1(pool3)\n",
    "        enc4_2 = self.enc4_2(enc4_1)\n",
    "        pool4 = self.pool4(enc4_2)\n",
    "\n",
    "        enc5_1 = self.enc5_1(pool4)\n",
    "        enc5_2 = self.enc5_2(enc5_1)\n",
    "\n",
    "        deconv4 = self.deconv4(enc5_2)\n",
    "        concat4 = torch.cat((deconv4, enc4_2), dim=1)\n",
    "        dec4_1 = self.dec4_1(concat4)\n",
    "        dec4_2 = self.dec4_2(dec4_1)\n",
    "\n",
    "        deconv3 = self.deconv3(dec4_2)\n",
    "        concat3 = torch.cat((deconv3, enc3_2), dim=1)\n",
    "        dec3_1 = self.dec3_1(concat3)\n",
    "        dec3_2 = self.dec3_2(dec3_1)\n",
    "\n",
    "        deconv2 = self.deconv2(dec3_2)\n",
    "        concat2 = torch.cat((deconv2, enc2_2), dim=1)\n",
    "        dec2_1 = self.dec2_1(concat2)\n",
    "        dec2_2 = self.dec2_2(dec2_1)\n",
    "\n",
    "        deconv1 = self.deconv1(dec2_2)\n",
    "        concat1 = torch.cat((deconv1, enc1_2), dim=1)\n",
    "        dec1_1 = self.dec1_1(concat1)\n",
    "        dec1_2 = self.dec1_2(dec1_1)\n",
    "\n",
    "        # Final classifier\n",
    "        out = self.classifier(dec1_2)\n",
    "        out = nn.Sigmoid()(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = BinaryNet(num_hologram=CH, in_planes=1, convReLU=False,\n",
    "                  convBN=False, poolReLU=False, poolBN=False,\n",
    "                  deconvReLU=False, deconvBN=False).cuda()\n",
    "test = torch.randn(1, 1, IPS, IPS).cuda()\n",
    "out = model(test)\n",
    "print(out.shape)\n",
    "\n",
    "\n",
    "class Dataset512(Dataset):\n",
    "    def __init__(self, target_dir, meta, transform=None, isTrain=True, padding=0):\n",
    "        self.target_dir = target_dir\n",
    "        self.transform = transform\n",
    "        self.meta = meta\n",
    "        self.isTrain = isTrain\n",
    "        self.target_list = sorted(glob.glob(target_dir+'*.png'))\n",
    "        self.center_crop = torchvision.transforms.CenterCrop(IPS)\n",
    "        self.random_crop = torchvision.transforms.RandomCrop((IPS, IPS))\n",
    "        self.padding = padding\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        target = tt.imread(self.target_list[idx], meta=self.meta, gray=True).unsqueeze(0)\n",
    "        if target.shape[-1] < IPS or target.shape[-2] < IPS:\n",
    "            target = torchvision.transforms.Resize(IPS)(target)\n",
    "        if self.isTrain:\n",
    "            target = self.random_crop(target)\n",
    "            target = torchvision.transforms.functional.pad(target, (self.padding, self.padding, self.padding, self.padding))\n",
    "        else:\n",
    "            target = self.center_crop(target)\n",
    "            target = torchvision.transforms.functional.pad(target, (self.padding, self.padding, self.padding, self.padding))\n",
    "        # 데이터와 파일 경로를 함께 반환\n",
    "        return target, self.target_list[idx]\n",
    "\n",
    "\n",
    "\n",
    "# BinaryHologramEnv 클래스\n",
    "class BinaryHologramEnv(gym.Env):\n",
    "    def __init__(self, target_function, trainloader, max_steps=10000, T_PSNR=30, T_steps=1, T_PSNR_DIFF=0.1):\n",
    "        super(BinaryHologramEnv, self).__init__()\n",
    "\n",
    "        # 관찰 공간: (4, 채널, 픽셀, 픽셀)\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(4, CH, IPS, IPS), dtype=np.float32)\n",
    "\n",
    "        # 행동 공간: 픽셀 하나를 선택하는 인덱스 (채널 * 픽셀 * 픽셀)\n",
    "        self.num_pixels = CH * IPS * IPS\n",
    "        self.action_space = spaces.Discrete(self.num_pixels)\n",
    "\n",
    "        # 타겟 함수와 데이터 로더 설정\n",
    "        self.target_function = target_function\n",
    "        self.trainloader = trainloader\n",
    "\n",
    "        # 환경 설정\n",
    "        self.max_steps = max_steps\n",
    "        self.T_PSNR = T_PSNR\n",
    "        self.T_steps = T_steps\n",
    "        self.T_PSNR_DIFF = T_PSNR_DIFF\n",
    "\n",
    "        # 학습 상태 초기화\n",
    "        self.state = None\n",
    "        self.observation = None\n",
    "        self.steps = 0\n",
    "        self.psnr_sustained_steps = 0\n",
    "        self.flip_count = 0\n",
    "\n",
    "        # 최고 PSNR_DIFF 추적 변수\n",
    "        self.max_psnr_diff = float('-inf')  # 가장 높은 PSNR_DIFF를 추적\n",
    "\n",
    "        # PSNR 저장 변수\n",
    "        self.previous_psnr = None\n",
    "\n",
    "        # 데이터 로더에서 첫 배치 설정\n",
    "        self.data_iter = iter(self.trainloader)\n",
    "        self.target_image = None\n",
    "\n",
    "        # 실패한 경우 반복 여부\n",
    "        self.retry_current_target = False  # 현재 데이터셋 반복 여부\n",
    "\n",
    "        # 에피소드 카운트\n",
    "        self.episode_num_count = 0\n",
    "\n",
    "\n",
    "    def reset(self, z=2e-3):\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        self.episode_num_count += 1  # Increment episode count at the start of each reset\n",
    "\n",
    "        # 이터레이터에서 다음 데이터를 가져옴\n",
    "        try:\n",
    "            self.target_image, self.current_file = next(self.data_iter)\n",
    "        except StopIteration:\n",
    "            # 데이터셋 끝에 도달하면 이터레이터를 다시 생성하고 처음부터 다시 시작\n",
    "            print(\"\\033[40;93m[INFO] Reached the end of dataset. Restarting from the beginning.\\033[0m\")\n",
    "            self.data_iter = iter(self.trainloader)\n",
    "            self.target_image, self.current_file = next(self.data_iter)\n",
    "\n",
    "        print(f\"\\033[40;93m[Episode Start] Currently using dataset file: {self.current_file}, Episode count: {self.episode_num_count}\\033[0m\")\n",
    "\n",
    "        self.target_image = self.target_image.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_output = self.target_function(self.target_image)\n",
    "        self.observation = model_output.cpu().numpy()  # (1, CH, IPS, IPS)\n",
    "\n",
    "        # 매 에피소드마다 초기화\n",
    "        self.max_psnr_diff = float('-inf')\n",
    "        self.steps = 0\n",
    "        self.flip_count = 0\n",
    "        self.psnr_sustained_steps = 0\n",
    "\n",
    "        # Ensure observation shape is (채널, 픽셀, 픽셀)\n",
    "        self.observation = model_output.squeeze(0).cpu().numpy()  # (채널, 픽셀, 픽셀)\n",
    "        self.state = (self.observation >= 0.5).astype(np.int8)  # 초기 Binary state\n",
    "\n",
    "        # 시뮬레이션 전 binary 형상을 (1, 채널, 픽셀, 픽셀)로 복원\n",
    "        binary = torch.tensor(self.state, dtype=torch.float32).unsqueeze(0).cuda()  # (1, 채널, 픽셀, 픽셀)\n",
    "        binary = tt.Tensor(binary, meta={'dx': (7.56e-6, 7.56e-6), 'wl': 515e-9})  # meta 정보 포함\n",
    "\n",
    "        # 시뮬레이션\n",
    "        sim = tt.simulate(binary, z).abs()**2\n",
    "        result = torch.mean(sim, dim=1, keepdim=True)\n",
    "\n",
    "        # MSE 및 PSNR 계산\n",
    "        mse = tt.relativeLoss(result, self.target_image, F.mse_loss).detach().cpu().numpy()\n",
    "        self.initial_psnr = tt.relativeLoss(result, self.target_image, tm.get_PSNR)  # 초기 PSNR 저장\n",
    "        self.previous_psnr = self.initial_psnr # 초기 PSNR 저장\n",
    "\n",
    "        # target_image_np와 result를 채널 차원(CH=8)으로 확장\n",
    "        target_image_np = np.repeat(self.target_image.squeeze(0).cpu().numpy(), CH, axis=0)  # 모양: [8, 512, 512]\n",
    "        result_np = np.repeat(result.squeeze(0).cpu().numpy(), CH, axis=0)  # 모양: [8, 512, 512]\n",
    "\n",
    "        # 모든 관찰값을 스택으로 결합\n",
    "        combined_observation = np.stack(\n",
    "            [self.state, self.observation, target_image_np, result_np], axis=0\n",
    "        )  # 최종 모양: [4, CH, IPS, IPS]\n",
    "\n",
    "        current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        print(f\"\\033[92mInitial MSE: {mse:.6f}, Initial PSNR: {self.initial_psnr:.6f}, {current_time}\\033[0m\")\n",
    "\n",
    "        self.retry_current_target = False  # 초기화 후 데이터 반복 플래그 해제\n",
    "\n",
    "        return combined_observation, {\"state\": self.state}\n",
    "\n",
    "\n",
    "    def step(self, action, z=2e-3):\n",
    "        # 행동 전 PSNR 계산\n",
    "        psnr_before = self.previous_psnr\n",
    "\n",
    "        # 행동을 기반으로 픽셀 좌표 계산Inv\n",
    "        channel = action // (IPS * IPS)\n",
    "        pixel_index = action % (IPS * IPS)\n",
    "        row = pixel_index // IPS\n",
    "        col = pixel_index % IPS\n",
    "\n",
    "        # 플립 전 모델 예측값 가져오기\n",
    "        pre_flip_value = self.observation[channel, row, col]\n",
    "\n",
    "        # 상태 변경\n",
    "        self.state[channel, row, col] = 1 - self.state[channel, row, col]\n",
    "        self.flip_count += 1  # 플립 증가\n",
    "\n",
    "        # 현재 상태로 새로운 시뮬레이션 수행\n",
    "        binary_after = torch.tensor(self.state, dtype=torch.float32).unsqueeze(0).cuda()\n",
    "        binary_after = tt.Tensor(binary_after, meta={'dx': (7.56e-6, 7.56e-6), 'wl': 515e-9})\n",
    "        sim_after = tt.simulate(binary_after, z).abs()**2\n",
    "        result_after = torch.mean(sim_after, dim=1, keepdim=True)\n",
    "        psnr_after = tt.relativeLoss(result_after, self.target_image, tm.get_PSNR)\n",
    "\n",
    "        # 시뮬레이션 결과를 NumPy로 변환\n",
    "        result_np = np.repeat(result_after.squeeze(0).cpu().numpy(), CH, axis=0)\n",
    "        target_image_np = np.repeat(self.target_image.squeeze(0).cpu().numpy(), CH, axis=0)\n",
    "\n",
    "        # Combined observation 생성\n",
    "        combined_observation = np.stack(\n",
    "            [self.state, self.observation, target_image_np, result_np], axis=0\n",
    "        )\n",
    "\n",
    "        # PSNR 변화량 계산\n",
    "        psnr_change = psnr_after - psnr_before\n",
    "        psnr_diff = psnr_after - self.initial_psnr\n",
    "\n",
    "        # psnr_change가 음수인 경우 상태 롤백 수행\n",
    "        if psnr_change < 0:\n",
    "\n",
    "            failed_observation = combined_observation\n",
    "\n",
    "            failed_action = action\n",
    "            failed_reward = psnr_change * rw  # PSNR 변화량(psnr_change)에 기반한 보상\n",
    "\n",
    "            # 플립된 픽셀을 원래대로 복구\n",
    "            self.state[channel, row, col] = 1 - self.state[channel, row, col]\n",
    "            self.flip_count -= 1\n",
    "\n",
    "            # 출력 추가 (100 스텝마다 출력)\n",
    "            if self.steps % 100 == 0:\n",
    "                current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "                success_ratio = self.flip_count / self.steps if self.steps > 0 else 0\n",
    "                print(\n",
    "                    f\"Step: {self.steps:<6} | Time: {current_time}\"\n",
    "                    f\"\\nPSNR Before: {psnr_before:.6f} | PSNR After: {psnr_after:.6f} | Change: {psnr_change:.6f} | Diff: {psnr_diff:.6f}\"\n",
    "                    f\"\\nReward: {failed_reward:.2f} | Success Ratio: {success_ratio:.6f} | Flip Count: {self.flip_count}\"\n",
    "                    f\"\\nPre-flip Value: {pre_flip_value:.6f} | New State Value: {self.state[channel, row, col]}\"\n",
    "                    f\"\\nFlip Pixel: Channel={channel}, Row={row}, Col={col}\"\n",
    "                )\n",
    "\n",
    "            # 스텝 증가\n",
    "            self.steps += 1\n",
    "\n",
    "            # 실패 정보 생성\n",
    "            info = {\n",
    "                \"psnr_before\": psnr_before,\n",
    "                \"psnr_after\": psnr_after,\n",
    "                \"psnr_change\": psnr_change,\n",
    "                \"psnr_diff\": psnr_diff,\n",
    "                \"pre_flip_value\": pre_flip_value,\n",
    "                \"state_before\": self.state.copy(),  # 행동 이전 상태\n",
    "                \"state_after\": None,  # 실패한 경우에는 상태를 업데이트하지 않음\n",
    "                \"observation_before\": self.observation.copy(),  # 행동 이전 관찰값\n",
    "                \"observation_after\": None,  # 실패한 경우 관찰값 업데이트 없음\n",
    "                \"failed_action\": failed_action,  # 실패한 행동\n",
    "                \"flip_count\": self.flip_count,  # 현재까지의 플립 횟수\n",
    "                \"reward\": failed_reward,\n",
    "                \"target_image\": self.target_image.cpu().numpy(),  # 타겟 이미지\n",
    "                \"simulation_result\": result_np,  # 현재 시뮬레이션 결과\n",
    "                \"step\": self.steps,  # 현재 스텝\n",
    "            }\n",
    "            return failed_observation, failed_reward, False, False, info\n",
    "\n",
    "        self.max_psnr_diff = max(self.max_psnr_diff, psnr_diff)  # 최고 PSNR_DIFF 업데이트\n",
    "\n",
    "        # 보상 계산\n",
    "        reward = psnr_change * rw  # PSNR 변화량(psnr_change)에 기반한 보상\n",
    "\n",
    "        # 출력 추가 (100 스텝마다 출력)\n",
    "        if self.steps % 100 == 0:\n",
    "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "            success_ratio = self.flip_count / self.steps if self.steps > 0 else 0\n",
    "            print(\n",
    "                f\"Step: {self.steps:<6} | Time: {current_time}\"\n",
    "                f\"\\nPSNR Before: {psnr_before:.6f} | PSNR After: {psnr_after:.6f} | Change: {psnr_change:.6f} | Diff: {psnr_diff:.6f}\"\n",
    "                f\"\\nReward: {reward:.2f} | Success Ratio: {success_ratio:.6f} | Flip Count: {self.flip_count}\"\n",
    "                f\"\\nPre-flip Value: {pre_flip_value:.6f} | New State Value: {self.state[channel, row, col]}\"\n",
    "                f\"\\nFlip Pixel: Channel={channel}, Row={row}, Col={col}\"\n",
    "            )\n",
    "\n",
    "        self.previous_psnr = psnr_after\n",
    "\n",
    "        # 성공 종료 조건: PSNR >= T_PSNR 또는 PSNR_DIFF >= T_PSNR_DIFF\n",
    "        terminated = self.steps >= self.max_steps or self.psnr_sustained_steps >= self.T_steps\n",
    "        truncated = self.steps >= self.max_steps\n",
    "\n",
    "        if psnr_after >= self.T_PSNR or psnr_diff >= self.T_PSNR_DIFF:\n",
    "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "            success_ratio = self.flip_count / self.steps if self.steps > 0 else 0\n",
    "            print(\n",
    "                f\"Step: {self.steps:<6} | Time: {current_time}\"\n",
    "                f\"\\nPSNR Before: {psnr_before:.6f} | PSNR After: {psnr_after:.6f} | Change: {psnr_change:.6f} | Diff: {psnr_diff:.6f}\"\n",
    "                f\"\\nReward: {reward:.2f} | Success Ratio: {success_ratio:.6f} | Flip Count: {self.flip_count}\"\n",
    "                f\"\\nPre-flip Value: {pre_flip_value:.6f} | New State Value: {self.state[channel, row, col]}\"\n",
    "                f\"\\nFlip Pixel: Channel={channel}, Row={row}, Col={col}\"\n",
    "            )\n",
    "            self.psnr_sustained_steps += 1\n",
    "            if self.psnr_sustained_steps >= self.T_steps:  # 성공 에피소드 조건\n",
    "\n",
    "                if self.steps <= 0:\n",
    "                    reward += 200\n",
    "                elif self.steps >= 4000:\n",
    "                    reward -= 200\n",
    "                else:\n",
    "                    # 0 < steps < 4000일 때 비례 보상 계산\n",
    "                    proportion = (4000 - self.steps) / 4000\n",
    "                    additional_reward = 200 * (2 * proportion - 1)  # 비례 보상 계산 (-200에서 +200 사이)\n",
    "                    if additional_reward > 0:\n",
    "                        success_ratio = self.flip_count / self.steps if self.steps > 0 else 0\n",
    "                        reward += additional_reward * success_ratio\n",
    "                    else:\n",
    "                        reward += additional_reward\n",
    "\n",
    "        else:\n",
    "            self.psnr_sustained_steps = 0\n",
    "\n",
    "        # 관찰값 업데이트\n",
    "        info = {\n",
    "            \"psnr_before\": psnr_before,\n",
    "            \"psnr_after\": psnr_after,\n",
    "            \"psnr_change\": psnr_change,\n",
    "            \"psnr_diff\": psnr_diff,\n",
    "            \"pre_flip_value\": pre_flip_value,\n",
    "            \"state_before\": self.state.copy(),  # 행동 이전 상태\n",
    "            \"state_after\": self.state.copy() if psnr_change >= 0 else None,  # 행동 성공 시 상태\n",
    "            \"observation_before\": self.observation.copy(),  # 행동 이전 관찰값\n",
    "            \"observation_after\": combined_observation if psnr_change >= 0 else None,  # 행동 성공 시 관찰값\n",
    "            \"failed_action\": action if psnr_change < 0 else None,  # 실패한 행동\n",
    "            \"flip_count\": self.flip_count,  # 현재까지의 플립 횟수\n",
    "            \"reward\": reward,\n",
    "            \"target_image\": self.target_image.cpu().numpy(),  # 타겟 이미지\n",
    "            \"simulation_result\": result_np,  # 현재 시뮬레이션 결과\n",
    "            \"action_coords\": (channel, row, col),  # 행동한 좌표\n",
    "            \"step\": self.steps  # 현재 스텝\n",
    "        }\n",
    "\n",
    "        self.steps += 1\n",
    "\n",
    "        return combined_observation, reward, terminated, truncated, info\n",
    "\n",
    "\n",
    "batch_size = 1\n",
    "#target_dir = 'dataset/'\n",
    "target_dir = '/nfs/dataset/DIV2K/DIV2K_train_HR/DIV2K_train_HR/'\n",
    "valid_dir = '/nfs/dataset/DIV2K/DIV2K_valid_HR/DIV2K_valid_HR/'\n",
    "meta = {'wl': (515e-9), 'dx': (7.56e-6, 7.56e-6)}  # 메타 정보\n",
    "padding = 0\n",
    "\n",
    "# Dataset512 클래스 사용\n",
    "train_dataset = Dataset512(target_dir=target_dir, meta=meta, isTrain=False, padding=padding) #센터크롭\n",
    "#train_dataset = Dataset512(target_dir=target_dir, meta=meta, isTrain=True, padding=padding) #랜덤크롭\n",
    "valid_dataset = Dataset512(target_dir=valid_dir, meta=meta, isTrain=False, padding=padding)\n",
    "\n",
    "# DataLoader 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "#train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# BinaryNet 모델 로드\n",
    "model = BinaryNet(num_hologram=CH, in_planes=1, convReLU=False, convBN=False,\n",
    "                  poolReLU=False, poolBN=False, deconvReLU=False, deconvBN=False).cuda()\n",
    "model.load_state_dict(torch.load('result_v/2024-12-19 20:37:52.499731_pre_reinforce_8_0.002/2024-12-19 20:37:52.499731_pre_reinforce_8_0.002'))\n",
    "model.eval()\n",
    "\n",
    "# 환경 생성에 새로운 데이터 로더 적용\n",
    "env = BinaryHologramEnv(\n",
    "    target_function=model,\n",
    "    trainloader=train_loader, \n",
    ")\n",
    "\n",
    "# 에피소드 보상 로깅 콜백\n",
    "class RewardLoggingCallback(BaseCallback):\n",
    "    def __init__(self, verbose=1):\n",
    "        super(RewardLoggingCallback, self).__init__(verbose)\n",
    "        self.episode_rewards = []  # 각 에피소드 보상을 저장\n",
    "        self.current_episode_reward = 0  # 현재 에피소드의 보상\n",
    "        self.episode_count = 0  # 에피소드 수를 추적\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # 현재 스텝의 보상을 누적\n",
    "        reward = self.locals[\"rewards\"]\n",
    "        self.current_episode_reward += reward[0]  # 첫 번째 환경의 보상\n",
    "\n",
    "        # 에피소드 종료 처리\n",
    "        if self.locals[\"dones\"][0]:  # 첫 번째 환경에서 에피소드 종료 시\n",
    "            self.episode_rewards.append(self.current_episode_reward)\n",
    "            self.episode_count += 1\n",
    "\n",
    "            if self.verbose > 0:\n",
    "                print(f\"\\033[41mEpisode {self.episode_count}: Total Reward: {self.current_episode_reward:.2f}\\033[0m\")\n",
    "\n",
    "            # 현재 에피소드 보상을 초기화\n",
    "            self.current_episode_reward = 0\n",
    "\n",
    "        return True  # 학습 계속\n",
    "\n",
    "# 학습 종료 콜백\n",
    "class StopOnEpisodeCallback(BaseCallback):\n",
    "    def __init__(self, max_episodes, verbose=1):\n",
    "        super(StopOnEpisodeCallback, self).__init__(verbose)\n",
    "        self.max_episodes = max_episodes\n",
    "        self.episode_count = 0  # 에피소드 수를 추적\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # `dones`이 True일 때마다 에피소드 증가\n",
    "        if self.locals.get(\"dones\") is not None:\n",
    "            self.episode_count += np.sum(self.locals[\"dones\"])  # 에피소드 완료 횟수 추가\n",
    "\n",
    "        if self.episode_count >= self.max_episodes:  # 최대 에피소드 도달 시 학습 종료\n",
    "            print(f\"Stopping training at episode {self.episode_count}\")\n",
    "            return False  # 학습 중단\n",
    "        return True  # 학습 계속\n",
    "\n",
    "# 저장할 폴더 경로 설정\n",
    "save_dir = \"./ppo_MlpPolicy_models/\"  # 모델 저장 디렉토리\n",
    "os.makedirs(save_dir, exist_ok=True)  # 디렉토리가 없으면 생성\n",
    "\n",
    "# 모델 저장 경로 설정\n",
    "ppo_model_path = os.path.join(save_dir, \"ppo_MlpPolicy_latest.zip\")  # 최신 PPO 모델 저장 경로\n",
    "resume_training = True  # True로 설정하면 이전 모델에서 학습 재개\n",
    "\n",
    "# PPO 모델 로드 또는 새로 생성\n",
    "if resume_training and os.path.exists(ppo_model_path):\n",
    "    print(f\"Loading trained PPO model from {ppo_model_path}\")\n",
    "    ppo_model = PPO.load(ppo_model_path, env=env)\n",
    "else:\n",
    "    if resume_training:\n",
    "        print(f\"Warning: PPO model not found at {ppo_model_path}. Starting training from scratch.\")\n",
    "    print(\"Starting training from scratch.\")\n",
    "    ppo_model = PPO(\n",
    "        \"MlpPolicy\",\n",
    "        env,\n",
    "        verbose=2,\n",
    "        n_steps=512,\n",
    "        batch_size=128,\n",
    "        gamma=0.99,\n",
    "        gae_lambda=0.9,\n",
    "        learning_rate=1e-4,\n",
    "        clip_range=0.2,\n",
    "        vf_coef=0.5,\n",
    "        max_grad_norm=0.5,\n",
    "        ent_coef=0.01,\n",
    "        tensorboard_log=\"./ppo_MlpPolicy/\",\n",
    "        policy_kwargs={\n",
    "        \"net_arch\": [dict(pi=[256, 128, 64], vf=[256, 128, 64])],\n",
    "        },\n",
    "    )\n",
    "\n",
    "# 콜백 설정\n",
    "max_episodes = 8000  # 원하는 에피소드 수\n",
    "reward_logging_callback = RewardLoggingCallback(verbose=1)\n",
    "stop_callback = StopOnEpisodeCallback(max_episodes=max_episodes)\n",
    "callback = CallbackList([reward_logging_callback, stop_callback])\n",
    "\n",
    "# 학습 시작\n",
    "ppo_model.learn(total_timesteps=1000000000, callback=callback)\n",
    "\n",
    "# 모델 저장\n",
    "print(f\"Start model saving at {save_dir}\")\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "ppo_model_save_path = os.path.join(save_dir, f\"ppo_MlpPolicy_{current_date}.zip\")\n",
    "ppo_model.save(ppo_model_save_path)\n",
    "print(f\"PPO Model saved at {save_dir}\")\n",
    "\n",
    "# 최신 모델 업데이트\n",
    "print(f\"Start model updating at {save_dir}\")\n",
    "ppo_model_latest_path = os.path.join(save_dir, \"ppo_MlpPolicy_latest.zip\")\n",
    "\n",
    "# 최신 모델을 덮어쓰기 위해 기존 모델 파일 복사\n",
    "if os.path.exists(ppo_model_latest_path):\n",
    "    os.remove(ppo_model_latest_path)  # 기존 파일 삭제\n",
    "shutil.copyfile(ppo_model_save_path, ppo_model_latest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dd0c83-99b3-4f86-bc23-89c6b278e3ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e105c7a2-bd3a-440c-9ad3-3ec9a08af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
